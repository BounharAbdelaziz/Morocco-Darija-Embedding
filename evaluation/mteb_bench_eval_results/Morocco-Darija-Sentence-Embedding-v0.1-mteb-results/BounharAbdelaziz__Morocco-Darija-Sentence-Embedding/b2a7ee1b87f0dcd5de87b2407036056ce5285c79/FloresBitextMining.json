{
  "dataset_revision": "e6b647fcb6299a2f686f742f4d4c023e553ea67e",
  "task_name": "FloresBitextMining",
  "mteb_version": "1.34.22",
  "scores": {
    "devtest": [
      {
        "precision": 0.077227,
        "recall": 0.11166,
        "f1": 0.083657,
        "accuracy": 0.11166,
        "main_score": 0.083657,
        "hf_subset": "ace_Arab-ary_Arab",
        "languages": [
          "ace-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.183607,
        "recall": 0.230237,
        "f1": 0.194349,
        "accuracy": 0.230237,
        "main_score": 0.194349,
        "hf_subset": "bam_Latn-ary_Arab",
        "languages": [
          "bam-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.000165,
        "recall": 0.000988,
        "f1": 0.000282,
        "accuracy": 0.000988,
        "main_score": 0.000282,
        "hf_subset": "dzo_Tibt-ary_Arab",
        "languages": [
          "dzo-Tibt",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.96525,
        "recall": 0.976285,
        "f1": 0.968874,
        "accuracy": 0.976285,
        "main_score": 0.968874,
        "hf_subset": "hin_Deva-ary_Arab",
        "languages": [
          "hin-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.922513,
        "recall": 0.945652,
        "f1": 0.929908,
        "accuracy": 0.945652,
        "main_score": 0.929908,
        "hf_subset": "khm_Khmr-ary_Arab",
        "languages": [
          "khm-Khmr",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.913825,
        "recall": 0.936759,
        "f1": 0.920949,
        "accuracy": 0.936759,
        "main_score": 0.920949,
        "hf_subset": "mag_Deva-ary_Arab",
        "languages": [
          "mag-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.672168,
        "recall": 0.738142,
        "f1": 0.691471,
        "accuracy": 0.738142,
        "main_score": 0.691471,
        "hf_subset": "pap_Latn-ary_Arab",
        "languages": [
          "pap-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.200152,
        "recall": 0.242095,
        "f1": 0.210729,
        "accuracy": 0.242095,
        "main_score": 0.210729,
        "hf_subset": "sot_Latn-ary_Arab",
        "languages": [
          "sot-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.964921,
        "recall": 0.975296,
        "f1": 0.968379,
        "accuracy": 0.975296,
        "main_score": 0.968379,
        "hf_subset": "tur_Latn-ary_Arab",
        "languages": [
          "tur-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.406764,
        "recall": 0.471344,
        "f1": 0.422835,
        "accuracy": 0.471344,
        "main_score": 0.422835,
        "hf_subset": "ace_Latn-ary_Arab",
        "languages": [
          "ace-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.57413,
        "recall": 0.641304,
        "f1": 0.592467,
        "accuracy": 0.641304,
        "main_score": 0.592467,
        "hf_subset": "ban_Latn-ary_Arab",
        "languages": [
          "ban-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.964921,
        "recall": 0.976285,
        "f1": 0.968709,
        "accuracy": 0.976285,
        "main_score": 0.968709,
        "hf_subset": "ell_Grek-ary_Arab",
        "languages": [
          "ell-Grek",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.866958,
        "recall": 0.903162,
        "f1": 0.878195,
        "accuracy": 0.903162,
        "main_score": 0.878195,
        "hf_subset": "hne_Deva-ary_Arab",
        "languages": [
          "hne-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.140322,
        "recall": 0.184783,
        "f1": 0.149119,
        "accuracy": 0.184783,
        "main_score": 0.149119,
        "hf_subset": "kik_Latn-ary_Arab",
        "languages": [
          "kik-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.82864,
        "recall": 0.875494,
        "f1": 0.843169,
        "accuracy": 0.875494,
        "main_score": 0.843169,
        "hf_subset": "mai_Deva-ary_Arab",
        "languages": [
          "mai-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.855155,
        "recall": 0.891304,
        "f1": 0.86629,
        "accuracy": 0.891304,
        "main_score": 0.86629,
        "hf_subset": "pbt_Arab-ary_Arab",
        "languages": [
          "pbt-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.970356,
        "recall": 0.980237,
        "f1": 0.97365,
        "accuracy": 0.980237,
        "main_score": 0.97365,
        "hf_subset": "spa_Latn-ary_Arab",
        "languages": [
          "spa-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.241939,
        "recall": 0.305336,
        "f1": 0.256123,
        "accuracy": 0.305336,
        "main_score": 0.256123,
        "hf_subset": "twi_Latn-ary_Arab",
        "languages": [
          "twi-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.961957,
        "recall": 0.974308,
        "f1": 0.966074,
        "accuracy": 0.974308,
        "main_score": 0.966074,
        "hf_subset": "acm_Arab-ary_Arab",
        "languages": [
          "acm-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.951087,
        "recall": 0.967391,
        "f1": 0.956522,
        "accuracy": 0.967391,
        "main_score": 0.956522,
        "hf_subset": "bel_Cyrl-ary_Arab",
        "languages": [
          "bel-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.975296,
        "recall": 0.983202,
        "f1": 0.977931,
        "accuracy": 0.983202,
        "main_score": 0.977931,
        "hf_subset": "eng_Latn-ary_Arab",
        "languages": [
          "eng-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.965744,
        "recall": 0.976285,
        "f1": 0.969203,
        "accuracy": 0.976285,
        "main_score": 0.969203,
        "hf_subset": "hrv_Latn-ary_Arab",
        "languages": [
          "hrv-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.150961,
        "recall": 0.194664,
        "f1": 0.160953,
        "accuracy": 0.194664,
        "main_score": 0.160953,
        "hf_subset": "kin_Latn-ary_Arab",
        "languages": [
          "kin-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.95751,
        "recall": 0.971344,
        "f1": 0.962121,
        "accuracy": 0.971344,
        "main_score": 0.962121,
        "hf_subset": "mal_Mlym-ary_Arab",
        "languages": [
          "mal-Mlym",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.969862,
        "recall": 0.979249,
        "f1": 0.972991,
        "accuracy": 0.979249,
        "main_score": 0.972991,
        "hf_subset": "pes_Arab-ary_Arab",
        "languages": [
          "pes-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.732103,
        "recall": 0.794466,
        "f1": 0.750941,
        "accuracy": 0.794466,
        "main_score": 0.750941,
        "hf_subset": "srd_Latn-ary_Arab",
        "languages": [
          "srd-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.042284,
        "recall": 0.0583,
        "f1": 0.045524,
        "accuracy": 0.0583,
        "main_score": 0.045524,
        "hf_subset": "tzm_Tfng-ary_Arab",
        "languages": [
          "tzm-Tfng",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.970356,
        "recall": 0.980237,
        "f1": 0.97365,
        "accuracy": 0.980237,
        "main_score": 0.97365,
        "hf_subset": "acq_Arab-ary_Arab",
        "languages": [
          "acq-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.21404,
        "recall": 0.263834,
        "f1": 0.224328,
        "accuracy": 0.263834,
        "main_score": 0.224328,
        "hf_subset": "bem_Latn-ary_Arab",
        "languages": [
          "bem-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.960474,
        "recall": 0.972332,
        "f1": 0.964427,
        "accuracy": 0.972332,
        "main_score": 0.964427,
        "hf_subset": "epo_Latn-ary_Arab",
        "languages": [
          "epo-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.969038,
        "recall": 0.978261,
        "f1": 0.972003,
        "accuracy": 0.978261,
        "main_score": 0.972003,
        "hf_subset": "hun_Latn-ary_Arab",
        "languages": [
          "hun-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.920685,
        "recall": 0.943676,
        "f1": 0.92803,
        "accuracy": 0.943676,
        "main_score": 0.92803,
        "hf_subset": "kir_Cyrl-ary_Arab",
        "languages": [
          "kir-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.95751,
        "recall": 0.971344,
        "f1": 0.962121,
        "accuracy": 0.971344,
        "main_score": 0.962121,
        "hf_subset": "mar_Deva-ary_Arab",
        "languages": [
          "mar-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.627914,
        "recall": 0.694664,
        "f1": 0.646377,
        "accuracy": 0.694664,
        "main_score": 0.646377,
        "hf_subset": "plt_Latn-ary_Arab",
        "languages": [
          "plt-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.966238,
        "recall": 0.976285,
        "f1": 0.969532,
        "accuracy": 0.976285,
        "main_score": 0.969532,
        "hf_subset": "srp_Cyrl-ary_Arab",
        "languages": [
          "srp-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.874506,
        "recall": 0.910079,
        "f1": 0.886001,
        "accuracy": 0.910079,
        "main_score": 0.886001,
        "hf_subset": "uig_Arab-ary_Arab",
        "languages": [
          "uig-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.964921,
        "recall": 0.976285,
        "f1": 0.968709,
        "accuracy": 0.976285,
        "main_score": 0.968709,
        "hf_subset": "aeb_Arab-ary_Arab",
        "languages": [
          "aeb-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.951252,
        "recall": 0.966403,
        "f1": 0.956192,
        "accuracy": 0.966403,
        "main_score": 0.956192,
        "hf_subset": "ben_Beng-ary_Arab",
        "languages": [
          "ben-Beng",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.95504,
        "recall": 0.969368,
        "f1": 0.959651,
        "accuracy": 0.969368,
        "main_score": 0.959651,
        "hf_subset": "est_Latn-ary_Arab",
        "languages": [
          "est-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.943511,
        "recall": 0.961462,
        "f1": 0.94944,
        "accuracy": 0.961462,
        "main_score": 0.94944,
        "hf_subset": "hye_Armn-ary_Arab",
        "languages": [
          "hye-Armn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.165062,
        "recall": 0.211462,
        "f1": 0.174558,
        "accuracy": 0.211462,
        "main_score": 0.174558,
        "hf_subset": "kmb_Latn-ary_Arab",
        "languages": [
          "kmb-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.049364,
        "recall": 0.079051,
        "f1": 0.055141,
        "accuracy": 0.079051,
        "main_score": 0.055141,
        "hf_subset": "min_Arab-ary_Arab",
        "languages": [
          "min-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.953722,
        "recall": 0.968379,
        "f1": 0.958498,
        "accuracy": 0.968379,
        "main_score": 0.958498,
        "hf_subset": "pol_Latn-ary_Arab",
        "languages": [
          "pol-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.169158,
        "recall": 0.212451,
        "f1": 0.178183,
        "accuracy": 0.212451,
        "main_score": 0.178183,
        "hf_subset": "ssw_Latn-ary_Arab",
        "languages": [
          "ssw-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.971344,
        "recall": 0.980237,
        "f1": 0.974308,
        "accuracy": 0.980237,
        "main_score": 0.974308,
        "hf_subset": "ukr_Cyrl-ary_Arab",
        "languages": [
          "ukr-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.964921,
        "recall": 0.976285,
        "f1": 0.968709,
        "accuracy": 0.976285,
        "main_score": 0.968709,
        "hf_subset": "afr_Latn-ary_Arab",
        "languages": [
          "afr-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.839992,
        "recall": 0.881423,
        "f1": 0.853063,
        "accuracy": 0.881423,
        "main_score": 0.853063,
        "hf_subset": "bho_Deva-ary_Arab",
        "languages": [
          "bho-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.908432,
        "recall": 0.934783,
        "f1": 0.916963,
        "accuracy": 0.934783,
        "main_score": 0.916963,
        "hf_subset": "eus_Latn-ary_Arab",
        "languages": [
          "eus-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.168074,
        "recall": 0.211462,
        "f1": 0.177459,
        "accuracy": 0.211462,
        "main_score": 0.177459,
        "hf_subset": "ibo_Latn-ary_Arab",
        "languages": [
          "ibo-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.736384,
        "recall": 0.79249,
        "f1": 0.752652,
        "accuracy": 0.79249,
        "main_score": 0.752652,
        "hf_subset": "kmr_Latn-ary_Arab",
        "languages": [
          "kmr-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.569615,
        "recall": 0.643281,
        "f1": 0.590618,
        "accuracy": 0.643281,
        "main_score": 0.590618,
        "hf_subset": "min_Latn-ary_Arab",
        "languages": [
          "min-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.967391,
        "recall": 0.977273,
        "f1": 0.970685,
        "accuracy": 0.977273,
        "main_score": 0.970685,
        "hf_subset": "por_Latn-ary_Arab",
        "languages": [
          "por-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.835557,
        "recall": 0.875494,
        "f1": 0.847553,
        "accuracy": 0.875494,
        "main_score": 0.847553,
        "hf_subset": "sun_Latn-ary_Arab",
        "languages": [
          "sun-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.172832,
        "recall": 0.220356,
        "f1": 0.182408,
        "accuracy": 0.220356,
        "main_score": 0.182408,
        "hf_subset": "umb_Latn-ary_Arab",
        "languages": [
          "umb-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.972826,
        "recall": 0.981225,
        "f1": 0.975626,
        "accuracy": 0.981225,
        "main_score": 0.975626,
        "hf_subset": "ajp_Arab-ary_Arab",
        "languages": [
          "ajp-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.073618,
        "recall": 0.101779,
        "f1": 0.08001,
        "accuracy": 0.101779,
        "main_score": 0.08001,
        "hf_subset": "bjn_Arab-ary_Arab",
        "languages": [
          "bjn-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.176364,
        "recall": 0.224308,
        "f1": 0.188104,
        "accuracy": 0.224308,
        "main_score": 0.188104,
        "hf_subset": "ewe_Latn-ary_Arab",
        "languages": [
          "ewe-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.381553,
        "recall": 0.454545,
        "f1": 0.400286,
        "accuracy": 0.454545,
        "main_score": 0.400286,
        "hf_subset": "ilo_Latn-ary_Arab",
        "languages": [
          "ilo-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.081111,
        "recall": 0.105731,
        "f1": 0.086995,
        "accuracy": 0.105731,
        "main_score": 0.086995,
        "hf_subset": "knc_Arab-ary_Arab",
        "languages": [
          "knc-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.966897,
        "recall": 0.977273,
        "f1": 0.970356,
        "accuracy": 0.977273,
        "main_score": 0.970356,
        "hf_subset": "mkd_Cyrl-ary_Arab",
        "languages": [
          "mkd-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.963439,
        "recall": 0.975296,
        "f1": 0.967391,
        "accuracy": 0.975296,
        "main_score": 0.967391,
        "hf_subset": "prs_Arab-ary_Arab",
        "languages": [
          "prs-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.970685,
        "recall": 0.979249,
        "f1": 0.973485,
        "accuracy": 0.979249,
        "main_score": 0.973485,
        "hf_subset": "swe_Latn-ary_Arab",
        "languages": [
          "swe-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.953063,
        "recall": 0.967391,
        "f1": 0.957675,
        "accuracy": 0.967391,
        "main_score": 0.957675,
        "hf_subset": "urd_Arab-ary_Arab",
        "languages": [
          "urd-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.228028,
        "recall": 0.286561,
        "f1": 0.241586,
        "accuracy": 0.286561,
        "main_score": 0.241586,
        "hf_subset": "aka_Latn-ary_Arab",
        "languages": [
          "aka-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.711955,
        "recall": 0.768775,
        "f1": 0.728255,
        "accuracy": 0.768775,
        "main_score": 0.728255,
        "hf_subset": "bjn_Latn-ary_Arab",
        "languages": [
          "bjn-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.662246,
        "recall": 0.726285,
        "f1": 0.680642,
        "accuracy": 0.726285,
        "main_score": 0.680642,
        "hf_subset": "fao_Latn-ary_Arab",
        "languages": [
          "fao-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.968379,
        "recall": 0.978261,
        "f1": 0.971673,
        "accuracy": 0.978261,
        "main_score": 0.971673,
        "hf_subset": "ind_Latn-ary_Arab",
        "languages": [
          "ind-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.227863,
        "recall": 0.275692,
        "f1": 0.239533,
        "accuracy": 0.275692,
        "main_score": 0.239533,
        "hf_subset": "knc_Latn-ary_Arab",
        "languages": [
          "knc-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.373917,
        "recall": 0.444664,
        "f1": 0.39179,
        "accuracy": 0.444664,
        "main_score": 0.39179,
        "hf_subset": "mlt_Latn-ary_Arab",
        "languages": [
          "mlt-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.210697,
        "recall": 0.259881,
        "f1": 0.221654,
        "accuracy": 0.259881,
        "main_score": 0.221654,
        "hf_subset": "quy_Latn-ary_Arab",
        "languages": [
          "quy-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.862731,
        "recall": 0.898221,
        "f1": 0.873668,
        "accuracy": 0.898221,
        "main_score": 0.873668,
        "hf_subset": "swh_Latn-ary_Arab",
        "languages": [
          "swh-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.903771,
        "recall": 0.93083,
        "f1": 0.912121,
        "accuracy": 0.93083,
        "main_score": 0.912121,
        "hf_subset": "uzn_Latn-ary_Arab",
        "languages": [
          "uzn-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.960474,
        "recall": 0.97332,
        "f1": 0.964756,
        "accuracy": 0.97332,
        "main_score": 0.964756,
        "hf_subset": "als_Latn-ary_Arab",
        "languages": [
          "als-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.033652,
        "recall": 0.048419,
        "f1": 0.037136,
        "accuracy": 0.048419,
        "main_score": 0.037136,
        "hf_subset": "bod_Tibt-ary_Arab",
        "languages": [
          "bod-Tibt",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.175289,
        "recall": 0.220356,
        "f1": 0.184652,
        "accuracy": 0.220356,
        "main_score": 0.184652,
        "hf_subset": "fij_Latn-ary_Arab",
        "languages": [
          "fij-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.929513,
        "recall": 0.951581,
        "f1": 0.936759,
        "accuracy": 0.951581,
        "main_score": 0.936759,
        "hf_subset": "isl_Latn-ary_Arab",
        "languages": [
          "isl-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.23225,
        "recall": 0.283597,
        "f1": 0.243352,
        "accuracy": 0.283597,
        "main_score": 0.243352,
        "hf_subset": "kon_Latn-ary_Arab",
        "languages": [
          "kon-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.119383,
        "recall": 0.155138,
        "f1": 0.125779,
        "accuracy": 0.155138,
        "main_score": 0.125779,
        "hf_subset": "mni_Beng-ary_Arab",
        "languages": [
          "mni-Beng",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.969862,
        "recall": 0.979249,
        "f1": 0.972991,
        "accuracy": 0.979249,
        "main_score": 0.972991,
        "hf_subset": "ron_Latn-ary_Arab",
        "languages": [
          "ron-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.837484,
        "recall": 0.878458,
        "f1": 0.850428,
        "accuracy": 0.878458,
        "main_score": 0.850428,
        "hf_subset": "szl_Latn-ary_Arab",
        "languages": [
          "szl-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.840556,
        "recall": 0.880435,
        "f1": 0.852619,
        "accuracy": 0.880435,
        "main_score": 0.852619,
        "hf_subset": "vec_Latn-ary_Arab",
        "languages": [
          "vec-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.816378,
        "recall": 0.866601,
        "f1": 0.832049,
        "accuracy": 0.866601,
        "main_score": 0.832049,
        "hf_subset": "amh_Ethi-ary_Arab",
        "languages": [
          "amh-Ethi",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.97085,
        "recall": 0.980237,
        "f1": 0.973979,
        "accuracy": 0.980237,
        "main_score": 0.973979,
        "hf_subset": "bos_Latn-ary_Arab",
        "languages": [
          "bos-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.960474,
        "recall": 0.97332,
        "f1": 0.964756,
        "accuracy": 0.97332,
        "main_score": 0.964756,
        "hf_subset": "fin_Latn-ary_Arab",
        "languages": [
          "fin-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.971344,
        "recall": 0.980237,
        "f1": 0.974308,
        "accuracy": 0.980237,
        "main_score": 0.974308,
        "hf_subset": "ita_Latn-ary_Arab",
        "languages": [
          "ita-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.958004,
        "recall": 0.971344,
        "f1": 0.962451,
        "accuracy": 0.971344,
        "main_score": 0.962451,
        "hf_subset": "kor_Hang-ary_Arab",
        "languages": [
          "kor-Hang",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.194629,
        "recall": 0.235178,
        "f1": 0.204213,
        "accuracy": 0.235178,
        "main_score": 0.204213,
        "hf_subset": "mos_Latn-ary_Arab",
        "languages": [
          "mos-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.151002,
        "recall": 0.193676,
        "f1": 0.160183,
        "accuracy": 0.193676,
        "main_score": 0.160183,
        "hf_subset": "run_Latn-ary_Arab",
        "languages": [
          "run-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.944993,
        "recall": 0.962451,
        "f1": 0.950758,
        "accuracy": 0.962451,
        "main_score": 0.950758,
        "hf_subset": "tam_Taml-ary_Arab",
        "languages": [
          "tam-Taml",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.958004,
        "recall": 0.971344,
        "f1": 0.962451,
        "accuracy": 0.971344,
        "main_score": 0.962451,
        "hf_subset": "vie_Latn-ary_Arab",
        "languages": [
          "vie-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.962945,
        "recall": 0.974308,
        "f1": 0.966733,
        "accuracy": 0.974308,
        "main_score": 0.966733,
        "hf_subset": "apc_Arab-ary_Arab",
        "languages": [
          "apc-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.350055,
        "recall": 0.411067,
        "f1": 0.365491,
        "accuracy": 0.411067,
        "main_score": 0.365491,
        "hf_subset": "bug_Latn-ary_Arab",
        "languages": [
          "bug-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.163713,
        "recall": 0.205534,
        "f1": 0.173216,
        "accuracy": 0.205534,
        "main_score": 0.173216,
        "hf_subset": "fon_Latn-ary_Arab",
        "languages": [
          "fon-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.873363,
        "recall": 0.905138,
        "f1": 0.882955,
        "accuracy": 0.905138,
        "main_score": 0.882955,
        "hf_subset": "jav_Latn-ary_Arab",
        "languages": [
          "jav-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.930995,
        "recall": 0.952569,
        "f1": 0.938076,
        "accuracy": 0.952569,
        "main_score": 0.938076,
        "hf_subset": "lao_Laoo-ary_Arab",
        "languages": [
          "lao-Laoo",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.141716,
        "recall": 0.167984,
        "f1": 0.146435,
        "accuracy": 0.167984,
        "main_score": 0.146435,
        "hf_subset": "mri_Latn-ary_Arab",
        "languages": [
          "mri-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.964921,
        "recall": 0.976285,
        "f1": 0.968709,
        "accuracy": 0.976285,
        "main_score": 0.968709,
        "hf_subset": "rus_Cyrl-ary_Arab",
        "languages": [
          "rus-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.231018,
        "recall": 0.285573,
        "f1": 0.244401,
        "accuracy": 0.285573,
        "main_score": 0.244401,
        "hf_subset": "taq_Latn-ary_Arab",
        "languages": [
          "taq-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.548392,
        "recall": 0.626482,
        "f1": 0.569239,
        "accuracy": 0.626482,
        "main_score": 0.569239,
        "hf_subset": "war_Latn-ary_Arab",
        "languages": [
          "war-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.971838,
        "recall": 0.981225,
        "f1": 0.974967,
        "accuracy": 0.981225,
        "main_score": 0.974967,
        "hf_subset": "arb_Arab-ary_Arab",
        "languages": [
          "arb-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.966897,
        "recall": 0.977273,
        "f1": 0.970356,
        "accuracy": 0.977273,
        "main_score": 0.970356,
        "hf_subset": "bul_Cyrl-ary_Arab",
        "languages": [
          "bul-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.974802,
        "recall": 0.982213,
        "f1": 0.977273,
        "accuracy": 0.982213,
        "main_score": 0.977273,
        "hf_subset": "fra_Latn-ary_Arab",
        "languages": [
          "fra-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.95191,
        "recall": 0.967391,
        "f1": 0.957016,
        "accuracy": 0.967391,
        "main_score": 0.957016,
        "hf_subset": "jpn_Jpan-ary_Arab",
        "languages": [
          "jpn-Jpan",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.723258,
        "recall": 0.785573,
        "f1": 0.741849,
        "accuracy": 0.785573,
        "main_score": 0.741849,
        "hf_subset": "lij_Latn-ary_Arab",
        "languages": [
          "lij-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.908267,
        "recall": 0.935771,
        "f1": 0.917161,
        "accuracy": 0.935771,
        "main_score": 0.917161,
        "hf_subset": "mya_Mymr-ary_Arab",
        "languages": [
          "mya-Mymr",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.214381,
        "recall": 0.257905,
        "f1": 0.224756,
        "accuracy": 0.257905,
        "main_score": 0.224756,
        "hf_subset": "sag_Latn-ary_Arab",
        "languages": [
          "sag-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.054568,
        "recall": 0.071146,
        "f1": 0.057798,
        "accuracy": 0.071146,
        "main_score": 0.057798,
        "hf_subset": "taq_Tfng-ary_Arab",
        "languages": [
          "taq-Tfng",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.226834,
        "recall": 0.277668,
        "f1": 0.239944,
        "accuracy": 0.277668,
        "main_score": 0.239944,
        "hf_subset": "wol_Latn-ary_Arab",
        "languages": [
          "wol-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.215474,
        "recall": 0.257905,
        "f1": 0.225146,
        "accuracy": 0.257905,
        "main_score": 0.225146,
        "hf_subset": "arb_Latn-ary_Arab",
        "languages": [
          "arb-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.968874,
        "recall": 0.979249,
        "f1": 0.972332,
        "accuracy": 0.979249,
        "main_score": 0.972332,
        "hf_subset": "cat_Latn-ary_Arab",
        "languages": [
          "cat-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.679451,
        "recall": 0.750988,
        "f1": 0.700561,
        "accuracy": 0.750988,
        "main_score": 0.700561,
        "hf_subset": "fur_Latn-ary_Arab",
        "languages": [
          "fur-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.098334,
        "recall": 0.131423,
        "f1": 0.104922,
        "accuracy": 0.131423,
        "main_score": 0.104922,
        "hf_subset": "kab_Latn-ary_Arab",
        "languages": [
          "kab-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.715175,
        "recall": 0.766798,
        "f1": 0.730176,
        "accuracy": 0.766798,
        "main_score": 0.730176,
        "hf_subset": "lim_Latn-ary_Arab",
        "languages": [
          "lim-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.966733,
        "recall": 0.977273,
        "f1": 0.970191,
        "accuracy": 0.977273,
        "main_score": 0.970191,
        "hf_subset": "nld_Latn-ary_Arab",
        "languages": [
          "nld-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.797394,
        "recall": 0.851779,
        "f1": 0.813938,
        "accuracy": 0.851779,
        "main_score": 0.813938,
        "hf_subset": "san_Deva-ary_Arab",
        "languages": [
          "san-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.447434,
        "recall": 0.528656,
        "f1": 0.469848,
        "accuracy": 0.528656,
        "main_score": 0.469848,
        "hf_subset": "tat_Cyrl-ary_Arab",
        "languages": [
          "tat-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.333063,
        "recall": 0.395257,
        "f1": 0.347231,
        "accuracy": 0.395257,
        "main_score": 0.347231,
        "hf_subset": "xho_Latn-ary_Arab",
        "languages": [
          "xho-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.970356,
        "recall": 0.980237,
        "f1": 0.97365,
        "accuracy": 0.980237,
        "main_score": 0.97365,
        "hf_subset": "ars_Arab-ary_Arab",
        "languages": [
          "ars-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.605564,
        "recall": 0.673913,
        "f1": 0.624554,
        "accuracy": 0.673913,
        "main_score": 0.624554,
        "hf_subset": "ceb_Latn-ary_Arab",
        "languages": [
          "ceb-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.197754,
        "recall": 0.240119,
        "f1": 0.207417,
        "accuracy": 0.240119,
        "main_score": 0.207417,
        "hf_subset": "fuv_Latn-ary_Arab",
        "languages": [
          "fuv-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.177838,
        "recall": 0.214427,
        "f1": 0.186638,
        "accuracy": 0.214427,
        "main_score": 0.186638,
        "hf_subset": "kac_Latn-ary_Arab",
        "languages": [
          "kac-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.234757,
        "recall": 0.29249,
        "f1": 0.247572,
        "accuracy": 0.29249,
        "main_score": 0.247572,
        "hf_subset": "lin_Latn-ary_Arab",
        "languages": [
          "lin-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.964921,
        "recall": 0.976285,
        "f1": 0.968709,
        "accuracy": 0.976285,
        "main_score": 0.968709,
        "hf_subset": "nno_Latn-ary_Arab",
        "languages": [
          "nno-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.004545,
        "recall": 0.006917,
        "f1": 0.00512,
        "accuracy": 0.006917,
        "main_score": 0.00512,
        "hf_subset": "sat_Olck-ary_Arab",
        "languages": [
          "sat-Olck",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.933794,
        "recall": 0.955534,
        "f1": 0.941041,
        "accuracy": 0.955534,
        "main_score": 0.941041,
        "hf_subset": "tel_Telu-ary_Arab",
        "languages": [
          "tel-Telu",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.758986,
        "recall": 0.817194,
        "f1": 0.776215,
        "accuracy": 0.817194,
        "main_score": 0.776215,
        "hf_subset": "ydd_Hebr-ary_Arab",
        "languages": [
          "ydd-Hebr",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.096502,
        "recall": 0.174901,
        "f1": 0.112639,
        "accuracy": 0.174901,
        "main_score": 0.112639,
        "hf_subset": "ary_Arab-ace_Arab",
        "languages": [
          "ary-Arab",
          "ace-Arab"
        ]
      },
      {
        "precision": 0.169583,
        "recall": 0.26087,
        "f1": 0.188824,
        "accuracy": 0.26087,
        "main_score": 0.188824,
        "hf_subset": "ary_Arab-bam_Latn",
        "languages": [
          "ary-Arab",
          "bam-Latn"
        ]
      },
      {
        "precision": 0.000227,
        "recall": 0.004941,
        "f1": 0.000403,
        "accuracy": 0.004941,
        "main_score": 0.000403,
        "hf_subset": "ary_Arab-dzo_Tibt",
        "languages": [
          "ary-Arab",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.957345,
        "recall": 0.970356,
        "f1": 0.961462,
        "accuracy": 0.970356,
        "main_score": 0.961462,
        "hf_subset": "ary_Arab-hin_Deva",
        "languages": [
          "ary-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.92556,
        "recall": 0.947628,
        "f1": 0.932477,
        "accuracy": 0.947628,
        "main_score": 0.932477,
        "hf_subset": "ary_Arab-khm_Khmr",
        "languages": [
          "ary-Arab",
          "khm-Khmr"
        ]
      },
      {
        "precision": 0.855929,
        "recall": 0.901186,
        "f1": 0.870553,
        "accuracy": 0.901186,
        "main_score": 0.870553,
        "hf_subset": "ary_Arab-mag_Deva",
        "languages": [
          "ary-Arab",
          "mag-Deva"
        ]
      },
      {
        "precision": 0.617872,
        "recall": 0.708498,
        "f1": 0.64395,
        "accuracy": 0.708498,
        "main_score": 0.64395,
        "hf_subset": "ary_Arab-pap_Latn",
        "languages": [
          "ary-Arab",
          "pap-Latn"
        ]
      },
      {
        "precision": 0.172043,
        "recall": 0.278656,
        "f1": 0.19488,
        "accuracy": 0.278656,
        "main_score": 0.19488,
        "hf_subset": "ary_Arab-sot_Latn",
        "languages": [
          "ary-Arab",
          "sot-Latn"
        ]
      },
      {
        "precision": 0.967227,
        "recall": 0.977273,
        "f1": 0.97052,
        "accuracy": 0.977273,
        "main_score": 0.97052,
        "hf_subset": "ary_Arab-tur_Latn",
        "languages": [
          "ary-Arab",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.339636,
        "recall": 0.455534,
        "f1": 0.367776,
        "accuracy": 0.455534,
        "main_score": 0.367776,
        "hf_subset": "ary_Arab-ace_Latn",
        "languages": [
          "ary-Arab",
          "ace-Latn"
        ]
      },
      {
        "precision": 0.516902,
        "recall": 0.621542,
        "f1": 0.545313,
        "accuracy": 0.621542,
        "main_score": 0.545313,
        "hf_subset": "ary_Arab-ban_Latn",
        "languages": [
          "ary-Arab",
          "ban-Latn"
        ]
      },
      {
        "precision": 0.963768,
        "recall": 0.975296,
        "f1": 0.967556,
        "accuracy": 0.975296,
        "main_score": 0.967556,
        "hf_subset": "ary_Arab-ell_Grek",
        "languages": [
          "ary-Arab",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.798872,
        "recall": 0.854743,
        "f1": 0.815983,
        "accuracy": 0.854743,
        "main_score": 0.815983,
        "hf_subset": "ary_Arab-hne_Deva",
        "languages": [
          "ary-Arab",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.134488,
        "recall": 0.242095,
        "f1": 0.157119,
        "accuracy": 0.242095,
        "main_score": 0.157119,
        "hf_subset": "ary_Arab-kik_Latn",
        "languages": [
          "ary-Arab",
          "kik-Latn"
        ]
      },
      {
        "precision": 0.760853,
        "recall": 0.827075,
        "f1": 0.780929,
        "accuracy": 0.827075,
        "main_score": 0.780929,
        "hf_subset": "ary_Arab-mai_Deva",
        "languages": [
          "ary-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.828008,
        "recall": 0.875494,
        "f1": 0.842556,
        "accuracy": 0.875494,
        "main_score": 0.842556,
        "hf_subset": "ary_Arab-pbt_Arab",
        "languages": [
          "ary-Arab",
          "pbt-Arab"
        ]
      },
      {
        "precision": 0.966733,
        "recall": 0.977273,
        "f1": 0.970191,
        "accuracy": 0.977273,
        "main_score": 0.970191,
        "hf_subset": "ary_Arab-spa_Latn",
        "languages": [
          "ary-Arab",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.218289,
        "recall": 0.320158,
        "f1": 0.240618,
        "accuracy": 0.320158,
        "main_score": 0.240618,
        "hf_subset": "ary_Arab-twi_Latn",
        "languages": [
          "ary-Arab",
          "twi-Latn"
        ]
      },
      {
        "precision": 0.970026,
        "recall": 0.979249,
        "f1": 0.972991,
        "accuracy": 0.979249,
        "main_score": 0.972991,
        "hf_subset": "ary_Arab-acm_Arab",
        "languages": [
          "ary-Arab",
          "acm-Arab"
        ]
      },
      {
        "precision": 0.94417,
        "recall": 0.962451,
        "f1": 0.950264,
        "accuracy": 0.962451,
        "main_score": 0.950264,
        "hf_subset": "ary_Arab-bel_Cyrl",
        "languages": [
          "ary-Arab",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.975626,
        "recall": 0.983202,
        "f1": 0.978096,
        "accuracy": 0.983202,
        "main_score": 0.978096,
        "hf_subset": "ary_Arab-eng_Latn",
        "languages": [
          "ary-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.966238,
        "recall": 0.977273,
        "f1": 0.969862,
        "accuracy": 0.977273,
        "main_score": 0.969862,
        "hf_subset": "ary_Arab-hrv_Latn",
        "languages": [
          "ary-Arab",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.144185,
        "recall": 0.231225,
        "f1": 0.162403,
        "accuracy": 0.231225,
        "main_score": 0.162403,
        "hf_subset": "ary_Arab-kin_Latn",
        "languages": [
          "ary-Arab",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.943511,
        "recall": 0.961462,
        "f1": 0.94944,
        "accuracy": 0.961462,
        "main_score": 0.94944,
        "hf_subset": "ary_Arab-mal_Mlym",
        "languages": [
          "ary-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.960968,
        "recall": 0.97332,
        "f1": 0.965086,
        "accuracy": 0.97332,
        "main_score": 0.965086,
        "hf_subset": "ary_Arab-pes_Arab",
        "languages": [
          "ary-Arab",
          "pes-Arab"
        ]
      },
      {
        "precision": 0.690508,
        "recall": 0.770751,
        "f1": 0.714196,
        "accuracy": 0.770751,
        "main_score": 0.714196,
        "hf_subset": "ary_Arab-srd_Latn",
        "languages": [
          "ary-Arab",
          "srd-Latn"
        ]
      },
      {
        "precision": 0.05424,
        "recall": 0.107708,
        "f1": 0.063405,
        "accuracy": 0.107708,
        "main_score": 0.063405,
        "hf_subset": "ary_Arab-tzm_Tfng",
        "languages": [
          "ary-Arab",
          "tzm-Tfng"
        ]
      },
      {
        "precision": 0.975626,
        "recall": 0.983202,
        "f1": 0.978096,
        "accuracy": 0.983202,
        "main_score": 0.978096,
        "hf_subset": "ary_Arab-acq_Arab",
        "languages": [
          "ary-Arab",
          "acq-Arab"
        ]
      },
      {
        "precision": 0.196501,
        "recall": 0.291502,
        "f1": 0.216322,
        "accuracy": 0.291502,
        "main_score": 0.216322,
        "hf_subset": "ary_Arab-bem_Latn",
        "languages": [
          "ary-Arab",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.957181,
        "recall": 0.970356,
        "f1": 0.961462,
        "accuracy": 0.970356,
        "main_score": 0.961462,
        "hf_subset": "ary_Arab-epo_Latn",
        "languages": [
          "ary-Arab",
          "epo-Latn"
        ]
      },
      {
        "precision": 0.955369,
        "recall": 0.969368,
        "f1": 0.95998,
        "accuracy": 0.969368,
        "main_score": 0.95998,
        "hf_subset": "ary_Arab-hun_Latn",
        "languages": [
          "ary-Arab",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.908185,
        "recall": 0.934783,
        "f1": 0.916568,
        "accuracy": 0.934783,
        "main_score": 0.916568,
        "hf_subset": "ary_Arab-kir_Cyrl",
        "languages": [
          "ary-Arab",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.930336,
        "recall": 0.951581,
        "f1": 0.937253,
        "accuracy": 0.951581,
        "main_score": 0.937253,
        "hf_subset": "ary_Arab-mar_Deva",
        "languages": [
          "ary-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.578508,
        "recall": 0.677866,
        "f1": 0.606621,
        "accuracy": 0.677866,
        "main_score": 0.606621,
        "hf_subset": "ary_Arab-plt_Latn",
        "languages": [
          "ary-Arab",
          "plt-Latn"
        ]
      },
      {
        "precision": 0.964097,
        "recall": 0.975296,
        "f1": 0.967721,
        "accuracy": 0.975296,
        "main_score": 0.967721,
        "hf_subset": "ary_Arab-srp_Cyrl",
        "languages": [
          "ary-Arab",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.854441,
        "recall": 0.896245,
        "f1": 0.867325,
        "accuracy": 0.896245,
        "main_score": 0.867325,
        "hf_subset": "ary_Arab-uig_Arab",
        "languages": [
          "ary-Arab",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.960145,
        "recall": 0.972332,
        "f1": 0.964097,
        "accuracy": 0.972332,
        "main_score": 0.964097,
        "hf_subset": "ary_Arab-aeb_Arab",
        "languages": [
          "ary-Arab",
          "aeb-Arab"
        ]
      },
      {
        "precision": 0.91996,
        "recall": 0.944664,
        "f1": 0.927866,
        "accuracy": 0.944664,
        "main_score": 0.927866,
        "hf_subset": "ary_Arab-ben_Beng",
        "languages": [
          "ary-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.933712,
        "recall": 0.954545,
        "f1": 0.940448,
        "accuracy": 0.954545,
        "main_score": 0.940448,
        "hf_subset": "ary_Arab-est_Latn",
        "languages": [
          "ary-Arab",
          "est-Latn"
        ]
      },
      {
        "precision": 0.925511,
        "recall": 0.947628,
        "f1": 0.932543,
        "accuracy": 0.947628,
        "main_score": 0.932543,
        "hf_subset": "ary_Arab-hye_Armn",
        "languages": [
          "ary-Arab",
          "hye-Armn"
        ]
      },
      {
        "precision": 0.148061,
        "recall": 0.243083,
        "f1": 0.167355,
        "accuracy": 0.243083,
        "main_score": 0.167355,
        "hf_subset": "ary_Arab-kmb_Latn",
        "languages": [
          "ary-Arab",
          "kmb-Latn"
        ]
      },
      {
        "precision": 0.061178,
        "recall": 0.113636,
        "f1": 0.071469,
        "accuracy": 0.113636,
        "main_score": 0.071469,
        "hf_subset": "ary_Arab-min_Arab",
        "languages": [
          "ary-Arab",
          "min-Arab"
        ]
      },
      {
        "precision": 0.971179,
        "recall": 0.980237,
        "f1": 0.974144,
        "accuracy": 0.980237,
        "main_score": 0.974144,
        "hf_subset": "ary_Arab-pol_Latn",
        "languages": [
          "ary-Arab",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.148471,
        "recall": 0.237154,
        "f1": 0.166149,
        "accuracy": 0.237154,
        "main_score": 0.166149,
        "hf_subset": "ary_Arab-ssw_Latn",
        "languages": [
          "ary-Arab",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.971179,
        "recall": 0.980237,
        "f1": 0.974144,
        "accuracy": 0.980237,
        "main_score": 0.974144,
        "hf_subset": "ary_Arab-ukr_Cyrl",
        "languages": [
          "ary-Arab",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.958004,
        "recall": 0.971344,
        "f1": 0.962451,
        "accuracy": 0.971344,
        "main_score": 0.962451,
        "hf_subset": "ary_Arab-afr_Latn",
        "languages": [
          "ary-Arab",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.786051,
        "recall": 0.843874,
        "f1": 0.804043,
        "accuracy": 0.843874,
        "main_score": 0.804043,
        "hf_subset": "ary_Arab-bho_Deva",
        "languages": [
          "ary-Arab",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.883646,
        "recall": 0.918972,
        "f1": 0.894993,
        "accuracy": 0.918972,
        "main_score": 0.894993,
        "hf_subset": "ary_Arab-eus_Latn",
        "languages": [
          "ary-Arab",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.135004,
        "recall": 0.238142,
        "f1": 0.156516,
        "accuracy": 0.238142,
        "main_score": 0.156516,
        "hf_subset": "ary_Arab-ibo_Latn",
        "languages": [
          "ary-Arab",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.679018,
        "recall": 0.763834,
        "f1": 0.705011,
        "accuracy": 0.763834,
        "main_score": 0.705011,
        "hf_subset": "ary_Arab-kmr_Latn",
        "languages": [
          "ary-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.530625,
        "recall": 0.641304,
        "f1": 0.561886,
        "accuracy": 0.641304,
        "main_score": 0.561886,
        "hf_subset": "ary_Arab-min_Latn",
        "languages": [
          "ary-Arab",
          "min-Latn"
        ]
      },
      {
        "precision": 0.962615,
        "recall": 0.974308,
        "f1": 0.966403,
        "accuracy": 0.974308,
        "main_score": 0.966403,
        "hf_subset": "ary_Arab-por_Latn",
        "languages": [
          "ary-Arab",
          "por-Latn"
        ]
      },
      {
        "precision": 0.778557,
        "recall": 0.839921,
        "f1": 0.797167,
        "accuracy": 0.839921,
        "main_score": 0.797167,
        "hf_subset": "ary_Arab-sun_Latn",
        "languages": [
          "ary-Arab",
          "sun-Latn"
        ]
      },
      {
        "precision": 0.157521,
        "recall": 0.25,
        "f1": 0.176317,
        "accuracy": 0.25,
        "main_score": 0.176317,
        "hf_subset": "ary_Arab-umb_Latn",
        "languages": [
          "ary-Arab",
          "umb-Latn"
        ]
      },
      {
        "precision": 0.969697,
        "recall": 0.979249,
        "f1": 0.972826,
        "accuracy": 0.979249,
        "main_score": 0.972826,
        "hf_subset": "ary_Arab-ajp_Arab",
        "languages": [
          "ary-Arab",
          "ajp-Arab"
        ]
      },
      {
        "precision": 0.074167,
        "recall": 0.13834,
        "f1": 0.087266,
        "accuracy": 0.13834,
        "main_score": 0.087266,
        "hf_subset": "ary_Arab-bjn_Arab",
        "languages": [
          "ary-Arab",
          "bjn-Arab"
        ]
      },
      {
        "precision": 0.150426,
        "recall": 0.248024,
        "f1": 0.170131,
        "accuracy": 0.248024,
        "main_score": 0.170131,
        "hf_subset": "ary_Arab-ewe_Latn",
        "languages": [
          "ary-Arab",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.373219,
        "recall": 0.48419,
        "f1": 0.401894,
        "accuracy": 0.48419,
        "main_score": 0.401894,
        "hf_subset": "ary_Arab-ilo_Latn",
        "languages": [
          "ary-Arab",
          "ilo-Latn"
        ]
      },
      {
        "precision": 0.072812,
        "recall": 0.130435,
        "f1": 0.083645,
        "accuracy": 0.130435,
        "main_score": 0.083645,
        "hf_subset": "ary_Arab-knc_Arab",
        "languages": [
          "ary-Arab",
          "knc-Arab"
        ]
      },
      {
        "precision": 0.961462,
        "recall": 0.974308,
        "f1": 0.965744,
        "accuracy": 0.974308,
        "main_score": 0.965744,
        "hf_subset": "ary_Arab-mkd_Cyrl",
        "languages": [
          "ary-Arab",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.953557,
        "recall": 0.968379,
        "f1": 0.958498,
        "accuracy": 0.968379,
        "main_score": 0.958498,
        "hf_subset": "ary_Arab-prs_Arab",
        "languages": [
          "ary-Arab",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.971509,
        "recall": 0.980237,
        "f1": 0.974308,
        "accuracy": 0.980237,
        "main_score": 0.974308,
        "hf_subset": "ary_Arab-swe_Latn",
        "languages": [
          "ary-Arab",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.941123,
        "recall": 0.958498,
        "f1": 0.946542,
        "accuracy": 0.958498,
        "main_score": 0.946542,
        "hf_subset": "ary_Arab-urd_Arab",
        "languages": [
          "ary-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.200558,
        "recall": 0.311265,
        "f1": 0.224959,
        "accuracy": 0.311265,
        "main_score": 0.224959,
        "hf_subset": "ary_Arab-aka_Latn",
        "languages": [
          "ary-Arab",
          "aka-Latn"
        ]
      },
      {
        "precision": 0.672538,
        "recall": 0.752964,
        "f1": 0.696135,
        "accuracy": 0.752964,
        "main_score": 0.696135,
        "hf_subset": "ary_Arab-bjn_Latn",
        "languages": [
          "ary-Arab",
          "bjn-Latn"
        ]
      },
      {
        "precision": 0.623931,
        "recall": 0.717391,
        "f1": 0.651572,
        "accuracy": 0.717391,
        "main_score": 0.651572,
        "hf_subset": "ary_Arab-fao_Latn",
        "languages": [
          "ary-Arab",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.969697,
        "recall": 0.979249,
        "f1": 0.972826,
        "accuracy": 0.979249,
        "main_score": 0.972826,
        "hf_subset": "ary_Arab-ind_Latn",
        "languages": [
          "ary-Arab",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.202051,
        "recall": 0.298419,
        "f1": 0.223699,
        "accuracy": 0.298419,
        "main_score": 0.223699,
        "hf_subset": "ary_Arab-knc_Latn",
        "languages": [
          "ary-Arab",
          "knc-Latn"
        ]
      },
      {
        "precision": 0.348675,
        "recall": 0.458498,
        "f1": 0.376105,
        "accuracy": 0.458498,
        "main_score": 0.376105,
        "hf_subset": "ary_Arab-mlt_Latn",
        "languages": [
          "ary-Arab",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.20004,
        "recall": 0.298419,
        "f1": 0.220796,
        "accuracy": 0.298419,
        "main_score": 0.220796,
        "hf_subset": "ary_Arab-quy_Latn",
        "languages": [
          "ary-Arab",
          "quy-Latn"
        ]
      },
      {
        "precision": 0.817523,
        "recall": 0.871542,
        "f1": 0.834486,
        "accuracy": 0.871542,
        "main_score": 0.834486,
        "hf_subset": "ary_Arab-swh_Latn",
        "languages": [
          "ary-Arab",
          "swh-Latn"
        ]
      },
      {
        "precision": 0.887599,
        "recall": 0.920949,
        "f1": 0.89809,
        "accuracy": 0.920949,
        "main_score": 0.89809,
        "hf_subset": "ary_Arab-uzn_Latn",
        "languages": [
          "ary-Arab",
          "uzn-Latn"
        ]
      },
      {
        "precision": 0.962286,
        "recall": 0.974308,
        "f1": 0.966238,
        "accuracy": 0.974308,
        "main_score": 0.966238,
        "hf_subset": "ary_Arab-als_Latn",
        "languages": [
          "ary-Arab",
          "als-Latn"
        ]
      },
      {
        "precision": 0.038216,
        "recall": 0.083992,
        "f1": 0.043977,
        "accuracy": 0.083992,
        "main_score": 0.043977,
        "hf_subset": "ary_Arab-bod_Tibt",
        "languages": [
          "ary-Arab",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.160637,
        "recall": 0.257905,
        "f1": 0.181437,
        "accuracy": 0.257905,
        "main_score": 0.181437,
        "hf_subset": "ary_Arab-fij_Latn",
        "languages": [
          "ary-Arab",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.907115,
        "recall": 0.936759,
        "f1": 0.916831,
        "accuracy": 0.936759,
        "main_score": 0.916831,
        "hf_subset": "ary_Arab-isl_Latn",
        "languages": [
          "ary-Arab",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.223407,
        "recall": 0.324111,
        "f1": 0.246107,
        "accuracy": 0.324111,
        "main_score": 0.246107,
        "hf_subset": "ary_Arab-kon_Latn",
        "languages": [
          "ary-Arab",
          "kon-Latn"
        ]
      },
      {
        "precision": 0.104509,
        "recall": 0.185771,
        "f1": 0.120398,
        "accuracy": 0.185771,
        "main_score": 0.120398,
        "hf_subset": "ary_Arab-mni_Beng",
        "languages": [
          "ary-Arab",
          "mni-Beng"
        ]
      },
      {
        "precision": 0.968215,
        "recall": 0.978261,
        "f1": 0.971509,
        "accuracy": 0.978261,
        "main_score": 0.971509,
        "hf_subset": "ary_Arab-ron_Latn",
        "languages": [
          "ary-Arab",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.788752,
        "recall": 0.846838,
        "f1": 0.806508,
        "accuracy": 0.846838,
        "main_score": 0.806508,
        "hf_subset": "ary_Arab-szl_Latn",
        "languages": [
          "ary-Arab",
          "szl-Latn"
        ]
      },
      {
        "precision": 0.778508,
        "recall": 0.841897,
        "f1": 0.798075,
        "accuracy": 0.841897,
        "main_score": 0.798075,
        "hf_subset": "ary_Arab-vec_Latn",
        "languages": [
          "ary-Arab",
          "vec-Latn"
        ]
      },
      {
        "precision": 0.802564,
        "recall": 0.855731,
        "f1": 0.819236,
        "accuracy": 0.855731,
        "main_score": 0.819236,
        "hf_subset": "ary_Arab-amh_Ethi",
        "languages": [
          "ary-Arab",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.972661,
        "recall": 0.981225,
        "f1": 0.975461,
        "accuracy": 0.981225,
        "main_score": 0.975461,
        "hf_subset": "ary_Arab-bos_Latn",
        "languages": [
          "ary-Arab",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.961627,
        "recall": 0.97332,
        "f1": 0.965415,
        "accuracy": 0.97332,
        "main_score": 0.965415,
        "hf_subset": "ary_Arab-fin_Latn",
        "languages": [
          "ary-Arab",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.968215,
        "recall": 0.978261,
        "f1": 0.971509,
        "accuracy": 0.978261,
        "main_score": 0.971509,
        "hf_subset": "ary_Arab-ita_Latn",
        "languages": [
          "ary-Arab",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.951746,
        "recall": 0.966403,
        "f1": 0.956522,
        "accuracy": 0.966403,
        "main_score": 0.956522,
        "hf_subset": "ary_Arab-kor_Hang",
        "languages": [
          "ary-Arab",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.168573,
        "recall": 0.264822,
        "f1": 0.190256,
        "accuracy": 0.264822,
        "main_score": 0.190256,
        "hf_subset": "ary_Arab-mos_Latn",
        "languages": [
          "ary-Arab",
          "mos-Latn"
        ]
      },
      {
        "precision": 0.143697,
        "recall": 0.226285,
        "f1": 0.159835,
        "accuracy": 0.226285,
        "main_score": 0.159835,
        "hf_subset": "ary_Arab-run_Latn",
        "languages": [
          "ary-Arab",
          "run-Latn"
        ]
      },
      {
        "precision": 0.937912,
        "recall": 0.95751,
        "f1": 0.944335,
        "accuracy": 0.95751,
        "main_score": 0.944335,
        "hf_subset": "ary_Arab-tam_Taml",
        "languages": [
          "ary-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.971509,
        "recall": 0.980237,
        "f1": 0.974308,
        "accuracy": 0.980237,
        "main_score": 0.974308,
        "hf_subset": "ary_Arab-vie_Latn",
        "languages": [
          "ary-Arab",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.967227,
        "recall": 0.977273,
        "f1": 0.97052,
        "accuracy": 0.977273,
        "main_score": 0.97052,
        "hf_subset": "ary_Arab-apc_Arab",
        "languages": [
          "ary-Arab",
          "apc-Arab"
        ]
      },
      {
        "precision": 0.299958,
        "recall": 0.414032,
        "f1": 0.327471,
        "accuracy": 0.414032,
        "main_score": 0.327471,
        "hf_subset": "ary_Arab-bug_Latn",
        "languages": [
          "ary-Arab",
          "bug-Latn"
        ]
      },
      {
        "precision": 0.125944,
        "recall": 0.222332,
        "f1": 0.144836,
        "accuracy": 0.222332,
        "main_score": 0.144836,
        "hf_subset": "ary_Arab-fon_Latn",
        "languages": [
          "ary-Arab",
          "fon-Latn"
        ]
      },
      {
        "precision": 0.811215,
        "recall": 0.865613,
        "f1": 0.828261,
        "accuracy": 0.865613,
        "main_score": 0.828261,
        "hf_subset": "ary_Arab-jav_Latn",
        "languages": [
          "ary-Arab",
          "jav-Latn"
        ]
      },
      {
        "precision": 0.918725,
        "recall": 0.943676,
        "f1": 0.926779,
        "accuracy": 0.943676,
        "main_score": 0.926779,
        "hf_subset": "ary_Arab-lao_Laoo",
        "languages": [
          "ary-Arab",
          "lao-Laoo"
        ]
      },
      {
        "precision": 0.107505,
        "recall": 0.200593,
        "f1": 0.124719,
        "accuracy": 0.200593,
        "main_score": 0.124719,
        "hf_subset": "ary_Arab-mri_Latn",
        "languages": [
          "ary-Arab",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.968874,
        "recall": 0.979249,
        "f1": 0.972332,
        "accuracy": 0.979249,
        "main_score": 0.972332,
        "hf_subset": "ary_Arab-rus_Cyrl",
        "languages": [
          "ary-Arab",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.200386,
        "recall": 0.302372,
        "f1": 0.223095,
        "accuracy": 0.302372,
        "main_score": 0.223095,
        "hf_subset": "ary_Arab-taq_Latn",
        "languages": [
          "ary-Arab",
          "taq-Latn"
        ]
      },
      {
        "precision": 0.516162,
        "recall": 0.624506,
        "f1": 0.546537,
        "accuracy": 0.624506,
        "main_score": 0.546537,
        "hf_subset": "ary_Arab-war_Latn",
        "languages": [
          "ary-Arab",
          "war-Latn"
        ]
      },
      {
        "precision": 0.977108,
        "recall": 0.98419,
        "f1": 0.979414,
        "accuracy": 0.98419,
        "main_score": 0.979414,
        "hf_subset": "ary_Arab-arb_Arab",
        "languages": [
          "ary-Arab",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.969697,
        "recall": 0.979249,
        "f1": 0.972826,
        "accuracy": 0.979249,
        "main_score": 0.972826,
        "hf_subset": "ary_Arab-bul_Cyrl",
        "languages": [
          "ary-Arab",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.968215,
        "recall": 0.978261,
        "f1": 0.971509,
        "accuracy": 0.978261,
        "main_score": 0.971509,
        "hf_subset": "ary_Arab-fra_Latn",
        "languages": [
          "ary-Arab",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.957181,
        "recall": 0.970356,
        "f1": 0.961462,
        "accuracy": 0.970356,
        "main_score": 0.961462,
        "hf_subset": "ary_Arab-jpn_Jpan",
        "languages": [
          "ary-Arab",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.677928,
        "recall": 0.755929,
        "f1": 0.700038,
        "accuracy": 0.755929,
        "main_score": 0.700038,
        "hf_subset": "ary_Arab-lij_Latn",
        "languages": [
          "ary-Arab",
          "lij-Latn"
        ]
      },
      {
        "precision": 0.877223,
        "recall": 0.914032,
        "f1": 0.888867,
        "accuracy": 0.914032,
        "main_score": 0.888867,
        "hf_subset": "ary_Arab-mya_Mymr",
        "languages": [
          "ary-Arab",
          "mya-Mymr"
        ]
      },
      {
        "precision": 0.179942,
        "recall": 0.283597,
        "f1": 0.202225,
        "accuracy": 0.283597,
        "main_score": 0.202225,
        "hf_subset": "ary_Arab-sag_Latn",
        "languages": [
          "ary-Arab",
          "sag-Latn"
        ]
      },
      {
        "precision": 0.055991,
        "recall": 0.105731,
        "f1": 0.063053,
        "accuracy": 0.105731,
        "main_score": 0.063053,
        "hf_subset": "ary_Arab-taq_Tfng",
        "languages": [
          "ary-Arab",
          "taq-Tfng"
        ]
      },
      {
        "precision": 0.192045,
        "recall": 0.30336,
        "f1": 0.216077,
        "accuracy": 0.30336,
        "main_score": 0.216077,
        "hf_subset": "ary_Arab-wol_Latn",
        "languages": [
          "ary-Arab",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.206816,
        "recall": 0.302372,
        "f1": 0.229011,
        "accuracy": 0.302372,
        "main_score": 0.229011,
        "hf_subset": "ary_Arab-arb_Latn",
        "languages": [
          "ary-Arab",
          "arb-Latn"
        ]
      },
      {
        "precision": 0.968215,
        "recall": 0.978261,
        "f1": 0.971509,
        "accuracy": 0.978261,
        "main_score": 0.971509,
        "hf_subset": "ary_Arab-cat_Latn",
        "languages": [
          "ary-Arab",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.628542,
        "recall": 0.718379,
        "f1": 0.654124,
        "accuracy": 0.718379,
        "main_score": 0.654124,
        "hf_subset": "ary_Arab-fur_Latn",
        "languages": [
          "ary-Arab",
          "fur-Latn"
        ]
      },
      {
        "precision": 0.110407,
        "recall": 0.184783,
        "f1": 0.125572,
        "accuracy": 0.184783,
        "main_score": 0.125572,
        "hf_subset": "ary_Arab-kab_Latn",
        "languages": [
          "ary-Arab",
          "kab-Latn"
        ]
      },
      {
        "precision": 0.658762,
        "recall": 0.741107,
        "f1": 0.682759,
        "accuracy": 0.741107,
        "main_score": 0.682759,
        "hf_subset": "ary_Arab-lim_Latn",
        "languages": [
          "ary-Arab",
          "lim-Latn"
        ]
      },
      {
        "precision": 0.96525,
        "recall": 0.976285,
        "f1": 0.968874,
        "accuracy": 0.976285,
        "main_score": 0.968874,
        "hf_subset": "ary_Arab-nld_Latn",
        "languages": [
          "ary-Arab",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.796673,
        "recall": 0.850791,
        "f1": 0.81349,
        "accuracy": 0.850791,
        "main_score": 0.81349,
        "hf_subset": "ary_Arab-san_Deva",
        "languages": [
          "ary-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.430198,
        "recall": 0.537549,
        "f1": 0.458606,
        "accuracy": 0.537549,
        "main_score": 0.458606,
        "hf_subset": "ary_Arab-tat_Cyrl",
        "languages": [
          "ary-Arab",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.28513,
        "recall": 0.399209,
        "f1": 0.312952,
        "accuracy": 0.399209,
        "main_score": 0.312952,
        "hf_subset": "ary_Arab-xho_Latn",
        "languages": [
          "ary-Arab",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.972661,
        "recall": 0.981225,
        "f1": 0.975461,
        "accuracy": 0.981225,
        "main_score": 0.975461,
        "hf_subset": "ary_Arab-ars_Arab",
        "languages": [
          "ary-Arab",
          "ars-Arab"
        ]
      },
      {
        "precision": 0.561002,
        "recall": 0.663043,
        "f1": 0.59011,
        "accuracy": 0.663043,
        "main_score": 0.59011,
        "hf_subset": "ary_Arab-ceb_Latn",
        "languages": [
          "ary-Arab",
          "ceb-Latn"
        ]
      },
      {
        "precision": 0.163681,
        "recall": 0.267787,
        "f1": 0.185802,
        "accuracy": 0.267787,
        "main_score": 0.185802,
        "hf_subset": "ary_Arab-fuv_Latn",
        "languages": [
          "ary-Arab",
          "fuv-Latn"
        ]
      },
      {
        "precision": 0.165537,
        "recall": 0.267787,
        "f1": 0.187446,
        "accuracy": 0.267787,
        "main_score": 0.187446,
        "hf_subset": "ary_Arab-kac_Latn",
        "languages": [
          "ary-Arab",
          "kac-Latn"
        ]
      },
      {
        "precision": 0.20161,
        "recall": 0.307312,
        "f1": 0.224181,
        "accuracy": 0.307312,
        "main_score": 0.224181,
        "hf_subset": "ary_Arab-lin_Latn",
        "languages": [
          "ary-Arab",
          "lin-Latn"
        ]
      },
      {
        "precision": 0.958333,
        "recall": 0.971344,
        "f1": 0.962615,
        "accuracy": 0.971344,
        "main_score": 0.962615,
        "hf_subset": "ary_Arab-nno_Latn",
        "languages": [
          "ary-Arab",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.003213,
        "recall": 0.01581,
        "f1": 0.004,
        "accuracy": 0.01581,
        "main_score": 0.004,
        "hf_subset": "ary_Arab-sat_Olck",
        "languages": [
          "ary-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.902092,
        "recall": 0.932806,
        "f1": 0.912121,
        "accuracy": 0.932806,
        "main_score": 0.912121,
        "hf_subset": "ary_Arab-tel_Telu",
        "languages": [
          "ary-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.736693,
        "recall": 0.8083,
        "f1": 0.758404,
        "accuracy": 0.8083,
        "main_score": 0.758404,
        "hf_subset": "ary_Arab-ydd_Hebr",
        "languages": [
          "ary-Arab",
          "ydd-Hebr"
        ]
      },
      {
        "precision": 0.966238,
        "recall": 0.976285,
        "f1": 0.969532,
        "accuracy": 0.976285,
        "main_score": 0.969532,
        "hf_subset": "ary_Arab-ces_Latn",
        "languages": [
          "ary-Arab",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.226732,
        "recall": 0.336957,
        "f1": 0.253203,
        "accuracy": 0.336957,
        "main_score": 0.253203,
        "hf_subset": "ary_Arab-gaz_Latn",
        "languages": [
          "ary-Arab",
          "gaz-Latn"
        ]
      },
      {
        "precision": 0.158863,
        "recall": 0.255929,
        "f1": 0.179239,
        "accuracy": 0.255929,
        "main_score": 0.179239,
        "hf_subset": "ary_Arab-kam_Latn",
        "languages": [
          "ary-Arab",
          "kam-Latn"
        ]
      },
      {
        "precision": 0.945735,
        "recall": 0.962451,
        "f1": 0.951153,
        "accuracy": 0.962451,
        "main_score": 0.951153,
        "hf_subset": "ary_Arab-lit_Latn",
        "languages": [
          "ary-Arab",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.96525,
        "recall": 0.976285,
        "f1": 0.968874,
        "accuracy": 0.976285,
        "main_score": 0.968874,
        "hf_subset": "ary_Arab-nob_Latn",
        "languages": [
          "ary-Arab",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.580825,
        "recall": 0.678854,
        "f1": 0.609045,
        "accuracy": 0.678854,
        "main_score": 0.609045,
        "hf_subset": "ary_Arab-scn_Latn",
        "languages": [
          "ary-Arab",
          "scn-Latn"
        ]
      },
      {
        "precision": 0.186551,
        "recall": 0.277668,
        "f1": 0.207722,
        "accuracy": 0.277668,
        "main_score": 0.207722,
        "hf_subset": "ary_Arab-tgk_Cyrl",
        "languages": [
          "ary-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.123765,
        "recall": 0.226285,
        "f1": 0.144428,
        "accuracy": 0.226285,
        "main_score": 0.144428,
        "hf_subset": "ary_Arab-yor_Latn",
        "languages": [
          "ary-Arab",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.970767,
        "recall": 0.979249,
        "f1": 0.973386,
        "accuracy": 0.979249,
        "main_score": 0.973386,
        "hf_subset": "ary_Arab-arz_Arab",
        "languages": [
          "ary-Arab",
          "arz-Arab"
        ]
      },
      {
        "precision": 0.164525,
        "recall": 0.266798,
        "f1": 0.185438,
        "accuracy": 0.266798,
        "main_score": 0.185438,
        "hf_subset": "ary_Arab-cjk_Latn",
        "languages": [
          "ary-Arab",
          "cjk-Latn"
        ]
      },
      {
        "precision": 0.53556,
        "recall": 0.645257,
        "f1": 0.566598,
        "accuracy": 0.645257,
        "main_score": 0.566598,
        "hf_subset": "ary_Arab-gla_Latn",
        "languages": [
          "ary-Arab",
          "gla-Latn"
        ]
      },
      {
        "precision": 0.916864,
        "recall": 0.939723,
        "f1": 0.923748,
        "accuracy": 0.939723,
        "main_score": 0.923748,
        "hf_subset": "ary_Arab-kan_Knda",
        "languages": [
          "ary-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.597908,
        "recall": 0.692688,
        "f1": 0.625022,
        "accuracy": 0.692688,
        "main_score": 0.625022,
        "hf_subset": "ary_Arab-lmo_Latn",
        "languages": [
          "ary-Arab",
          "lmo-Latn"
        ]
      },
      {
        "precision": 0.925478,
        "recall": 0.947628,
        "f1": 0.932543,
        "accuracy": 0.947628,
        "main_score": 0.932543,
        "hf_subset": "ary_Arab-npi_Deva",
        "languages": [
          "ary-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.166429,
        "recall": 0.271739,
        "f1": 0.18945,
        "accuracy": 0.271739,
        "main_score": 0.18945,
        "hf_subset": "ary_Arab-shn_Mymr",
        "languages": [
          "ary-Arab",
          "shn-Mymr"
        ]
      },
      {
        "precision": 0.927207,
        "recall": 0.948617,
        "f1": 0.934124,
        "accuracy": 0.948617,
        "main_score": 0.934124,
        "hf_subset": "ary_Arab-tgl_Latn",
        "languages": [
          "ary-Arab",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.96278,
        "recall": 0.974308,
        "f1": 0.966568,
        "accuracy": 0.974308,
        "main_score": 0.966568,
        "hf_subset": "ary_Arab-yue_Hant",
        "languages": [
          "ary-Arab",
          "yue-Hant"
        ]
      },
      {
        "precision": 0.728007,
        "recall": 0.800395,
        "f1": 0.749852,
        "accuracy": 0.800395,
        "main_score": 0.749852,
        "hf_subset": "ary_Arab-asm_Beng",
        "languages": [
          "ary-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.079506,
        "recall": 0.158103,
        "f1": 0.094814,
        "accuracy": 0.158103,
        "main_score": 0.094814,
        "hf_subset": "ary_Arab-ckb_Arab",
        "languages": [
          "ary-Arab",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.718692,
        "recall": 0.79249,
        "f1": 0.740862,
        "accuracy": 0.79249,
        "main_score": 0.740862,
        "hf_subset": "ary_Arab-gle_Latn",
        "languages": [
          "ary-Arab",
          "gle-Latn"
        ]
      },
      {
        "precision": 0.361804,
        "recall": 0.478261,
        "f1": 0.391175,
        "accuracy": 0.478261,
        "main_score": 0.391175,
        "hf_subset": "ary_Arab-kas_Arab",
        "languages": [
          "ary-Arab",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.438633,
        "recall": 0.546443,
        "f1": 0.467279,
        "accuracy": 0.546443,
        "main_score": 0.467279,
        "hf_subset": "ary_Arab-ltg_Latn",
        "languages": [
          "ary-Arab",
          "ltg-Latn"
        ]
      },
      {
        "precision": 0.170275,
        "recall": 0.272727,
        "f1": 0.192069,
        "accuracy": 0.272727,
        "main_score": 0.192069,
        "hf_subset": "ary_Arab-nso_Latn",
        "languages": [
          "ary-Arab",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.900198,
        "recall": 0.929842,
        "f1": 0.909552,
        "accuracy": 0.929842,
        "main_score": 0.909552,
        "hf_subset": "ary_Arab-sin_Sinh",
        "languages": [
          "ary-Arab",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.966733,
        "recall": 0.977273,
        "f1": 0.970191,
        "accuracy": 0.977273,
        "main_score": 0.970191,
        "hf_subset": "ary_Arab-tha_Thai",
        "languages": [
          "ary-Arab",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.972661,
        "recall": 0.981225,
        "f1": 0.975461,
        "accuracy": 0.981225,
        "main_score": 0.975461,
        "hf_subset": "ary_Arab-zho_Hans",
        "languages": [
          "ary-Arab",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.921854,
        "recall": 0.94664,
        "f1": 0.929908,
        "accuracy": 0.94664,
        "main_score": 0.929908,
        "hf_subset": "ary_Arab-ast_Latn",
        "languages": [
          "ary-Arab",
          "ast-Latn"
        ]
      },
      {
        "precision": 0.729348,
        "recall": 0.802372,
        "f1": 0.751139,
        "accuracy": 0.802372,
        "main_score": 0.751139,
        "hf_subset": "ary_Arab-crh_Latn",
        "languages": [
          "ary-Arab",
          "crh-Latn"
        ]
      },
      {
        "precision": 0.968874,
        "recall": 0.978261,
        "f1": 0.971838,
        "accuracy": 0.978261,
        "main_score": 0.971838,
        "hf_subset": "ary_Arab-glg_Latn",
        "languages": [
          "ary-Arab",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.309873,
        "recall": 0.412055,
        "f1": 0.334934,
        "accuracy": 0.412055,
        "main_score": 0.334934,
        "hf_subset": "ary_Arab-kas_Deva",
        "languages": [
          "ary-Arab",
          "kas-Deva"
        ]
      },
      {
        "precision": 0.537427,
        "recall": 0.634387,
        "f1": 0.56397,
        "accuracy": 0.634387,
        "main_score": 0.56397,
        "hf_subset": "ary_Arab-ltz_Latn",
        "languages": [
          "ary-Arab",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.094037,
        "recall": 0.171937,
        "f1": 0.108261,
        "accuracy": 0.171937,
        "main_score": 0.108261,
        "hf_subset": "ary_Arab-nus_Latn",
        "languages": [
          "ary-Arab",
          "nus-Latn"
        ]
      },
      {
        "precision": 0.966733,
        "recall": 0.977273,
        "f1": 0.970191,
        "accuracy": 0.977273,
        "main_score": 0.970191,
        "hf_subset": "ary_Arab-slk_Latn",
        "languages": [
          "ary-Arab",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.264069,
        "recall": 0.357708,
        "f1": 0.285742,
        "accuracy": 0.357708,
        "main_score": 0.285742,
        "hf_subset": "ary_Arab-tir_Ethi",
        "languages": [
          "ary-Arab",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.956522,
        "recall": 0.969368,
        "f1": 0.960639,
        "accuracy": 0.969368,
        "main_score": 0.960639,
        "hf_subset": "ary_Arab-zho_Hant",
        "languages": [
          "ary-Arab",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.893314,
        "recall": 0.923913,
        "f1": 0.903162,
        "accuracy": 0.923913,
        "main_score": 0.903162,
        "hf_subset": "ary_Arab-awa_Deva",
        "languages": [
          "ary-Arab",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.861825,
        "recall": 0.90415,
        "f1": 0.875494,
        "accuracy": 0.90415,
        "main_score": 0.875494,
        "hf_subset": "ary_Arab-cym_Latn",
        "languages": [
          "ary-Arab",
          "cym-Latn"
        ]
      },
      {
        "precision": 0.300065,
        "recall": 0.413043,
        "f1": 0.327082,
        "accuracy": 0.413043,
        "main_score": 0.327082,
        "hf_subset": "ary_Arab-grn_Latn",
        "languages": [
          "ary-Arab",
          "grn-Latn"
        ]
      },
      {
        "precision": 0.930171,
        "recall": 0.950593,
        "f1": 0.936594,
        "accuracy": 0.950593,
        "main_score": 0.936594,
        "hf_subset": "ary_Arab-kat_Geor",
        "languages": [
          "ary-Arab",
          "kat-Geor"
        ]
      },
      {
        "precision": 0.223979,
        "recall": 0.33004,
        "f1": 0.24739,
        "accuracy": 0.33004,
        "main_score": 0.24739,
        "hf_subset": "ary_Arab-lua_Latn",
        "languages": [
          "ary-Arab",
          "lua-Latn"
        ]
      },
      {
        "precision": 0.183202,
        "recall": 0.282609,
        "f1": 0.204454,
        "accuracy": 0.282609,
        "main_score": 0.204454,
        "hf_subset": "ary_Arab-nya_Latn",
        "languages": [
          "ary-Arab",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.95191,
        "recall": 0.967391,
        "f1": 0.957016,
        "accuracy": 0.967391,
        "main_score": 0.957016,
        "hf_subset": "ary_Arab-slv_Latn",
        "languages": [
          "ary-Arab",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.320887,
        "recall": 0.445652,
        "f1": 0.352551,
        "accuracy": 0.445652,
        "main_score": 0.352551,
        "hf_subset": "ary_Arab-tpi_Latn",
        "languages": [
          "ary-Arab",
          "tpi-Latn"
        ]
      },
      {
        "precision": 0.967062,
        "recall": 0.977273,
        "f1": 0.970356,
        "accuracy": 0.977273,
        "main_score": 0.970356,
        "hf_subset": "ary_Arab-zsm_Latn",
        "languages": [
          "ary-Arab",
          "zsm-Latn"
        ]
      },
      {
        "precision": 0.149132,
        "recall": 0.242095,
        "f1": 0.168017,
        "accuracy": 0.242095,
        "main_score": 0.168017,
        "hf_subset": "ary_Arab-ayr_Latn",
        "languages": [
          "ary-Arab",
          "ayr-Latn"
        ]
      },
      {
        "precision": 0.968544,
        "recall": 0.978261,
        "f1": 0.971673,
        "accuracy": 0.978261,
        "main_score": 0.971673,
        "hf_subset": "ary_Arab-dan_Latn",
        "languages": [
          "ary-Arab",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.910903,
        "recall": 0.937747,
        "f1": 0.919433,
        "accuracy": 0.937747,
        "main_score": 0.919433,
        "hf_subset": "ary_Arab-guj_Gujr",
        "languages": [
          "ary-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.933169,
        "recall": 0.952569,
        "f1": 0.939196,
        "accuracy": 0.952569,
        "main_score": 0.939196,
        "hf_subset": "ary_Arab-kaz_Cyrl",
        "languages": [
          "ary-Arab",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.161782,
        "recall": 0.250988,
        "f1": 0.180385,
        "accuracy": 0.250988,
        "main_score": 0.180385,
        "hf_subset": "ary_Arab-lug_Latn",
        "languages": [
          "ary-Arab",
          "lug-Latn"
        ]
      },
      {
        "precision": 0.908514,
        "recall": 0.936759,
        "f1": 0.917556,
        "accuracy": 0.936759,
        "main_score": 0.917556,
        "hf_subset": "ary_Arab-oci_Latn",
        "languages": [
          "ary-Arab",
          "oci-Latn"
        ]
      },
      {
        "precision": 0.155131,
        "recall": 0.247036,
        "f1": 0.173873,
        "accuracy": 0.247036,
        "main_score": 0.173873,
        "hf_subset": "ary_Arab-smo_Latn",
        "languages": [
          "ary-Arab",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.164501,
        "recall": 0.264822,
        "f1": 0.186097,
        "accuracy": 0.264822,
        "main_score": 0.186097,
        "hf_subset": "ary_Arab-tsn_Latn",
        "languages": [
          "ary-Arab",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.233439,
        "recall": 0.333004,
        "f1": 0.255611,
        "accuracy": 0.333004,
        "main_score": 0.255611,
        "hf_subset": "ary_Arab-zul_Latn",
        "languages": [
          "ary-Arab",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.358552,
        "recall": 0.476285,
        "f1": 0.388396,
        "accuracy": 0.476285,
        "main_score": 0.388396,
        "hf_subset": "ary_Arab-azb_Arab",
        "languages": [
          "ary-Arab",
          "azb-Arab"
        ]
      },
      {
        "precision": 0.972991,
        "recall": 0.981225,
        "f1": 0.975626,
        "accuracy": 0.981225,
        "main_score": 0.975626,
        "hf_subset": "ary_Arab-deu_Latn",
        "languages": [
          "ary-Arab",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.248299,
        "recall": 0.359684,
        "f1": 0.274387,
        "accuracy": 0.359684,
        "main_score": 0.274387,
        "hf_subset": "ary_Arab-hat_Latn",
        "languages": [
          "ary-Arab",
          "hat-Latn"
        ]
      },
      {
        "precision": 0.137976,
        "recall": 0.225296,
        "f1": 0.155398,
        "accuracy": 0.225296,
        "main_score": 0.155398,
        "hf_subset": "ary_Arab-kbp_Latn",
        "languages": [
          "ary-Arab",
          "kbp-Latn"
        ]
      },
      {
        "precision": 0.166465,
        "recall": 0.257905,
        "f1": 0.184993,
        "accuracy": 0.257905,
        "main_score": 0.184993,
        "hf_subset": "ary_Arab-luo_Latn",
        "languages": [
          "ary-Arab",
          "luo-Latn"
        ]
      },
      {
        "precision": 0.893281,
        "recall": 0.926877,
        "f1": 0.90415,
        "accuracy": 0.926877,
        "main_score": 0.90415,
        "hf_subset": "ary_Arab-ory_Orya",
        "languages": [
          "ary-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.138115,
        "recall": 0.235178,
        "f1": 0.157192,
        "accuracy": 0.235178,
        "main_score": 0.157192,
        "hf_subset": "ary_Arab-sna_Latn",
        "languages": [
          "ary-Arab",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.140633,
        "recall": 0.248024,
        "f1": 0.162906,
        "accuracy": 0.248024,
        "main_score": 0.162906,
        "hf_subset": "ary_Arab-tso_Latn",
        "languages": [
          "ary-Arab",
          "tso-Latn"
        ]
      },
      {
        "precision": 0.945817,
        "recall": 0.962451,
        "f1": 0.951087,
        "accuracy": 0.962451,
        "main_score": 0.951087,
        "hf_subset": "ary_Arab-azj_Latn",
        "languages": [
          "ary-Arab",
          "azj-Latn"
        ]
      },
      {
        "precision": 0.173907,
        "recall": 0.280632,
        "f1": 0.197213,
        "accuracy": 0.280632,
        "main_score": 0.197213,
        "hf_subset": "ary_Arab-dik_Latn",
        "languages": [
          "ary-Arab",
          "dik-Latn"
        ]
      },
      {
        "precision": 0.496592,
        "recall": 0.612648,
        "f1": 0.52877,
        "accuracy": 0.612648,
        "main_score": 0.52877,
        "hf_subset": "ary_Arab-hau_Latn",
        "languages": [
          "ary-Arab",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.625202,
        "recall": 0.715415,
        "f1": 0.650793,
        "accuracy": 0.715415,
        "main_score": 0.650793,
        "hf_subset": "ary_Arab-kea_Latn",
        "languages": [
          "ary-Arab",
          "kea-Latn"
        ]
      },
      {
        "precision": 0.258845,
        "recall": 0.370553,
        "f1": 0.284453,
        "accuracy": 0.370553,
        "main_score": 0.284453,
        "hf_subset": "ary_Arab-lus_Latn",
        "languages": [
          "ary-Arab",
          "lus-Latn"
        ]
      },
      {
        "precision": 0.430958,
        "recall": 0.538538,
        "f1": 0.459649,
        "accuracy": 0.538538,
        "main_score": 0.459649,
        "hf_subset": "ary_Arab-pag_Latn",
        "languages": [
          "ary-Arab",
          "pag-Latn"
        ]
      },
      {
        "precision": 0.854249,
        "recall": 0.897233,
        "f1": 0.868003,
        "accuracy": 0.897233,
        "main_score": 0.868003,
        "hf_subset": "ary_Arab-snd_Arab",
        "languages": [
          "ary-Arab",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.318635,
        "recall": 0.429842,
        "f1": 0.34547,
        "accuracy": 0.429842,
        "main_score": 0.34547,
        "hf_subset": "ary_Arab-tuk_Latn",
        "languages": [
          "ary-Arab",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.392092,
        "recall": 0.501976,
        "f1": 0.421374,
        "accuracy": 0.501976,
        "main_score": 0.421374,
        "hf_subset": "ary_Arab-bak_Cyrl",
        "languages": [
          "ary-Arab",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.116338,
        "recall": 0.203557,
        "f1": 0.133636,
        "accuracy": 0.203557,
        "main_score": 0.133636,
        "hf_subset": "ary_Arab-dyu_Latn",
        "languages": [
          "ary-Arab",
          "dyu-Latn"
        ]
      },
      {
        "precision": 0.948123,
        "recall": 0.964427,
        "f1": 0.953393,
        "accuracy": 0.964427,
        "main_score": 0.953393,
        "hf_subset": "ary_Arab-heb_Hebr",
        "languages": [
          "ary-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.890069,
        "recall": 0.922925,
        "f1": 0.900593,
        "accuracy": 0.922925,
        "main_score": 0.900593,
        "hf_subset": "ary_Arab-khk_Cyrl",
        "languages": [
          "ary-Arab",
          "khk-Cyrl"
        ]
      },
      {
        "precision": 0.948534,
        "recall": 0.964427,
        "f1": 0.953623,
        "accuracy": 0.964427,
        "main_score": 0.953623,
        "hf_subset": "ary_Arab-lvs_Latn",
        "languages": [
          "ary-Arab",
          "lvs-Latn"
        ]
      },
      {
        "precision": 0.857905,
        "recall": 0.898221,
        "f1": 0.870191,
        "accuracy": 0.898221,
        "main_score": 0.870191,
        "hf_subset": "ary_Arab-pan_Guru",
        "languages": [
          "ary-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.534964,
        "recall": 0.637352,
        "f1": 0.563176,
        "accuracy": 0.637352,
        "main_score": 0.563176,
        "hf_subset": "ary_Arab-som_Latn",
        "languages": [
          "ary-Arab",
          "som-Latn"
        ]
      },
      {
        "precision": 0.165863,
        "recall": 0.26581,
        "f1": 0.186884,
        "accuracy": 0.26581,
        "main_score": 0.186884,
        "hf_subset": "ary_Arab-tum_Latn",
        "languages": [
          "ary-Arab",
          "tum-Latn"
        ]
      },
      {
        "precision": 0.969368,
        "recall": 0.979249,
        "f1": 0.972661,
        "accuracy": 0.979249,
        "main_score": 0.972661,
        "hf_subset": "ces_Latn-ary_Arab",
        "languages": [
          "ces-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.234479,
        "recall": 0.281621,
        "f1": 0.245178,
        "accuracy": 0.281621,
        "main_score": 0.245178,
        "hf_subset": "gaz_Latn-ary_Arab",
        "languages": [
          "gaz-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.196948,
        "recall": 0.246047,
        "f1": 0.207866,
        "accuracy": 0.246047,
        "main_score": 0.207866,
        "hf_subset": "kam_Latn-ary_Arab",
        "languages": [
          "kam-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.951416,
        "recall": 0.966403,
        "f1": 0.956357,
        "accuracy": 0.966403,
        "main_score": 0.956357,
        "hf_subset": "lit_Latn-ary_Arab",
        "languages": [
          "lit-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.973814,
        "recall": 0.982213,
        "f1": 0.976614,
        "accuracy": 0.982213,
        "main_score": 0.976614,
        "hf_subset": "nob_Latn-ary_Arab",
        "languages": [
          "nob-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.627381,
        "recall": 0.698617,
        "f1": 0.647759,
        "accuracy": 0.698617,
        "main_score": 0.647759,
        "hf_subset": "scn_Latn-ary_Arab",
        "languages": [
          "scn-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.193739,
        "recall": 0.243083,
        "f1": 0.20533,
        "accuracy": 0.243083,
        "main_score": 0.20533,
        "hf_subset": "tgk_Cyrl-ary_Arab",
        "languages": [
          "tgk-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.162201,
        "recall": 0.199605,
        "f1": 0.170852,
        "accuracy": 0.199605,
        "main_score": 0.170852,
        "hf_subset": "yor_Latn-ary_Arab",
        "languages": [
          "yor-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.962945,
        "recall": 0.975296,
        "f1": 0.967062,
        "accuracy": 0.975296,
        "main_score": 0.967062,
        "hf_subset": "arz_Arab-ary_Arab",
        "languages": [
          "arz-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.177993,
        "recall": 0.222332,
        "f1": 0.187721,
        "accuracy": 0.222332,
        "main_score": 0.187721,
        "hf_subset": "cjk_Latn-ary_Arab",
        "languages": [
          "cjk-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.584508,
        "recall": 0.651186,
        "f1": 0.602644,
        "accuracy": 0.651186,
        "main_score": 0.602644,
        "hf_subset": "gla_Latn-ary_Arab",
        "languages": [
          "gla-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.943594,
        "recall": 0.960474,
        "f1": 0.949012,
        "accuracy": 0.960474,
        "main_score": 0.949012,
        "hf_subset": "kan_Knda-ary_Arab",
        "languages": [
          "kan-Knda",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.65764,
        "recall": 0.719368,
        "f1": 0.674588,
        "accuracy": 0.719368,
        "main_score": 0.674588,
        "hf_subset": "lmo_Latn-ary_Arab",
        "languages": [
          "lmo-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.935639,
        "recall": 0.954545,
        "f1": 0.9417,
        "accuracy": 0.954545,
        "main_score": 0.9417,
        "hf_subset": "npi_Deva-ary_Arab",
        "languages": [
          "npi-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.19651,
        "recall": 0.23913,
        "f1": 0.206783,
        "accuracy": 0.23913,
        "main_score": 0.206783,
        "hf_subset": "shn_Mymr-ary_Arab",
        "languages": [
          "shn-Mymr",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.936924,
        "recall": 0.955534,
        "f1": 0.943017,
        "accuracy": 0.955534,
        "main_score": 0.943017,
        "hf_subset": "tgl_Latn-ary_Arab",
        "languages": [
          "tgl-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.961957,
        "recall": 0.974308,
        "f1": 0.966074,
        "accuracy": 0.974308,
        "main_score": 0.966074,
        "hf_subset": "yue_Hant-ary_Arab",
        "languages": [
          "yue-Hant",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.767715,
        "recall": 0.829051,
        "f1": 0.786415,
        "accuracy": 0.829051,
        "main_score": 0.786415,
        "hf_subset": "asm_Beng-ary_Arab",
        "languages": [
          "asm-Beng",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.06345,
        "recall": 0.090909,
        "f1": 0.068813,
        "accuracy": 0.090909,
        "main_score": 0.068813,
        "hf_subset": "ckb_Arab-ary_Arab",
        "languages": [
          "ckb-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.765219,
        "recall": 0.81917,
        "f1": 0.781573,
        "accuracy": 0.81917,
        "main_score": 0.781573,
        "hf_subset": "gle_Latn-ary_Arab",
        "languages": [
          "gle-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.391948,
        "recall": 0.461462,
        "f1": 0.40974,
        "accuracy": 0.461462,
        "main_score": 0.40974,
        "hf_subset": "kas_Arab-ary_Arab",
        "languages": [
          "kas-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.4481,
        "recall": 0.52668,
        "f1": 0.468923,
        "accuracy": 0.52668,
        "main_score": 0.468923,
        "hf_subset": "ltg_Latn-ary_Arab",
        "languages": [
          "ltg-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.189297,
        "recall": 0.233202,
        "f1": 0.199362,
        "accuracy": 0.233202,
        "main_score": 0.199362,
        "hf_subset": "nso_Latn-ary_Arab",
        "languages": [
          "nso-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.931324,
        "recall": 0.951581,
        "f1": 0.937912,
        "accuracy": 0.951581,
        "main_score": 0.937912,
        "hf_subset": "sin_Sinh-ary_Arab",
        "languages": [
          "sin-Sinh",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.967391,
        "recall": 0.978261,
        "f1": 0.971014,
        "accuracy": 0.978261,
        "main_score": 0.971014,
        "hf_subset": "tha_Thai-ary_Arab",
        "languages": [
          "tha-Thai",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.967391,
        "recall": 0.978261,
        "f1": 0.971014,
        "accuracy": 0.978261,
        "main_score": 0.971014,
        "hf_subset": "zho_Hans-ary_Arab",
        "languages": [
          "zho-Hans",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.942111,
        "recall": 0.959486,
        "f1": 0.947694,
        "accuracy": 0.959486,
        "main_score": 0.947694,
        "hf_subset": "ast_Latn-ary_Arab",
        "languages": [
          "ast-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.764443,
        "recall": 0.821146,
        "f1": 0.781697,
        "accuracy": 0.821146,
        "main_score": 0.781697,
        "hf_subset": "crh_Latn-ary_Arab",
        "languages": [
          "crh-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.970356,
        "recall": 0.979249,
        "f1": 0.97332,
        "accuracy": 0.979249,
        "main_score": 0.97332,
        "hf_subset": "glg_Latn-ary_Arab",
        "languages": [
          "glg-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.34824,
        "recall": 0.408103,
        "f1": 0.362898,
        "accuracy": 0.408103,
        "main_score": 0.362898,
        "hf_subset": "kas_Deva-ary_Arab",
        "languages": [
          "kas-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.579365,
        "recall": 0.65415,
        "f1": 0.600047,
        "accuracy": 0.65415,
        "main_score": 0.600047,
        "hf_subset": "ltz_Latn-ary_Arab",
        "languages": [
          "ltz-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.104256,
        "recall": 0.13834,
        "f1": 0.111399,
        "accuracy": 0.13834,
        "main_score": 0.111399,
        "hf_subset": "nus_Latn-ary_Arab",
        "languages": [
          "nus-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.97085,
        "recall": 0.980237,
        "f1": 0.973979,
        "accuracy": 0.980237,
        "main_score": 0.973979,
        "hf_subset": "slk_Latn-ary_Arab",
        "languages": [
          "slk-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.239273,
        "recall": 0.297431,
        "f1": 0.252957,
        "accuracy": 0.297431,
        "main_score": 0.252957,
        "hf_subset": "tir_Ethi-ary_Arab",
        "languages": [
          "tir-Ethi",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.964921,
        "recall": 0.976285,
        "f1": 0.968709,
        "accuracy": 0.976285,
        "main_score": 0.968709,
        "hf_subset": "zho_Hant-ary_Arab",
        "languages": [
          "zho-Hant",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.9389,
        "recall": 0.95751,
        "f1": 0.944829,
        "accuracy": 0.95751,
        "main_score": 0.944829,
        "hf_subset": "awa_Deva-ary_Arab",
        "languages": [
          "awa-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.90196,
        "recall": 0.929842,
        "f1": 0.910804,
        "accuracy": 0.929842,
        "main_score": 0.910804,
        "hf_subset": "cym_Latn-ary_Arab",
        "languages": [
          "cym-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.29635,
        "recall": 0.363636,
        "f1": 0.311306,
        "accuracy": 0.363636,
        "main_score": 0.311306,
        "hf_subset": "grn_Latn-ary_Arab",
        "languages": [
          "grn-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.947299,
        "recall": 0.964427,
        "f1": 0.952899,
        "accuracy": 0.964427,
        "main_score": 0.952899,
        "hf_subset": "kat_Geor-ary_Arab",
        "languages": [
          "kat-Geor",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.248388,
        "recall": 0.304348,
        "f1": 0.260977,
        "accuracy": 0.304348,
        "main_score": 0.260977,
        "hf_subset": "lua_Latn-ary_Arab",
        "languages": [
          "lua-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.200589,
        "recall": 0.253953,
        "f1": 0.211516,
        "accuracy": 0.253953,
        "main_score": 0.211516,
        "hf_subset": "nya_Latn-ary_Arab",
        "languages": [
          "nya-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.961957,
        "recall": 0.97332,
        "f1": 0.965744,
        "accuracy": 0.97332,
        "main_score": 0.965744,
        "hf_subset": "slv_Latn-ary_Arab",
        "languages": [
          "slv-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.406064,
        "recall": 0.453557,
        "f1": 0.418553,
        "accuracy": 0.453557,
        "main_score": 0.418553,
        "hf_subset": "tpi_Latn-ary_Arab",
        "languages": [
          "tpi-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.968379,
        "recall": 0.978261,
        "f1": 0.971673,
        "accuracy": 0.978261,
        "main_score": 0.971673,
        "hf_subset": "zsm_Latn-ary_Arab",
        "languages": [
          "zsm-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.171832,
        "recall": 0.214427,
        "f1": 0.181269,
        "accuracy": 0.214427,
        "main_score": 0.181269,
        "hf_subset": "ayr_Latn-ary_Arab",
        "languages": [
          "ayr-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.978261,
        "recall": 0.985178,
        "f1": 0.980567,
        "accuracy": 0.985178,
        "main_score": 0.980567,
        "hf_subset": "dan_Latn-ary_Arab",
        "languages": [
          "dan-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.932395,
        "recall": 0.953557,
        "f1": 0.939295,
        "accuracy": 0.953557,
        "main_score": 0.939295,
        "hf_subset": "guj_Gujr-ary_Arab",
        "languages": [
          "guj-Gujr",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.95751,
        "recall": 0.971344,
        "f1": 0.962121,
        "accuracy": 0.971344,
        "main_score": 0.962121,
        "hf_subset": "kaz_Cyrl-ary_Arab",
        "languages": [
          "kaz-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.16057,
        "recall": 0.213439,
        "f1": 0.17072,
        "accuracy": 0.213439,
        "main_score": 0.17072,
        "hf_subset": "lug_Latn-ary_Arab",
        "languages": [
          "lug-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.934947,
        "recall": 0.954545,
        "f1": 0.94137,
        "accuracy": 0.954545,
        "main_score": 0.94137,
        "hf_subset": "oci_Latn-ary_Arab",
        "languages": [
          "oci-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.178506,
        "recall": 0.219368,
        "f1": 0.18829,
        "accuracy": 0.219368,
        "main_score": 0.18829,
        "hf_subset": "smo_Latn-ary_Arab",
        "languages": [
          "smo-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.192708,
        "recall": 0.233202,
        "f1": 0.202062,
        "accuracy": 0.233202,
        "main_score": 0.202062,
        "hf_subset": "tsn_Latn-ary_Arab",
        "languages": [
          "tsn-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.258349,
        "recall": 0.315217,
        "f1": 0.270578,
        "accuracy": 0.315217,
        "main_score": 0.270578,
        "hf_subset": "zul_Latn-ary_Arab",
        "languages": [
          "zul-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.389869,
        "recall": 0.466403,
        "f1": 0.409493,
        "accuracy": 0.466403,
        "main_score": 0.409493,
        "hf_subset": "azb_Arab-ary_Arab",
        "languages": [
          "azb-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.977767,
        "recall": 0.985178,
        "f1": 0.980237,
        "accuracy": 0.985178,
        "main_score": 0.980237,
        "hf_subset": "deu_Latn-ary_Arab",
        "languages": [
          "deu-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.312386,
        "recall": 0.37253,
        "f1": 0.326974,
        "accuracy": 0.37253,
        "main_score": 0.326974,
        "hf_subset": "hat_Latn-ary_Arab",
        "languages": [
          "hat-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.155518,
        "recall": 0.192688,
        "f1": 0.164856,
        "accuracy": 0.192688,
        "main_score": 0.164856,
        "hf_subset": "kbp_Latn-ary_Arab",
        "languages": [
          "kbp-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.192953,
        "recall": 0.241107,
        "f1": 0.203708,
        "accuracy": 0.241107,
        "main_score": 0.203708,
        "hf_subset": "luo_Latn-ary_Arab",
        "languages": [
          "luo-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.916206,
        "recall": 0.940711,
        "f1": 0.924078,
        "accuracy": 0.940711,
        "main_score": 0.924078,
        "hf_subset": "ory_Orya-ary_Arab",
        "languages": [
          "ory-Orya",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.156001,
        "recall": 0.1917,
        "f1": 0.163157,
        "accuracy": 0.1917,
        "main_score": 0.163157,
        "hf_subset": "sna_Latn-ary_Arab",
        "languages": [
          "sna-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.190832,
        "recall": 0.228261,
        "f1": 0.19849,
        "accuracy": 0.228261,
        "main_score": 0.19849,
        "hf_subset": "tso_Latn-ary_Arab",
        "languages": [
          "tso-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.949111,
        "recall": 0.964427,
        "f1": 0.954216,
        "accuracy": 0.964427,
        "main_score": 0.954216,
        "hf_subset": "azj_Latn-ary_Arab",
        "languages": [
          "azj-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.205431,
        "recall": 0.264822,
        "f1": 0.219742,
        "accuracy": 0.264822,
        "main_score": 0.219742,
        "hf_subset": "dik_Latn-ary_Arab",
        "languages": [
          "dik-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.566183,
        "recall": 0.629447,
        "f1": 0.582745,
        "accuracy": 0.629447,
        "main_score": 0.582745,
        "hf_subset": "hau_Latn-ary_Arab",
        "languages": [
          "hau-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.68086,
        "recall": 0.75,
        "f1": 0.70101,
        "accuracy": 0.75,
        "main_score": 0.70101,
        "hf_subset": "kea_Latn-ary_Arab",
        "languages": [
          "kea-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.279539,
        "recall": 0.331028,
        "f1": 0.292359,
        "accuracy": 0.331028,
        "main_score": 0.292359,
        "hf_subset": "lus_Latn-ary_Arab",
        "languages": [
          "lus-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.446937,
        "recall": 0.516798,
        "f1": 0.465233,
        "accuracy": 0.516798,
        "main_score": 0.465233,
        "hf_subset": "pag_Latn-ary_Arab",
        "languages": [
          "pag-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.896443,
        "recall": 0.925889,
        "f1": 0.905632,
        "accuracy": 0.925889,
        "main_score": 0.905632,
        "hf_subset": "snd_Arab-ary_Arab",
        "languages": [
          "snd-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.33675,
        "recall": 0.405138,
        "f1": 0.354157,
        "accuracy": 0.405138,
        "main_score": 0.354157,
        "hf_subset": "tuk_Latn-ary_Arab",
        "languages": [
          "tuk-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.421921,
        "recall": 0.493083,
        "f1": 0.44172,
        "accuracy": 0.493083,
        "main_score": 0.44172,
        "hf_subset": "bak_Cyrl-ary_Arab",
        "languages": [
          "bak-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.14481,
        "recall": 0.184783,
        "f1": 0.153277,
        "accuracy": 0.184783,
        "main_score": 0.153277,
        "hf_subset": "dyu_Latn-ary_Arab",
        "languages": [
          "dyu-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.972826,
        "recall": 0.981225,
        "f1": 0.975626,
        "accuracy": 0.981225,
        "main_score": 0.975626,
        "hf_subset": "heb_Hebr-ary_Arab",
        "languages": [
          "heb-Hebr",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.919549,
        "recall": 0.944664,
        "f1": 0.927767,
        "accuracy": 0.944664,
        "main_score": 0.927767,
        "hf_subset": "khk_Cyrl-ary_Arab",
        "languages": [
          "khk-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.957839,
        "recall": 0.971344,
        "f1": 0.962286,
        "accuracy": 0.971344,
        "main_score": 0.962286,
        "hf_subset": "lvs_Latn-ary_Arab",
        "languages": [
          "lvs-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.868775,
        "recall": 0.906126,
        "f1": 0.880731,
        "accuracy": 0.906126,
        "main_score": 0.880731,
        "hf_subset": "pan_Guru-ary_Arab",
        "languages": [
          "pan-Guru",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.569783,
        "recall": 0.636364,
        "f1": 0.588028,
        "accuracy": 0.636364,
        "main_score": 0.588028,
        "hf_subset": "som_Latn-ary_Arab",
        "languages": [
          "som-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.172642,
        "recall": 0.222332,
        "f1": 0.182415,
        "accuracy": 0.222332,
        "main_score": 0.182415,
        "hf_subset": "tum_Latn-ary_Arab",
        "languages": [
          "tum-Latn",
          "ary-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 928.817741394043,
  "kg_co2_emissions": null
}