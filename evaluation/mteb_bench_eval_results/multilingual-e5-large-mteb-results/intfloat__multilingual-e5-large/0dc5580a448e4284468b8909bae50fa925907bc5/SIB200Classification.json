{
  "dataset_revision": "a74d7350ea12af010cfb1c21e34f1f81fd2e615b",
  "task_name": "SIB200Classification",
  "mteb_version": "1.34.22",
  "scores": {
    "train": [
      {
        "accuracy": 0.673324,
        "f1": 0.65913,
        "f1_weighted": 0.673144,
        "scores_per_experiment": [
          {
            "accuracy": 0.680456,
            "f1": 0.668762,
            "f1_weighted": 0.687493
          },
          {
            "accuracy": 0.666191,
            "f1": 0.654266,
            "f1_weighted": 0.66833
          },
          {
            "accuracy": 0.629101,
            "f1": 0.622226,
            "f1_weighted": 0.619964
          },
          {
            "accuracy": 0.691869,
            "f1": 0.671377,
            "f1_weighted": 0.690264
          },
          {
            "accuracy": 0.686163,
            "f1": 0.667583,
            "f1_weighted": 0.686721
          },
          {
            "accuracy": 0.710414,
            "f1": 0.697098,
            "f1_weighted": 0.712182
          },
          {
            "accuracy": 0.669044,
            "f1": 0.653981,
            "f1_weighted": 0.671035
          },
          {
            "accuracy": 0.660485,
            "f1": 0.644999,
            "f1_weighted": 0.659195
          },
          {
            "accuracy": 0.649073,
            "f1": 0.633212,
            "f1_weighted": 0.646302
          },
          {
            "accuracy": 0.690442,
            "f1": 0.677799,
            "f1_weighted": 0.68995
          }
        ],
        "main_score": 0.673324,
        "hf_subset": "ary_Arab",
        "languages": [
          "ary-Arab"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.621212,
        "f1": 0.601789,
        "f1_weighted": 0.623573,
        "scores_per_experiment": [
          {
            "accuracy": 0.666667,
            "f1": 0.662605,
            "f1_weighted": 0.677874
          },
          {
            "accuracy": 0.616162,
            "f1": 0.605201,
            "f1_weighted": 0.614218
          },
          {
            "accuracy": 0.565657,
            "f1": 0.573204,
            "f1_weighted": 0.568969
          },
          {
            "accuracy": 0.717172,
            "f1": 0.697182,
            "f1_weighted": 0.715186
          },
          {
            "accuracy": 0.59596,
            "f1": 0.548876,
            "f1_weighted": 0.595593
          },
          {
            "accuracy": 0.636364,
            "f1": 0.614585,
            "f1_weighted": 0.644535
          },
          {
            "accuracy": 0.59596,
            "f1": 0.567477,
            "f1_weighted": 0.606237
          },
          {
            "accuracy": 0.616162,
            "f1": 0.589292,
            "f1_weighted": 0.611499
          },
          {
            "accuracy": 0.585859,
            "f1": 0.568837,
            "f1_weighted": 0.577207
          },
          {
            "accuracy": 0.616162,
            "f1": 0.590626,
            "f1_weighted": 0.624412
          }
        ],
        "main_score": 0.621212,
        "hf_subset": "ary_Arab",
        "languages": [
          "ary-Arab"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.689706,
        "f1": 0.665529,
        "f1_weighted": 0.68513,
        "scores_per_experiment": [
          {
            "accuracy": 0.70098,
            "f1": 0.679085,
            "f1_weighted": 0.700918
          },
          {
            "accuracy": 0.691176,
            "f1": 0.667191,
            "f1_weighted": 0.691657
          },
          {
            "accuracy": 0.666667,
            "f1": 0.649905,
            "f1_weighted": 0.650842
          },
          {
            "accuracy": 0.686275,
            "f1": 0.650004,
            "f1_weighted": 0.68228
          },
          {
            "accuracy": 0.720588,
            "f1": 0.703166,
            "f1_weighted": 0.720091
          },
          {
            "accuracy": 0.691176,
            "f1": 0.657307,
            "f1_weighted": 0.688651
          },
          {
            "accuracy": 0.671569,
            "f1": 0.642228,
            "f1_weighted": 0.668441
          },
          {
            "accuracy": 0.686275,
            "f1": 0.678326,
            "f1_weighted": 0.68086
          },
          {
            "accuracy": 0.666667,
            "f1": 0.629556,
            "f1_weighted": 0.650544
          },
          {
            "accuracy": 0.715686,
            "f1": 0.698527,
            "f1_weighted": 0.717019
          }
        ],
        "main_score": 0.689706,
        "hf_subset": "ary_Arab",
        "languages": [
          "ary-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 31.68045163154602,
  "kg_co2_emissions": null
}