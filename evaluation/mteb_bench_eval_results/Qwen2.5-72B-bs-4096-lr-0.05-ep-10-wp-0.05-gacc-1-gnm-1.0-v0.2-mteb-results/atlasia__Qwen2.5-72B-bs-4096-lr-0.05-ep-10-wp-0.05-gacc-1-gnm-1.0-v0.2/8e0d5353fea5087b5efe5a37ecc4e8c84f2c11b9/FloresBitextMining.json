{
  "dataset_revision": "e6b647fcb6299a2f686f742f4d4c023e553ea67e",
  "task_name": "FloresBitextMining",
  "mteb_version": "1.34.22",
  "scores": {
    "devtest": [
      {
        "precision": 0.013834,
        "recall": 0.024704,
        "f1": 0.015713,
        "accuracy": 0.024704,
        "main_score": 0.015713,
        "hf_subset": "ace_Arab-ary_Arab",
        "languages": [
          "ace-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.017886,
        "recall": 0.028656,
        "f1": 0.019267,
        "accuracy": 0.028656,
        "main_score": 0.019267,
        "hf_subset": "bam_Latn-ary_Arab",
        "languages": [
          "bam-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 2e-06,
        "accuracy": 0.000988,
        "main_score": 2e-06,
        "hf_subset": "dzo_Tibt-ary_Arab",
        "languages": [
          "dzo-Tibt",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.000993,
        "recall": 0.002964,
        "f1": 0.000998,
        "accuracy": 0.002964,
        "main_score": 0.000998,
        "hf_subset": "hin_Deva-ary_Arab",
        "languages": [
          "hin-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.000989,
        "recall": 0.001976,
        "f1": 0.00099,
        "accuracy": 0.001976,
        "main_score": 0.00099,
        "hf_subset": "khm_Khmr-ary_Arab",
        "languages": [
          "khm-Khmr",
          "ary-Arab"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000988,
        "f1": 3e-06,
        "accuracy": 0.000988,
        "main_score": 3e-06,
        "hf_subset": "mag_Deva-ary_Arab",
        "languages": [
          "mag-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.063433,
        "recall": 0.093874,
        "f1": 0.069227,
        "accuracy": 0.093874,
        "main_score": 0.069227,
        "hf_subset": "pap_Latn-ary_Arab",
        "languages": [
          "pap-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.030323,
        "recall": 0.045455,
        "f1": 0.032914,
        "accuracy": 0.045455,
        "main_score": 0.032914,
        "hf_subset": "sot_Latn-ary_Arab",
        "languages": [
          "sot-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.041359,
        "recall": 0.068182,
        "f1": 0.04744,
        "accuracy": 0.068182,
        "main_score": 0.04744,
        "hf_subset": "tur_Latn-ary_Arab",
        "languages": [
          "tur-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.034419,
        "recall": 0.052372,
        "f1": 0.037477,
        "accuracy": 0.052372,
        "main_score": 0.037477,
        "hf_subset": "ace_Latn-ary_Arab",
        "languages": [
          "ace-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.042643,
        "recall": 0.061265,
        "f1": 0.046323,
        "accuracy": 0.061265,
        "main_score": 0.046323,
        "hf_subset": "ban_Latn-ary_Arab",
        "languages": [
          "ban-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.000989,
        "recall": 0.001976,
        "f1": 0.00099,
        "accuracy": 0.001976,
        "main_score": 0.00099,
        "hf_subset": "ell_Grek-ary_Arab",
        "languages": [
          "ell-Grek",
          "ary-Arab"
        ]
      },
      {
        "precision": 4e-06,
        "recall": 0.001976,
        "f1": 8e-06,
        "accuracy": 0.001976,
        "main_score": 8e-06,
        "hf_subset": "hne_Deva-ary_Arab",
        "languages": [
          "hne-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.031874,
        "recall": 0.048419,
        "f1": 0.034383,
        "accuracy": 0.048419,
        "main_score": 0.034383,
        "hf_subset": "kik_Latn-ary_Arab",
        "languages": [
          "kik-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000988,
        "f1": 3e-06,
        "accuracy": 0.000988,
        "main_score": 3e-06,
        "hf_subset": "mai_Deva-ary_Arab",
        "languages": [
          "mai-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.014764,
        "recall": 0.027668,
        "f1": 0.016861,
        "accuracy": 0.027668,
        "main_score": 0.016861,
        "hf_subset": "pbt_Arab-ary_Arab",
        "languages": [
          "pbt-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.055833,
        "recall": 0.089921,
        "f1": 0.063722,
        "accuracy": 0.089921,
        "main_score": 0.063722,
        "hf_subset": "spa_Latn-ary_Arab",
        "languages": [
          "spa-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.023348,
        "recall": 0.037549,
        "f1": 0.025148,
        "accuracy": 0.037549,
        "main_score": 0.025148,
        "hf_subset": "twi_Latn-ary_Arab",
        "languages": [
          "twi-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.758095,
        "recall": 0.812253,
        "f1": 0.773468,
        "accuracy": 0.812253,
        "main_score": 0.773468,
        "hf_subset": "acm_Arab-ary_Arab",
        "languages": [
          "acm-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.010589,
        "recall": 0.016798,
        "f1": 0.012077,
        "accuracy": 0.016798,
        "main_score": 0.012077,
        "hf_subset": "bel_Cyrl-ary_Arab",
        "languages": [
          "bel-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.812171,
        "recall": 0.865613,
        "f1": 0.828873,
        "accuracy": 0.865613,
        "main_score": 0.828873,
        "hf_subset": "eng_Latn-ary_Arab",
        "languages": [
          "eng-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.03138,
        "recall": 0.054348,
        "f1": 0.036145,
        "accuracy": 0.054348,
        "main_score": 0.036145,
        "hf_subset": "hrv_Latn-ary_Arab",
        "languages": [
          "hrv-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.030094,
        "recall": 0.044466,
        "f1": 0.032157,
        "accuracy": 0.044466,
        "main_score": 0.032157,
        "hf_subset": "kin_Latn-ary_Arab",
        "languages": [
          "kin-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 2e-06,
        "accuracy": 0.000988,
        "main_score": 2e-06,
        "hf_subset": "mal_Mlym-ary_Arab",
        "languages": [
          "mal-Mlym",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.028855,
        "recall": 0.043478,
        "f1": 0.030858,
        "accuracy": 0.043478,
        "main_score": 0.030858,
        "hf_subset": "pes_Arab-ary_Arab",
        "languages": [
          "pes-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.049331,
        "recall": 0.075099,
        "f1": 0.05464,
        "accuracy": 0.075099,
        "main_score": 0.05464,
        "hf_subset": "srd_Latn-ary_Arab",
        "languages": [
          "srd-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 2e-06,
        "accuracy": 0.000988,
        "main_score": 2e-06,
        "hf_subset": "tzm_Tfng-ary_Arab",
        "languages": [
          "tzm-Tfng",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.756291,
        "recall": 0.815217,
        "f1": 0.773657,
        "accuracy": 0.815217,
        "main_score": 0.773657,
        "hf_subset": "acq_Arab-ary_Arab",
        "languages": [
          "acq-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.045914,
        "recall": 0.068182,
        "f1": 0.050025,
        "accuracy": 0.068182,
        "main_score": 0.050025,
        "hf_subset": "bem_Latn-ary_Arab",
        "languages": [
          "bem-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.046341,
        "recall": 0.076087,
        "f1": 0.051776,
        "accuracy": 0.076087,
        "main_score": 0.051776,
        "hf_subset": "epo_Latn-ary_Arab",
        "languages": [
          "epo-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.025277,
        "recall": 0.048419,
        "f1": 0.029127,
        "accuracy": 0.048419,
        "main_score": 0.029127,
        "hf_subset": "hun_Latn-ary_Arab",
        "languages": [
          "hun-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.009577,
        "recall": 0.014822,
        "f1": 0.010641,
        "accuracy": 0.014822,
        "main_score": 0.010641,
        "hf_subset": "kir_Cyrl-ary_Arab",
        "languages": [
          "kir-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 2e-06,
        "accuracy": 0.000988,
        "main_score": 2e-06,
        "hf_subset": "mar_Deva-ary_Arab",
        "languages": [
          "mar-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.024146,
        "recall": 0.038538,
        "f1": 0.026075,
        "accuracy": 0.038538,
        "main_score": 0.026075,
        "hf_subset": "plt_Latn-ary_Arab",
        "languages": [
          "plt-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.016727,
        "recall": 0.024704,
        "f1": 0.018396,
        "accuracy": 0.024704,
        "main_score": 0.018396,
        "hf_subset": "srp_Cyrl-ary_Arab",
        "languages": [
          "srp-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.010747,
        "recall": 0.01581,
        "f1": 0.011248,
        "accuracy": 0.01581,
        "main_score": 0.011248,
        "hf_subset": "uig_Arab-ary_Arab",
        "languages": [
          "uig-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.708241,
        "recall": 0.76581,
        "f1": 0.723804,
        "accuracy": 0.76581,
        "main_score": 0.723804,
        "hf_subset": "aeb_Arab-ary_Arab",
        "languages": [
          "aeb-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.000352,
        "recall": 0.002964,
        "f1": 0.000539,
        "accuracy": 0.002964,
        "main_score": 0.000539,
        "hf_subset": "ben_Beng-ary_Arab",
        "languages": [
          "ben-Beng",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.030743,
        "recall": 0.054348,
        "f1": 0.035935,
        "accuracy": 0.054348,
        "main_score": 0.035935,
        "hf_subset": "est_Latn-ary_Arab",
        "languages": [
          "est-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 2e-06,
        "accuracy": 0.000988,
        "main_score": 2e-06,
        "hf_subset": "hye_Armn-ary_Arab",
        "languages": [
          "hye-Armn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.02241,
        "recall": 0.034585,
        "f1": 0.024149,
        "accuracy": 0.034585,
        "main_score": 0.024149,
        "hf_subset": "kmb_Latn-ary_Arab",
        "languages": [
          "kmb-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.011602,
        "recall": 0.023715,
        "f1": 0.013302,
        "accuracy": 0.023715,
        "main_score": 0.013302,
        "hf_subset": "min_Arab-ary_Arab",
        "languages": [
          "min-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.030031,
        "recall": 0.056324,
        "f1": 0.034611,
        "accuracy": 0.056324,
        "main_score": 0.034611,
        "hf_subset": "pol_Latn-ary_Arab",
        "languages": [
          "pol-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.02323,
        "recall": 0.035573,
        "f1": 0.025156,
        "accuracy": 0.035573,
        "main_score": 0.025156,
        "hf_subset": "ssw_Latn-ary_Arab",
        "languages": [
          "ssw-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.015076,
        "recall": 0.023715,
        "f1": 0.016873,
        "accuracy": 0.023715,
        "main_score": 0.016873,
        "hf_subset": "ukr_Cyrl-ary_Arab",
        "languages": [
          "ukr-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.061459,
        "recall": 0.090909,
        "f1": 0.067391,
        "accuracy": 0.090909,
        "main_score": 0.067391,
        "hf_subset": "afr_Latn-ary_Arab",
        "languages": [
          "afr-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.000992,
        "recall": 0.002964,
        "f1": 0.000996,
        "accuracy": 0.002964,
        "main_score": 0.000996,
        "hf_subset": "bho_Deva-ary_Arab",
        "languages": [
          "bho-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.029743,
        "recall": 0.049407,
        "f1": 0.033409,
        "accuracy": 0.049407,
        "main_score": 0.033409,
        "hf_subset": "eus_Latn-ary_Arab",
        "languages": [
          "eus-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.027481,
        "recall": 0.047431,
        "f1": 0.031101,
        "accuracy": 0.047431,
        "main_score": 0.031101,
        "hf_subset": "ibo_Latn-ary_Arab",
        "languages": [
          "ibo-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.028544,
        "recall": 0.043478,
        "f1": 0.030418,
        "accuracy": 0.043478,
        "main_score": 0.030418,
        "hf_subset": "kmr_Latn-ary_Arab",
        "languages": [
          "kmr-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.033084,
        "recall": 0.051383,
        "f1": 0.036519,
        "accuracy": 0.051383,
        "main_score": 0.036519,
        "hf_subset": "min_Latn-ary_Arab",
        "languages": [
          "min-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.059672,
        "recall": 0.096838,
        "f1": 0.068699,
        "accuracy": 0.096838,
        "main_score": 0.068699,
        "hf_subset": "por_Latn-ary_Arab",
        "languages": [
          "por-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.039911,
        "recall": 0.063241,
        "f1": 0.044583,
        "accuracy": 0.063241,
        "main_score": 0.044583,
        "hf_subset": "sun_Latn-ary_Arab",
        "languages": [
          "sun-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.021567,
        "recall": 0.032609,
        "f1": 0.023361,
        "accuracy": 0.032609,
        "main_score": 0.023361,
        "hf_subset": "umb_Latn-ary_Arab",
        "languages": [
          "umb-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.747345,
        "recall": 0.800395,
        "f1": 0.762273,
        "accuracy": 0.800395,
        "main_score": 0.762273,
        "hf_subset": "ajp_Arab-ary_Arab",
        "languages": [
          "ajp-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.016837,
        "recall": 0.02668,
        "f1": 0.018131,
        "accuracy": 0.02668,
        "main_score": 0.018131,
        "hf_subset": "bjn_Arab-ary_Arab",
        "languages": [
          "bjn-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.014359,
        "recall": 0.02668,
        "f1": 0.016118,
        "accuracy": 0.02668,
        "main_score": 0.016118,
        "hf_subset": "ewe_Latn-ary_Arab",
        "languages": [
          "ewe-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.071286,
        "recall": 0.096838,
        "f1": 0.076692,
        "accuracy": 0.096838,
        "main_score": 0.076692,
        "hf_subset": "ilo_Latn-ary_Arab",
        "languages": [
          "ilo-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.014949,
        "recall": 0.028656,
        "f1": 0.017061,
        "accuracy": 0.028656,
        "main_score": 0.017061,
        "hf_subset": "knc_Arab-ary_Arab",
        "languages": [
          "knc-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.01596,
        "recall": 0.029644,
        "f1": 0.017998,
        "accuracy": 0.029644,
        "main_score": 0.017998,
        "hf_subset": "mkd_Cyrl-ary_Arab",
        "languages": [
          "mkd-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.03256,
        "recall": 0.047431,
        "f1": 0.034703,
        "accuracy": 0.047431,
        "main_score": 0.034703,
        "hf_subset": "prs_Arab-ary_Arab",
        "languages": [
          "prs-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.052822,
        "recall": 0.087945,
        "f1": 0.060644,
        "accuracy": 0.087945,
        "main_score": 0.060644,
        "hf_subset": "swe_Latn-ary_Arab",
        "languages": [
          "swe-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.004361,
        "recall": 0.008893,
        "f1": 0.004967,
        "accuracy": 0.008893,
        "main_score": 0.004967,
        "hf_subset": "urd_Arab-ary_Arab",
        "languages": [
          "urd-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.026885,
        "recall": 0.04249,
        "f1": 0.029749,
        "accuracy": 0.04249,
        "main_score": 0.029749,
        "hf_subset": "aka_Latn-ary_Arab",
        "languages": [
          "aka-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.043012,
        "recall": 0.057312,
        "f1": 0.045961,
        "accuracy": 0.057312,
        "main_score": 0.045961,
        "hf_subset": "bjn_Latn-ary_Arab",
        "languages": [
          "bjn-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.027303,
        "recall": 0.047431,
        "f1": 0.030812,
        "accuracy": 0.047431,
        "main_score": 0.030812,
        "hf_subset": "fao_Latn-ary_Arab",
        "languages": [
          "fao-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.051428,
        "recall": 0.089921,
        "f1": 0.059761,
        "accuracy": 0.089921,
        "main_score": 0.059761,
        "hf_subset": "ind_Latn-ary_Arab",
        "languages": [
          "ind-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.041528,
        "recall": 0.068182,
        "f1": 0.046404,
        "accuracy": 0.068182,
        "main_score": 0.046404,
        "hf_subset": "knc_Latn-ary_Arab",
        "languages": [
          "knc-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.037407,
        "recall": 0.065217,
        "f1": 0.043248,
        "accuracy": 0.065217,
        "main_score": 0.043248,
        "hf_subset": "mlt_Latn-ary_Arab",
        "languages": [
          "mlt-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.014444,
        "recall": 0.025692,
        "f1": 0.016571,
        "accuracy": 0.025692,
        "main_score": 0.016571,
        "hf_subset": "quy_Latn-ary_Arab",
        "languages": [
          "quy-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.020317,
        "recall": 0.036561,
        "f1": 0.02281,
        "accuracy": 0.036561,
        "main_score": 0.02281,
        "hf_subset": "swh_Latn-ary_Arab",
        "languages": [
          "swh-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.021721,
        "recall": 0.035573,
        "f1": 0.02434,
        "accuracy": 0.035573,
        "main_score": 0.02434,
        "hf_subset": "uzn_Latn-ary_Arab",
        "languages": [
          "uzn-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.02866,
        "recall": 0.038538,
        "f1": 0.030914,
        "accuracy": 0.038538,
        "main_score": 0.030914,
        "hf_subset": "als_Latn-ary_Arab",
        "languages": [
          "als-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 2e-06,
        "accuracy": 0.000988,
        "main_score": 2e-06,
        "hf_subset": "bod_Tibt-ary_Arab",
        "languages": [
          "bod-Tibt",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.027138,
        "recall": 0.041502,
        "f1": 0.028974,
        "accuracy": 0.041502,
        "main_score": 0.028974,
        "hf_subset": "fij_Latn-ary_Arab",
        "languages": [
          "fij-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.020052,
        "recall": 0.032609,
        "f1": 0.022007,
        "accuracy": 0.032609,
        "main_score": 0.022007,
        "hf_subset": "isl_Latn-ary_Arab",
        "languages": [
          "isl-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.022661,
        "recall": 0.034585,
        "f1": 0.023756,
        "accuracy": 0.034585,
        "main_score": 0.023756,
        "hf_subset": "kon_Latn-ary_Arab",
        "languages": [
          "kon-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.00203,
        "recall": 0.004941,
        "f1": 0.002409,
        "accuracy": 0.004941,
        "main_score": 0.002409,
        "hf_subset": "mni_Beng-ary_Arab",
        "languages": [
          "mni-Beng",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.065446,
        "recall": 0.094862,
        "f1": 0.07274,
        "accuracy": 0.094862,
        "main_score": 0.07274,
        "hf_subset": "ron_Latn-ary_Arab",
        "languages": [
          "ron-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.026021,
        "recall": 0.047431,
        "f1": 0.030794,
        "accuracy": 0.047431,
        "main_score": 0.030794,
        "hf_subset": "szl_Latn-ary_Arab",
        "languages": [
          "szl-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.057605,
        "recall": 0.089921,
        "f1": 0.064664,
        "accuracy": 0.089921,
        "main_score": 0.064664,
        "hf_subset": "vec_Latn-ary_Arab",
        "languages": [
          "vec-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.000611,
        "recall": 0.004941,
        "f1": 0.00088,
        "accuracy": 0.004941,
        "main_score": 0.00088,
        "hf_subset": "amh_Ethi-ary_Arab",
        "languages": [
          "amh-Ethi",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.026047,
        "recall": 0.046443,
        "f1": 0.030335,
        "accuracy": 0.046443,
        "main_score": 0.030335,
        "hf_subset": "bos_Latn-ary_Arab",
        "languages": [
          "bos-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.018452,
        "recall": 0.033597,
        "f1": 0.020859,
        "accuracy": 0.033597,
        "main_score": 0.020859,
        "hf_subset": "fin_Latn-ary_Arab",
        "languages": [
          "fin-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.057731,
        "recall": 0.088933,
        "f1": 0.065324,
        "accuracy": 0.088933,
        "main_score": 0.065324,
        "hf_subset": "ita_Latn-ary_Arab",
        "languages": [
          "ita-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.036028,
        "recall": 0.061265,
        "f1": 0.040869,
        "accuracy": 0.061265,
        "main_score": 0.040869,
        "hf_subset": "kor_Hang-ary_Arab",
        "languages": [
          "kor-Hang",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.03021,
        "recall": 0.048419,
        "f1": 0.033544,
        "accuracy": 0.048419,
        "main_score": 0.033544,
        "hf_subset": "mos_Latn-ary_Arab",
        "languages": [
          "mos-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.016203,
        "recall": 0.034585,
        "f1": 0.019327,
        "accuracy": 0.034585,
        "main_score": 0.019327,
        "hf_subset": "run_Latn-ary_Arab",
        "languages": [
          "run-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.001088,
        "recall": 0.002964,
        "f1": 0.00117,
        "accuracy": 0.002964,
        "main_score": 0.00117,
        "hf_subset": "tam_Taml-ary_Arab",
        "languages": [
          "tam-Taml",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.07239,
        "recall": 0.117589,
        "f1": 0.083053,
        "accuracy": 0.117589,
        "main_score": 0.083053,
        "hf_subset": "vie_Latn-ary_Arab",
        "languages": [
          "vie-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.720457,
        "recall": 0.774704,
        "f1": 0.735642,
        "accuracy": 0.774704,
        "main_score": 0.735642,
        "hf_subset": "apc_Arab-ary_Arab",
        "languages": [
          "apc-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.024033,
        "recall": 0.037549,
        "f1": 0.025779,
        "accuracy": 0.037549,
        "main_score": 0.025779,
        "hf_subset": "bug_Latn-ary_Arab",
        "languages": [
          "bug-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.001483,
        "recall": 0.002964,
        "f1": 0.001649,
        "accuracy": 0.002964,
        "main_score": 0.001649,
        "hf_subset": "fon_Latn-ary_Arab",
        "languages": [
          "fon-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.032915,
        "recall": 0.047431,
        "f1": 0.035911,
        "accuracy": 0.047431,
        "main_score": 0.035911,
        "hf_subset": "jav_Latn-ary_Arab",
        "languages": [
          "jav-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.015652,
        "recall": 0.018775,
        "f1": 0.015987,
        "accuracy": 0.018775,
        "main_score": 0.015987,
        "hf_subset": "lao_Laoo-ary_Arab",
        "languages": [
          "lao-Laoo",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.027913,
        "recall": 0.040514,
        "f1": 0.029923,
        "accuracy": 0.040514,
        "main_score": 0.029923,
        "hf_subset": "mri_Latn-ary_Arab",
        "languages": [
          "mri-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.026914,
        "recall": 0.043478,
        "f1": 0.030232,
        "accuracy": 0.043478,
        "main_score": 0.030232,
        "hf_subset": "rus_Cyrl-ary_Arab",
        "languages": [
          "rus-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.048172,
        "recall": 0.075099,
        "f1": 0.053331,
        "accuracy": 0.075099,
        "main_score": 0.053331,
        "hf_subset": "taq_Latn-ary_Arab",
        "languages": [
          "taq-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.075736,
        "recall": 0.114625,
        "f1": 0.082897,
        "accuracy": 0.114625,
        "main_score": 0.082897,
        "hf_subset": "war_Latn-ary_Arab",
        "languages": [
          "war-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.770349,
        "recall": 0.826087,
        "f1": 0.787044,
        "accuracy": 0.826087,
        "main_score": 0.787044,
        "hf_subset": "arb_Arab-ary_Arab",
        "languages": [
          "arb-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.020925,
        "recall": 0.033597,
        "f1": 0.023333,
        "accuracy": 0.033597,
        "main_score": 0.023333,
        "hf_subset": "bul_Cyrl-ary_Arab",
        "languages": [
          "bul-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.087595,
        "recall": 0.130435,
        "f1": 0.098001,
        "accuracy": 0.130435,
        "main_score": 0.098001,
        "hf_subset": "fra_Latn-ary_Arab",
        "languages": [
          "fra-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.039354,
        "recall": 0.073123,
        "f1": 0.046296,
        "accuracy": 0.073123,
        "main_score": 0.046296,
        "hf_subset": "jpn_Jpan-ary_Arab",
        "languages": [
          "jpn-Jpan",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.066815,
        "recall": 0.091897,
        "f1": 0.072399,
        "accuracy": 0.091897,
        "main_score": 0.072399,
        "hf_subset": "lij_Latn-ary_Arab",
        "languages": [
          "lij-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.001005,
        "recall": 0.001976,
        "f1": 0.001022,
        "accuracy": 0.001976,
        "main_score": 0.001022,
        "hf_subset": "mya_Mymr-ary_Arab",
        "languages": [
          "mya-Mymr",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.031036,
        "recall": 0.047431,
        "f1": 0.033693,
        "accuracy": 0.047431,
        "main_score": 0.033693,
        "hf_subset": "sag_Latn-ary_Arab",
        "languages": [
          "sag-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "taq_Tfng-ary_Arab",
        "languages": [
          "taq-Tfng",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.030913,
        "recall": 0.047431,
        "f1": 0.033371,
        "accuracy": 0.047431,
        "main_score": 0.033371,
        "hf_subset": "wol_Latn-ary_Arab",
        "languages": [
          "wol-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.019626,
        "recall": 0.038538,
        "f1": 0.022833,
        "accuracy": 0.038538,
        "main_score": 0.022833,
        "hf_subset": "arb_Latn-ary_Arab",
        "languages": [
          "arb-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.058131,
        "recall": 0.092885,
        "f1": 0.066045,
        "accuracy": 0.092885,
        "main_score": 0.066045,
        "hf_subset": "cat_Latn-ary_Arab",
        "languages": [
          "cat-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.047266,
        "recall": 0.077075,
        "f1": 0.053927,
        "accuracy": 0.077075,
        "main_score": 0.053927,
        "hf_subset": "fur_Latn-ary_Arab",
        "languages": [
          "fur-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.026137,
        "recall": 0.04249,
        "f1": 0.028978,
        "accuracy": 0.04249,
        "main_score": 0.028978,
        "hf_subset": "kab_Latn-ary_Arab",
        "languages": [
          "kab-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.05973,
        "recall": 0.099802,
        "f1": 0.068054,
        "accuracy": 0.099802,
        "main_score": 0.068054,
        "hf_subset": "lim_Latn-ary_Arab",
        "languages": [
          "lim-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.067364,
        "recall": 0.102767,
        "f1": 0.073891,
        "accuracy": 0.102767,
        "main_score": 0.073891,
        "hf_subset": "nld_Latn-ary_Arab",
        "languages": [
          "nld-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.000993,
        "recall": 0.002964,
        "f1": 0.000997,
        "accuracy": 0.002964,
        "main_score": 0.000997,
        "hf_subset": "san_Deva-ary_Arab",
        "languages": [
          "san-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.017881,
        "recall": 0.023715,
        "f1": 0.018627,
        "accuracy": 0.023715,
        "main_score": 0.018627,
        "hf_subset": "tat_Cyrl-ary_Arab",
        "languages": [
          "tat-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.022996,
        "recall": 0.043478,
        "f1": 0.026116,
        "accuracy": 0.043478,
        "main_score": 0.026116,
        "hf_subset": "xho_Latn-ary_Arab",
        "languages": [
          "xho-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.7591,
        "recall": 0.818182,
        "f1": 0.776649,
        "accuracy": 0.818182,
        "main_score": 0.776649,
        "hf_subset": "ars_Arab-ary_Arab",
        "languages": [
          "ars-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.053793,
        "recall": 0.079051,
        "f1": 0.05819,
        "accuracy": 0.079051,
        "main_score": 0.05819,
        "hf_subset": "ceb_Latn-ary_Arab",
        "languages": [
          "ceb-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.050937,
        "recall": 0.076087,
        "f1": 0.054962,
        "accuracy": 0.076087,
        "main_score": 0.054962,
        "hf_subset": "fuv_Latn-ary_Arab",
        "languages": [
          "fuv-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.023603,
        "recall": 0.035573,
        "f1": 0.025503,
        "accuracy": 0.035573,
        "main_score": 0.025503,
        "hf_subset": "kac_Latn-ary_Arab",
        "languages": [
          "kac-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.027537,
        "recall": 0.044466,
        "f1": 0.029808,
        "accuracy": 0.044466,
        "main_score": 0.029808,
        "hf_subset": "lin_Latn-ary_Arab",
        "languages": [
          "lin-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.051206,
        "recall": 0.083004,
        "f1": 0.058114,
        "accuracy": 0.083004,
        "main_score": 0.058114,
        "hf_subset": "nno_Latn-ary_Arab",
        "languages": [
          "nno-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000988,
        "f1": 3e-06,
        "accuracy": 0.000988,
        "main_score": 3e-06,
        "hf_subset": "sat_Olck-ary_Arab",
        "languages": [
          "sat-Olck",
          "ary-Arab"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 2e-06,
        "accuracy": 0.000988,
        "main_score": 2e-06,
        "hf_subset": "tel_Telu-ary_Arab",
        "languages": [
          "tel-Telu",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.014257,
        "recall": 0.027668,
        "f1": 0.016724,
        "accuracy": 0.027668,
        "main_score": 0.016724,
        "hf_subset": "ydd_Hebr-ary_Arab",
        "languages": [
          "ydd-Hebr",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.005787,
        "recall": 0.01581,
        "f1": 0.006724,
        "accuracy": 0.01581,
        "main_score": 0.006724,
        "hf_subset": "ary_Arab-ace_Arab",
        "languages": [
          "ary-Arab",
          "ace-Arab"
        ]
      },
      {
        "precision": 0.005068,
        "recall": 0.009881,
        "f1": 0.005508,
        "accuracy": 0.009881,
        "main_score": 0.005508,
        "hf_subset": "ary_Arab-bam_Latn",
        "languages": [
          "ary-Arab",
          "bam-Latn"
        ]
      },
      {
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "accuracy": 0.0,
        "main_score": 0.0,
        "hf_subset": "ary_Arab-dzo_Tibt",
        "languages": [
          "ary-Arab",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.002206,
        "recall": 0.006917,
        "f1": 0.002721,
        "accuracy": 0.006917,
        "main_score": 0.002721,
        "hf_subset": "ary_Arab-hin_Deva",
        "languages": [
          "ary-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.001183,
        "recall": 0.006917,
        "f1": 0.001355,
        "accuracy": 0.006917,
        "main_score": 0.001355,
        "hf_subset": "ary_Arab-khm_Khmr",
        "languages": [
          "ary-Arab",
          "khm-Khmr"
        ]
      },
      {
        "precision": 0.000355,
        "recall": 0.003953,
        "f1": 0.000545,
        "accuracy": 0.003953,
        "main_score": 0.000545,
        "hf_subset": "ary_Arab-mag_Deva",
        "languages": [
          "ary-Arab",
          "mag-Deva"
        ]
      },
      {
        "precision": 0.01791,
        "recall": 0.025692,
        "f1": 0.018522,
        "accuracy": 0.025692,
        "main_score": 0.018522,
        "hf_subset": "ary_Arab-pap_Latn",
        "languages": [
          "ary-Arab",
          "pap-Latn"
        ]
      },
      {
        "precision": 0.011666,
        "recall": 0.019763,
        "f1": 0.012607,
        "accuracy": 0.019763,
        "main_score": 0.012607,
        "hf_subset": "ary_Arab-sot_Latn",
        "languages": [
          "ary-Arab",
          "sot-Latn"
        ]
      },
      {
        "precision": 0.012818,
        "recall": 0.021739,
        "f1": 0.013734,
        "accuracy": 0.021739,
        "main_score": 0.013734,
        "hf_subset": "ary_Arab-tur_Latn",
        "languages": [
          "ary-Arab",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.013214,
        "recall": 0.020751,
        "f1": 0.014284,
        "accuracy": 0.020751,
        "main_score": 0.014284,
        "hf_subset": "ary_Arab-ace_Latn",
        "languages": [
          "ary-Arab",
          "ace-Latn"
        ]
      },
      {
        "precision": 0.021277,
        "recall": 0.028656,
        "f1": 0.022393,
        "accuracy": 0.028656,
        "main_score": 0.022393,
        "hf_subset": "ary_Arab-ban_Latn",
        "languages": [
          "ary-Arab",
          "ban-Latn"
        ]
      },
      {
        "precision": 0.002911,
        "recall": 0.005929,
        "f1": 0.003329,
        "accuracy": 0.005929,
        "main_score": 0.003329,
        "hf_subset": "ary_Arab-ell_Grek",
        "languages": [
          "ary-Arab",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.001977,
        "recall": 0.002964,
        "f1": 0.001978,
        "accuracy": 0.002964,
        "main_score": 0.001978,
        "hf_subset": "ary_Arab-hne_Deva",
        "languages": [
          "ary-Arab",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.00569,
        "recall": 0.008893,
        "f1": 0.006049,
        "accuracy": 0.008893,
        "main_score": 0.006049,
        "hf_subset": "ary_Arab-kik_Latn",
        "languages": [
          "ary-Arab",
          "kik-Latn"
        ]
      },
      {
        "precision": 0.000989,
        "recall": 0.001976,
        "f1": 0.00099,
        "accuracy": 0.001976,
        "main_score": 0.00099,
        "hf_subset": "ary_Arab-mai_Deva",
        "languages": [
          "ary-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.007304,
        "recall": 0.014822,
        "f1": 0.008325,
        "accuracy": 0.014822,
        "main_score": 0.008325,
        "hf_subset": "ary_Arab-pbt_Arab",
        "languages": [
          "ary-Arab",
          "pbt-Arab"
        ]
      },
      {
        "precision": 0.0194,
        "recall": 0.030632,
        "f1": 0.020804,
        "accuracy": 0.030632,
        "main_score": 0.020804,
        "hf_subset": "ary_Arab-spa_Latn",
        "languages": [
          "ary-Arab",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.011126,
        "recall": 0.012846,
        "f1": 0.011283,
        "accuracy": 0.012846,
        "main_score": 0.011283,
        "hf_subset": "ary_Arab-twi_Latn",
        "languages": [
          "ary-Arab",
          "twi-Latn"
        ]
      },
      {
        "precision": 0.603538,
        "recall": 0.640316,
        "f1": 0.611561,
        "accuracy": 0.640316,
        "main_score": 0.611561,
        "hf_subset": "ary_Arab-acm_Arab",
        "languages": [
          "ary-Arab",
          "acm-Arab"
        ]
      },
      {
        "precision": 0.003958,
        "recall": 0.006917,
        "f1": 0.004292,
        "accuracy": 0.006917,
        "main_score": 0.004292,
        "hf_subset": "ary_Arab-bel_Cyrl",
        "languages": [
          "ary-Arab",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.463406,
        "recall": 0.502964,
        "f1": 0.472237,
        "accuracy": 0.502964,
        "main_score": 0.472237,
        "hf_subset": "ary_Arab-eng_Latn",
        "languages": [
          "ary-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.00594,
        "recall": 0.008893,
        "f1": 0.006281,
        "accuracy": 0.008893,
        "main_score": 0.006281,
        "hf_subset": "ary_Arab-hrv_Latn",
        "languages": [
          "ary-Arab",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.014718,
        "recall": 0.017787,
        "f1": 0.01525,
        "accuracy": 0.017787,
        "main_score": 0.01525,
        "hf_subset": "ary_Arab-kin_Latn",
        "languages": [
          "ary-Arab",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.002497,
        "recall": 0.003953,
        "f1": 0.002687,
        "accuracy": 0.003953,
        "main_score": 0.002687,
        "hf_subset": "ary_Arab-mal_Mlym",
        "languages": [
          "ary-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.014835,
        "recall": 0.029644,
        "f1": 0.016701,
        "accuracy": 0.029644,
        "main_score": 0.016701,
        "hf_subset": "ary_Arab-pes_Arab",
        "languages": [
          "ary-Arab",
          "pes-Arab"
        ]
      },
      {
        "precision": 0.013867,
        "recall": 0.018775,
        "f1": 0.014693,
        "accuracy": 0.018775,
        "main_score": 0.014693,
        "hf_subset": "ary_Arab-srd_Latn",
        "languages": [
          "ary-Arab",
          "srd-Latn"
        ]
      },
      {
        "precision": 0.000726,
        "recall": 0.002964,
        "f1": 0.001054,
        "accuracy": 0.002964,
        "main_score": 0.001054,
        "hf_subset": "ary_Arab-tzm_Tfng",
        "languages": [
          "ary-Arab",
          "tzm-Tfng"
        ]
      },
      {
        "precision": 0.559371,
        "recall": 0.598814,
        "f1": 0.568914,
        "accuracy": 0.598814,
        "main_score": 0.568914,
        "hf_subset": "ary_Arab-acq_Arab",
        "languages": [
          "ary-Arab",
          "acq-Arab"
        ]
      },
      {
        "precision": 0.019248,
        "recall": 0.025692,
        "f1": 0.020351,
        "accuracy": 0.025692,
        "main_score": 0.020351,
        "hf_subset": "ary_Arab-bem_Latn",
        "languages": [
          "ary-Arab",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.017375,
        "recall": 0.020751,
        "f1": 0.018061,
        "accuracy": 0.020751,
        "main_score": 0.018061,
        "hf_subset": "ary_Arab-epo_Latn",
        "languages": [
          "ary-Arab",
          "epo-Latn"
        ]
      },
      {
        "precision": 0.009423,
        "recall": 0.016798,
        "f1": 0.010171,
        "accuracy": 0.016798,
        "main_score": 0.010171,
        "hf_subset": "ary_Arab-hun_Latn",
        "languages": [
          "ary-Arab",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.004575,
        "recall": 0.01087,
        "f1": 0.005309,
        "accuracy": 0.01087,
        "main_score": 0.005309,
        "hf_subset": "ary_Arab-kir_Cyrl",
        "languages": [
          "ary-Arab",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.001977,
        "recall": 0.002964,
        "f1": 0.001978,
        "accuracy": 0.002964,
        "main_score": 0.001978,
        "hf_subset": "ary_Arab-mar_Deva",
        "languages": [
          "ary-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.013101,
        "recall": 0.017787,
        "f1": 0.013289,
        "accuracy": 0.017787,
        "main_score": 0.013289,
        "hf_subset": "ary_Arab-plt_Latn",
        "languages": [
          "ary-Arab",
          "plt-Latn"
        ]
      },
      {
        "precision": 0.006269,
        "recall": 0.01087,
        "f1": 0.006845,
        "accuracy": 0.01087,
        "main_score": 0.006845,
        "hf_subset": "ary_Arab-srp_Cyrl",
        "languages": [
          "ary-Arab",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.003168,
        "recall": 0.006917,
        "f1": 0.003635,
        "accuracy": 0.006917,
        "main_score": 0.003635,
        "hf_subset": "ary_Arab-uig_Arab",
        "languages": [
          "ary-Arab",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.623508,
        "recall": 0.671937,
        "f1": 0.634043,
        "accuracy": 0.671937,
        "main_score": 0.634043,
        "hf_subset": "ary_Arab-aeb_Arab",
        "languages": [
          "ary-Arab",
          "aeb-Arab"
        ]
      },
      {
        "precision": 0.001977,
        "recall": 0.002964,
        "f1": 0.001979,
        "accuracy": 0.002964,
        "main_score": 0.001979,
        "hf_subset": "ary_Arab-ben_Beng",
        "languages": [
          "ary-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.010731,
        "recall": 0.01581,
        "f1": 0.011702,
        "accuracy": 0.01581,
        "main_score": 0.011702,
        "hf_subset": "ary_Arab-est_Latn",
        "languages": [
          "ary-Arab",
          "est-Latn"
        ]
      },
      {
        "precision": 0.006899,
        "recall": 0.012846,
        "f1": 0.007686,
        "accuracy": 0.012846,
        "main_score": 0.007686,
        "hf_subset": "ary_Arab-hye_Armn",
        "languages": [
          "ary-Arab",
          "hye-Armn"
        ]
      },
      {
        "precision": 0.006485,
        "recall": 0.009881,
        "f1": 0.006708,
        "accuracy": 0.009881,
        "main_score": 0.006708,
        "hf_subset": "ary_Arab-kmb_Latn",
        "languages": [
          "ary-Arab",
          "kmb-Latn"
        ]
      },
      {
        "precision": 0.014575,
        "recall": 0.018775,
        "f1": 0.01526,
        "accuracy": 0.018775,
        "main_score": 0.01526,
        "hf_subset": "ary_Arab-min_Arab",
        "languages": [
          "ary-Arab",
          "min-Arab"
        ]
      },
      {
        "precision": 0.011029,
        "recall": 0.017787,
        "f1": 0.012021,
        "accuracy": 0.017787,
        "main_score": 0.012021,
        "hf_subset": "ary_Arab-pol_Latn",
        "languages": [
          "ary-Arab",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.008813,
        "recall": 0.018775,
        "f1": 0.009788,
        "accuracy": 0.018775,
        "main_score": 0.009788,
        "hf_subset": "ary_Arab-ssw_Latn",
        "languages": [
          "ary-Arab",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.003234,
        "recall": 0.007905,
        "f1": 0.003446,
        "accuracy": 0.007905,
        "main_score": 0.003446,
        "hf_subset": "ary_Arab-ukr_Cyrl",
        "languages": [
          "ary-Arab",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.014678,
        "recall": 0.018775,
        "f1": 0.015113,
        "accuracy": 0.018775,
        "main_score": 0.015113,
        "hf_subset": "ary_Arab-afr_Latn",
        "languages": [
          "ary-Arab",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.003357,
        "recall": 0.007905,
        "f1": 0.00363,
        "accuracy": 0.007905,
        "main_score": 0.00363,
        "hf_subset": "ary_Arab-bho_Deva",
        "languages": [
          "ary-Arab",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.00913,
        "recall": 0.014822,
        "f1": 0.009655,
        "accuracy": 0.014822,
        "main_score": 0.009655,
        "hf_subset": "ary_Arab-eus_Latn",
        "languages": [
          "ary-Arab",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.010267,
        "recall": 0.014822,
        "f1": 0.011141,
        "accuracy": 0.014822,
        "main_score": 0.011141,
        "hf_subset": "ary_Arab-ibo_Latn",
        "languages": [
          "ary-Arab",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.011323,
        "recall": 0.016798,
        "f1": 0.011645,
        "accuracy": 0.016798,
        "main_score": 0.011645,
        "hf_subset": "ary_Arab-kmr_Latn",
        "languages": [
          "ary-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.010674,
        "recall": 0.019763,
        "f1": 0.011588,
        "accuracy": 0.019763,
        "main_score": 0.011588,
        "hf_subset": "ary_Arab-min_Latn",
        "languages": [
          "ary-Arab",
          "min-Latn"
        ]
      },
      {
        "precision": 0.017182,
        "recall": 0.024704,
        "f1": 0.017932,
        "accuracy": 0.024704,
        "main_score": 0.017932,
        "hf_subset": "ary_Arab-por_Latn",
        "languages": [
          "ary-Arab",
          "por-Latn"
        ]
      },
      {
        "precision": 0.013657,
        "recall": 0.017787,
        "f1": 0.014068,
        "accuracy": 0.017787,
        "main_score": 0.014068,
        "hf_subset": "ary_Arab-sun_Latn",
        "languages": [
          "ary-Arab",
          "sun-Latn"
        ]
      },
      {
        "precision": 0.00521,
        "recall": 0.011858,
        "f1": 0.005841,
        "accuracy": 0.011858,
        "main_score": 0.005841,
        "hf_subset": "ary_Arab-umb_Latn",
        "languages": [
          "ary-Arab",
          "umb-Latn"
        ]
      },
      {
        "precision": 0.542,
        "recall": 0.585968,
        "f1": 0.551527,
        "accuracy": 0.585968,
        "main_score": 0.551527,
        "hf_subset": "ary_Arab-ajp_Arab",
        "languages": [
          "ary-Arab",
          "ajp-Arab"
        ]
      },
      {
        "precision": 0.023295,
        "recall": 0.028656,
        "f1": 0.024017,
        "accuracy": 0.028656,
        "main_score": 0.024017,
        "hf_subset": "ary_Arab-bjn_Arab",
        "languages": [
          "ary-Arab",
          "bjn-Arab"
        ]
      },
      {
        "precision": 0.004201,
        "recall": 0.006917,
        "f1": 0.004679,
        "accuracy": 0.006917,
        "main_score": 0.004679,
        "hf_subset": "ary_Arab-ewe_Latn",
        "languages": [
          "ary-Arab",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.019052,
        "recall": 0.023715,
        "f1": 0.01926,
        "accuracy": 0.023715,
        "main_score": 0.01926,
        "hf_subset": "ary_Arab-ilo_Latn",
        "languages": [
          "ary-Arab",
          "ilo-Latn"
        ]
      },
      {
        "precision": 0.008156,
        "recall": 0.016798,
        "f1": 0.009569,
        "accuracy": 0.016798,
        "main_score": 0.009569,
        "hf_subset": "ary_Arab-knc_Arab",
        "languages": [
          "ary-Arab",
          "knc-Arab"
        ]
      },
      {
        "precision": 0.004952,
        "recall": 0.006917,
        "f1": 0.004963,
        "accuracy": 0.006917,
        "main_score": 0.004963,
        "hf_subset": "ary_Arab-mkd_Cyrl",
        "languages": [
          "ary-Arab",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.016194,
        "recall": 0.020751,
        "f1": 0.017068,
        "accuracy": 0.020751,
        "main_score": 0.017068,
        "hf_subset": "ary_Arab-prs_Arab",
        "languages": [
          "ary-Arab",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.021779,
        "recall": 0.031621,
        "f1": 0.023165,
        "accuracy": 0.031621,
        "main_score": 0.023165,
        "hf_subset": "ary_Arab-swe_Latn",
        "languages": [
          "ary-Arab",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.001998,
        "recall": 0.003953,
        "f1": 0.002019,
        "accuracy": 0.003953,
        "main_score": 0.002019,
        "hf_subset": "ary_Arab-urd_Arab",
        "languages": [
          "ary-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.009722,
        "recall": 0.01581,
        "f1": 0.010145,
        "accuracy": 0.01581,
        "main_score": 0.010145,
        "hf_subset": "ary_Arab-aka_Latn",
        "languages": [
          "ary-Arab",
          "aka-Latn"
        ]
      },
      {
        "precision": 0.013341,
        "recall": 0.01581,
        "f1": 0.013639,
        "accuracy": 0.01581,
        "main_score": 0.013639,
        "hf_subset": "ary_Arab-bjn_Latn",
        "languages": [
          "ary-Arab",
          "bjn-Latn"
        ]
      },
      {
        "precision": 0.009118,
        "recall": 0.014822,
        "f1": 0.009768,
        "accuracy": 0.014822,
        "main_score": 0.009768,
        "hf_subset": "ary_Arab-fao_Latn",
        "languages": [
          "ary-Arab",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.016462,
        "recall": 0.024704,
        "f1": 0.017229,
        "accuracy": 0.024704,
        "main_score": 0.017229,
        "hf_subset": "ary_Arab-ind_Latn",
        "languages": [
          "ary-Arab",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.016692,
        "recall": 0.029644,
        "f1": 0.018178,
        "accuracy": 0.029644,
        "main_score": 0.018178,
        "hf_subset": "ary_Arab-knc_Latn",
        "languages": [
          "ary-Arab",
          "knc-Latn"
        ]
      },
      {
        "precision": 0.015055,
        "recall": 0.023715,
        "f1": 0.01607,
        "accuracy": 0.023715,
        "main_score": 0.01607,
        "hf_subset": "ary_Arab-mlt_Latn",
        "languages": [
          "ary-Arab",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.016733,
        "recall": 0.02668,
        "f1": 0.018817,
        "accuracy": 0.02668,
        "main_score": 0.018817,
        "hf_subset": "ary_Arab-quy_Latn",
        "languages": [
          "ary-Arab",
          "quy-Latn"
        ]
      },
      {
        "precision": 0.005337,
        "recall": 0.008893,
        "f1": 0.005561,
        "accuracy": 0.008893,
        "main_score": 0.005561,
        "hf_subset": "ary_Arab-swh_Latn",
        "languages": [
          "ary-Arab",
          "swh-Latn"
        ]
      },
      {
        "precision": 0.002954,
        "recall": 0.006917,
        "f1": 0.003412,
        "accuracy": 0.006917,
        "main_score": 0.003412,
        "hf_subset": "ary_Arab-uzn_Latn",
        "languages": [
          "ary-Arab",
          "uzn-Latn"
        ]
      },
      {
        "precision": 0.009962,
        "recall": 0.016798,
        "f1": 0.010527,
        "accuracy": 0.016798,
        "main_score": 0.010527,
        "hf_subset": "ary_Arab-als_Latn",
        "languages": [
          "ary-Arab",
          "als-Latn"
        ]
      },
      {
        "precision": 0.003076,
        "recall": 0.008893,
        "f1": 0.003625,
        "accuracy": 0.008893,
        "main_score": 0.003625,
        "hf_subset": "ary_Arab-bod_Tibt",
        "languages": [
          "ary-Arab",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.013404,
        "recall": 0.017787,
        "f1": 0.014073,
        "accuracy": 0.017787,
        "main_score": 0.014073,
        "hf_subset": "ary_Arab-fij_Latn",
        "languages": [
          "ary-Arab",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.007037,
        "recall": 0.01087,
        "f1": 0.00747,
        "accuracy": 0.01087,
        "main_score": 0.00747,
        "hf_subset": "ary_Arab-isl_Latn",
        "languages": [
          "ary-Arab",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.012408,
        "recall": 0.01581,
        "f1": 0.012627,
        "accuracy": 0.01581,
        "main_score": 0.012627,
        "hf_subset": "ary_Arab-kon_Latn",
        "languages": [
          "ary-Arab",
          "kon-Latn"
        ]
      },
      {
        "precision": 0.003064,
        "recall": 0.004941,
        "f1": 0.003146,
        "accuracy": 0.004941,
        "main_score": 0.003146,
        "hf_subset": "ary_Arab-mni_Beng",
        "languages": [
          "ary-Arab",
          "mni-Beng"
        ]
      },
      {
        "precision": 0.01995,
        "recall": 0.028656,
        "f1": 0.021538,
        "accuracy": 0.028656,
        "main_score": 0.021538,
        "hf_subset": "ary_Arab-ron_Latn",
        "languages": [
          "ary-Arab",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.014264,
        "recall": 0.020751,
        "f1": 0.015318,
        "accuracy": 0.020751,
        "main_score": 0.015318,
        "hf_subset": "ary_Arab-szl_Latn",
        "languages": [
          "ary-Arab",
          "szl-Latn"
        ]
      },
      {
        "precision": 0.017029,
        "recall": 0.023715,
        "f1": 0.018134,
        "accuracy": 0.023715,
        "main_score": 0.018134,
        "hf_subset": "ary_Arab-vec_Latn",
        "languages": [
          "ary-Arab",
          "vec-Latn"
        ]
      },
      {
        "precision": 9e-06,
        "recall": 0.001976,
        "f1": 1.8e-05,
        "accuracy": 0.001976,
        "main_score": 1.8e-05,
        "hf_subset": "ary_Arab-amh_Ethi",
        "languages": [
          "ary-Arab",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.010708,
        "recall": 0.012846,
        "f1": 0.011041,
        "accuracy": 0.012846,
        "main_score": 0.011041,
        "hf_subset": "ary_Arab-bos_Latn",
        "languages": [
          "ary-Arab",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.006178,
        "recall": 0.007905,
        "f1": 0.006329,
        "accuracy": 0.007905,
        "main_score": 0.006329,
        "hf_subset": "ary_Arab-fin_Latn",
        "languages": [
          "ary-Arab",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.016343,
        "recall": 0.024704,
        "f1": 0.017546,
        "accuracy": 0.024704,
        "main_score": 0.017546,
        "hf_subset": "ary_Arab-ita_Latn",
        "languages": [
          "ary-Arab",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.008138,
        "recall": 0.014822,
        "f1": 0.008822,
        "accuracy": 0.014822,
        "main_score": 0.008822,
        "hf_subset": "ary_Arab-kor_Hang",
        "languages": [
          "ary-Arab",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.005213,
        "recall": 0.007905,
        "f1": 0.005385,
        "accuracy": 0.007905,
        "main_score": 0.005385,
        "hf_subset": "ary_Arab-mos_Latn",
        "languages": [
          "ary-Arab",
          "mos-Latn"
        ]
      },
      {
        "precision": 0.009097,
        "recall": 0.013834,
        "f1": 0.009629,
        "accuracy": 0.013834,
        "main_score": 0.009629,
        "hf_subset": "ary_Arab-run_Latn",
        "languages": [
          "ary-Arab",
          "run-Latn"
        ]
      },
      {
        "precision": 0.002474,
        "recall": 0.003953,
        "f1": 0.002643,
        "accuracy": 0.003953,
        "main_score": 0.002643,
        "hf_subset": "ary_Arab-tam_Taml",
        "languages": [
          "ary-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.025795,
        "recall": 0.034585,
        "f1": 0.027083,
        "accuracy": 0.034585,
        "main_score": 0.027083,
        "hf_subset": "ary_Arab-vie_Latn",
        "languages": [
          "ary-Arab",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.599072,
        "recall": 0.648221,
        "f1": 0.610996,
        "accuracy": 0.648221,
        "main_score": 0.610996,
        "hf_subset": "ary_Arab-apc_Arab",
        "languages": [
          "ary-Arab",
          "apc-Arab"
        ]
      },
      {
        "precision": 0.013163,
        "recall": 0.020751,
        "f1": 0.014238,
        "accuracy": 0.020751,
        "main_score": 0.014238,
        "hf_subset": "ary_Arab-bug_Latn",
        "languages": [
          "ary-Arab",
          "bug-Latn"
        ]
      },
      {
        "precision": 0.003982,
        "recall": 0.005929,
        "f1": 0.00401,
        "accuracy": 0.005929,
        "main_score": 0.00401,
        "hf_subset": "ary_Arab-fon_Latn",
        "languages": [
          "ary-Arab",
          "fon-Latn"
        ]
      },
      {
        "precision": 0.016685,
        "recall": 0.019763,
        "f1": 0.017108,
        "accuracy": 0.019763,
        "main_score": 0.017108,
        "hf_subset": "ary_Arab-jav_Latn",
        "languages": [
          "ary-Arab",
          "jav-Latn"
        ]
      },
      {
        "precision": 0.005612,
        "recall": 0.009881,
        "f1": 0.005917,
        "accuracy": 0.009881,
        "main_score": 0.005917,
        "hf_subset": "ary_Arab-lao_Laoo",
        "languages": [
          "ary-Arab",
          "lao-Laoo"
        ]
      },
      {
        "precision": 0.011309,
        "recall": 0.018775,
        "f1": 0.012009,
        "accuracy": 0.018775,
        "main_score": 0.012009,
        "hf_subset": "ary_Arab-mri_Latn",
        "languages": [
          "ary-Arab",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.003954,
        "recall": 0.004941,
        "f1": 0.003955,
        "accuracy": 0.004941,
        "main_score": 0.003955,
        "hf_subset": "ary_Arab-rus_Cyrl",
        "languages": [
          "ary-Arab",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.017651,
        "recall": 0.027668,
        "f1": 0.01939,
        "accuracy": 0.027668,
        "main_score": 0.01939,
        "hf_subset": "ary_Arab-taq_Latn",
        "languages": [
          "ary-Arab",
          "taq-Latn"
        ]
      },
      {
        "precision": 0.021247,
        "recall": 0.027668,
        "f1": 0.021891,
        "accuracy": 0.027668,
        "main_score": 0.021891,
        "hf_subset": "ary_Arab-war_Latn",
        "languages": [
          "ary-Arab",
          "war-Latn"
        ]
      },
      {
        "precision": 0.536338,
        "recall": 0.577075,
        "f1": 0.545559,
        "accuracy": 0.577075,
        "main_score": 0.545559,
        "hf_subset": "ary_Arab-arb_Arab",
        "languages": [
          "ary-Arab",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.003459,
        "recall": 0.004941,
        "f1": 0.003625,
        "accuracy": 0.004941,
        "main_score": 0.003625,
        "hf_subset": "ary_Arab-bul_Cyrl",
        "languages": [
          "ary-Arab",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.021285,
        "recall": 0.027668,
        "f1": 0.022301,
        "accuracy": 0.027668,
        "main_score": 0.022301,
        "hf_subset": "ary_Arab-fra_Latn",
        "languages": [
          "ary-Arab",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.015413,
        "recall": 0.023715,
        "f1": 0.016184,
        "accuracy": 0.023715,
        "main_score": 0.016184,
        "hf_subset": "ary_Arab-jpn_Jpan",
        "languages": [
          "ary-Arab",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.017754,
        "recall": 0.033597,
        "f1": 0.020519,
        "accuracy": 0.033597,
        "main_score": 0.020519,
        "hf_subset": "ary_Arab-lij_Latn",
        "languages": [
          "ary-Arab",
          "lij-Latn"
        ]
      },
      {
        "precision": 0.001489,
        "recall": 0.003953,
        "f1": 0.00166,
        "accuracy": 0.003953,
        "main_score": 0.00166,
        "hf_subset": "ary_Arab-mya_Mymr",
        "languages": [
          "ary-Arab",
          "mya-Mymr"
        ]
      },
      {
        "precision": 0.009275,
        "recall": 0.01581,
        "f1": 0.010306,
        "accuracy": 0.01581,
        "main_score": 0.010306,
        "hf_subset": "ary_Arab-sag_Latn",
        "languages": [
          "ary-Arab",
          "sag-Latn"
        ]
      },
      {
        "precision": 8.4e-05,
        "recall": 0.001976,
        "f1": 0.000155,
        "accuracy": 0.001976,
        "main_score": 0.000155,
        "hf_subset": "ary_Arab-taq_Tfng",
        "languages": [
          "ary-Arab",
          "taq-Tfng"
        ]
      },
      {
        "precision": 0.01146,
        "recall": 0.017787,
        "f1": 0.011907,
        "accuracy": 0.017787,
        "main_score": 0.011907,
        "hf_subset": "ary_Arab-wol_Latn",
        "languages": [
          "ary-Arab",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.012515,
        "recall": 0.016798,
        "f1": 0.013142,
        "accuracy": 0.016798,
        "main_score": 0.013142,
        "hf_subset": "ary_Arab-arb_Latn",
        "languages": [
          "ary-Arab",
          "arb-Latn"
        ]
      },
      {
        "precision": 0.018526,
        "recall": 0.024704,
        "f1": 0.019397,
        "accuracy": 0.024704,
        "main_score": 0.019397,
        "hf_subset": "ary_Arab-cat_Latn",
        "languages": [
          "ary-Arab",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.014727,
        "recall": 0.020751,
        "f1": 0.015519,
        "accuracy": 0.020751,
        "main_score": 0.015519,
        "hf_subset": "ary_Arab-fur_Latn",
        "languages": [
          "ary-Arab",
          "fur-Latn"
        ]
      },
      {
        "precision": 0.011894,
        "recall": 0.016798,
        "f1": 0.012389,
        "accuracy": 0.016798,
        "main_score": 0.012389,
        "hf_subset": "ary_Arab-kab_Latn",
        "languages": [
          "ary-Arab",
          "kab-Latn"
        ]
      },
      {
        "precision": 0.020013,
        "recall": 0.029644,
        "f1": 0.021182,
        "accuracy": 0.029644,
        "main_score": 0.021182,
        "hf_subset": "ary_Arab-lim_Latn",
        "languages": [
          "ary-Arab",
          "lim-Latn"
        ]
      },
      {
        "precision": 0.022406,
        "recall": 0.035573,
        "f1": 0.024471,
        "accuracy": 0.035573,
        "main_score": 0.024471,
        "hf_subset": "ary_Arab-nld_Latn",
        "languages": [
          "ary-Arab",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.004221,
        "recall": 0.006917,
        "f1": 0.004426,
        "accuracy": 0.006917,
        "main_score": 0.004426,
        "hf_subset": "ary_Arab-san_Deva",
        "languages": [
          "ary-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.007599,
        "recall": 0.01087,
        "f1": 0.007917,
        "accuracy": 0.01087,
        "main_score": 0.007917,
        "hf_subset": "ary_Arab-tat_Cyrl",
        "languages": [
          "ary-Arab",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.015316,
        "recall": 0.022727,
        "f1": 0.01602,
        "accuracy": 0.022727,
        "main_score": 0.01602,
        "hf_subset": "ary_Arab-xho_Latn",
        "languages": [
          "ary-Arab",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.533067,
        "recall": 0.574111,
        "f1": 0.542571,
        "accuracy": 0.574111,
        "main_score": 0.542571,
        "hf_subset": "ary_Arab-ars_Arab",
        "languages": [
          "ary-Arab",
          "ars-Arab"
        ]
      },
      {
        "precision": 0.013089,
        "recall": 0.017787,
        "f1": 0.0133,
        "accuracy": 0.017787,
        "main_score": 0.0133,
        "hf_subset": "ary_Arab-ceb_Latn",
        "languages": [
          "ary-Arab",
          "ceb-Latn"
        ]
      },
      {
        "precision": 0.01914,
        "recall": 0.02668,
        "f1": 0.020056,
        "accuracy": 0.02668,
        "main_score": 0.020056,
        "hf_subset": "ary_Arab-fuv_Latn",
        "languages": [
          "ary-Arab",
          "fuv-Latn"
        ]
      },
      {
        "precision": 0.016971,
        "recall": 0.02668,
        "f1": 0.018151,
        "accuracy": 0.02668,
        "main_score": 0.018151,
        "hf_subset": "ary_Arab-kac_Latn",
        "languages": [
          "ary-Arab",
          "kac-Latn"
        ]
      },
      {
        "precision": 0.014181,
        "recall": 0.021739,
        "f1": 0.015208,
        "accuracy": 0.021739,
        "main_score": 0.015208,
        "hf_subset": "ary_Arab-lin_Latn",
        "languages": [
          "ary-Arab",
          "lin-Latn"
        ]
      },
      {
        "precision": 0.016562,
        "recall": 0.025692,
        "f1": 0.017116,
        "accuracy": 0.025692,
        "main_score": 0.017116,
        "hf_subset": "ary_Arab-nno_Latn",
        "languages": [
          "ary-Arab",
          "nno-Latn"
        ]
      },
      {
        "precision": 2.3e-05,
        "recall": 0.001976,
        "f1": 4.4e-05,
        "accuracy": 0.001976,
        "main_score": 4.4e-05,
        "hf_subset": "ary_Arab-sat_Olck",
        "languages": [
          "ary-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.001519,
        "recall": 0.005929,
        "f1": 0.001876,
        "accuracy": 0.005929,
        "main_score": 0.001876,
        "hf_subset": "ary_Arab-tel_Telu",
        "languages": [
          "ary-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.004345,
        "recall": 0.007905,
        "f1": 0.004894,
        "accuracy": 0.007905,
        "main_score": 0.004894,
        "hf_subset": "ary_Arab-ydd_Hebr",
        "languages": [
          "ary-Arab",
          "ydd-Hebr"
        ]
      },
      {
        "precision": 0.006094,
        "recall": 0.01087,
        "f1": 0.006238,
        "accuracy": 0.01087,
        "main_score": 0.006238,
        "hf_subset": "ary_Arab-ces_Latn",
        "languages": [
          "ary-Arab",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.006862,
        "recall": 0.011858,
        "f1": 0.007429,
        "accuracy": 0.011858,
        "main_score": 0.007429,
        "hf_subset": "ary_Arab-gaz_Latn",
        "languages": [
          "ary-Arab",
          "gaz-Latn"
        ]
      },
      {
        "precision": 0.016221,
        "recall": 0.022727,
        "f1": 0.017378,
        "accuracy": 0.022727,
        "main_score": 0.017378,
        "hf_subset": "ary_Arab-kam_Latn",
        "languages": [
          "ary-Arab",
          "kam-Latn"
        ]
      },
      {
        "precision": 0.005235,
        "recall": 0.008893,
        "f1": 0.005778,
        "accuracy": 0.008893,
        "main_score": 0.005778,
        "hf_subset": "ary_Arab-lit_Latn",
        "languages": [
          "ary-Arab",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.02115,
        "recall": 0.030632,
        "f1": 0.022252,
        "accuracy": 0.030632,
        "main_score": 0.022252,
        "hf_subset": "ary_Arab-nob_Latn",
        "languages": [
          "ary-Arab",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.016869,
        "recall": 0.024704,
        "f1": 0.018286,
        "accuracy": 0.024704,
        "main_score": 0.018286,
        "hf_subset": "ary_Arab-scn_Latn",
        "languages": [
          "ary-Arab",
          "scn-Latn"
        ]
      },
      {
        "precision": 0.004723,
        "recall": 0.009881,
        "f1": 0.005064,
        "accuracy": 0.009881,
        "main_score": 0.005064,
        "hf_subset": "ary_Arab-tgk_Cyrl",
        "languages": [
          "ary-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.005773,
        "recall": 0.008893,
        "f1": 0.006111,
        "accuracy": 0.008893,
        "main_score": 0.006111,
        "hf_subset": "ary_Arab-yor_Latn",
        "languages": [
          "ary-Arab",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.615268,
        "recall": 0.664032,
        "f1": 0.626675,
        "accuracy": 0.664032,
        "main_score": 0.626675,
        "hf_subset": "ary_Arab-arz_Arab",
        "languages": [
          "ary-Arab",
          "arz-Arab"
        ]
      },
      {
        "precision": 0.010897,
        "recall": 0.012846,
        "f1": 0.010924,
        "accuracy": 0.012846,
        "main_score": 0.010924,
        "hf_subset": "ary_Arab-cjk_Latn",
        "languages": [
          "ary-Arab",
          "cjk-Latn"
        ]
      },
      {
        "precision": 0.010268,
        "recall": 0.013834,
        "f1": 0.010815,
        "accuracy": 0.013834,
        "main_score": 0.010815,
        "hf_subset": "ary_Arab-gla_Latn",
        "languages": [
          "ary-Arab",
          "gla-Latn"
        ]
      },
      {
        "precision": 0.002781,
        "recall": 0.006917,
        "f1": 0.003152,
        "accuracy": 0.006917,
        "main_score": 0.003152,
        "hf_subset": "ary_Arab-kan_Knda",
        "languages": [
          "ary-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.021907,
        "recall": 0.029644,
        "f1": 0.022667,
        "accuracy": 0.029644,
        "main_score": 0.022667,
        "hf_subset": "ary_Arab-lmo_Latn",
        "languages": [
          "ary-Arab",
          "lmo-Latn"
        ]
      },
      {
        "precision": 0.00124,
        "recall": 0.003953,
        "f1": 0.001393,
        "accuracy": 0.003953,
        "main_score": 0.001393,
        "hf_subset": "ary_Arab-npi_Deva",
        "languages": [
          "ary-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.005587,
        "recall": 0.01087,
        "f1": 0.006425,
        "accuracy": 0.01087,
        "main_score": 0.006425,
        "hf_subset": "ary_Arab-shn_Mymr",
        "languages": [
          "ary-Arab",
          "shn-Mymr"
        ]
      },
      {
        "precision": 0.01298,
        "recall": 0.021739,
        "f1": 0.013606,
        "accuracy": 0.021739,
        "main_score": 0.013606,
        "hf_subset": "ary_Arab-tgl_Latn",
        "languages": [
          "ary-Arab",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.019772,
        "recall": 0.030632,
        "f1": 0.02123,
        "accuracy": 0.030632,
        "main_score": 0.02123,
        "hf_subset": "ary_Arab-yue_Hant",
        "languages": [
          "ary-Arab",
          "yue-Hant"
        ]
      },
      {
        "precision": 0.000166,
        "recall": 0.001976,
        "f1": 0.000285,
        "accuracy": 0.001976,
        "main_score": 0.000285,
        "hf_subset": "ary_Arab-asm_Beng",
        "languages": [
          "ary-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.003987,
        "recall": 0.006917,
        "f1": 0.004449,
        "accuracy": 0.006917,
        "main_score": 0.004449,
        "hf_subset": "ary_Arab-ckb_Arab",
        "languages": [
          "ary-Arab",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.008803,
        "recall": 0.014822,
        "f1": 0.009369,
        "accuracy": 0.014822,
        "main_score": 0.009369,
        "hf_subset": "ary_Arab-gle_Latn",
        "languages": [
          "ary-Arab",
          "gle-Latn"
        ]
      },
      {
        "precision": 0.003242,
        "recall": 0.007905,
        "f1": 0.003462,
        "accuracy": 0.007905,
        "main_score": 0.003462,
        "hf_subset": "ary_Arab-kas_Arab",
        "languages": [
          "ary-Arab",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.007971,
        "recall": 0.016798,
        "f1": 0.009162,
        "accuracy": 0.016798,
        "main_score": 0.009162,
        "hf_subset": "ary_Arab-ltg_Latn",
        "languages": [
          "ary-Arab",
          "ltg-Latn"
        ]
      },
      {
        "precision": 0.021457,
        "recall": 0.027668,
        "f1": 0.022137,
        "accuracy": 0.027668,
        "main_score": 0.022137,
        "hf_subset": "ary_Arab-nso_Latn",
        "languages": [
          "ary-Arab",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.001001,
        "recall": 0.002964,
        "f1": 0.001013,
        "accuracy": 0.002964,
        "main_score": 0.001013,
        "hf_subset": "ary_Arab-sin_Sinh",
        "languages": [
          "ary-Arab",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.004173,
        "recall": 0.007905,
        "f1": 0.00435,
        "accuracy": 0.007905,
        "main_score": 0.00435,
        "hf_subset": "ary_Arab-tha_Thai",
        "languages": [
          "ary-Arab",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.021712,
        "recall": 0.033597,
        "f1": 0.023727,
        "accuracy": 0.033597,
        "main_score": 0.023727,
        "hf_subset": "ary_Arab-zho_Hans",
        "languages": [
          "ary-Arab",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.016248,
        "recall": 0.028656,
        "f1": 0.017839,
        "accuracy": 0.028656,
        "main_score": 0.017839,
        "hf_subset": "ary_Arab-ast_Latn",
        "languages": [
          "ary-Arab",
          "ast-Latn"
        ]
      },
      {
        "precision": 0.008248,
        "recall": 0.012846,
        "f1": 0.008888,
        "accuracy": 0.012846,
        "main_score": 0.008888,
        "hf_subset": "ary_Arab-crh_Latn",
        "languages": [
          "ary-Arab",
          "crh-Latn"
        ]
      },
      {
        "precision": 0.020805,
        "recall": 0.029644,
        "f1": 0.022108,
        "accuracy": 0.029644,
        "main_score": 0.022108,
        "hf_subset": "ary_Arab-glg_Latn",
        "languages": [
          "ary-Arab",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.003795,
        "recall": 0.007905,
        "f1": 0.004258,
        "accuracy": 0.007905,
        "main_score": 0.004258,
        "hf_subset": "ary_Arab-kas_Deva",
        "languages": [
          "ary-Arab",
          "kas-Deva"
        ]
      },
      {
        "precision": 0.008111,
        "recall": 0.012846,
        "f1": 0.008288,
        "accuracy": 0.012846,
        "main_score": 0.008288,
        "hf_subset": "ary_Arab-ltz_Latn",
        "languages": [
          "ary-Arab",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.001498,
        "recall": 0.004941,
        "f1": 0.00181,
        "accuracy": 0.004941,
        "main_score": 0.00181,
        "hf_subset": "ary_Arab-nus_Latn",
        "languages": [
          "ary-Arab",
          "nus-Latn"
        ]
      },
      {
        "precision": 0.011481,
        "recall": 0.019763,
        "f1": 0.012385,
        "accuracy": 0.019763,
        "main_score": 0.012385,
        "hf_subset": "ary_Arab-slk_Latn",
        "languages": [
          "ary-Arab",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.002157,
        "recall": 0.006917,
        "f1": 0.002666,
        "accuracy": 0.006917,
        "main_score": 0.002666,
        "hf_subset": "ary_Arab-tir_Ethi",
        "languages": [
          "ary-Arab",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.017284,
        "recall": 0.023715,
        "f1": 0.017949,
        "accuracy": 0.023715,
        "main_score": 0.017949,
        "hf_subset": "ary_Arab-zho_Hant",
        "languages": [
          "ary-Arab",
          "zho-Hant"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 2e-06,
        "accuracy": 0.000988,
        "main_score": 2e-06,
        "hf_subset": "ary_Arab-awa_Deva",
        "languages": [
          "ary-Arab",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.013045,
        "recall": 0.021739,
        "f1": 0.013654,
        "accuracy": 0.021739,
        "main_score": 0.013654,
        "hf_subset": "ary_Arab-cym_Latn",
        "languages": [
          "ary-Arab",
          "cym-Latn"
        ]
      },
      {
        "precision": 0.010693,
        "recall": 0.016798,
        "f1": 0.011503,
        "accuracy": 0.016798,
        "main_score": 0.011503,
        "hf_subset": "ary_Arab-grn_Latn",
        "languages": [
          "ary-Arab",
          "grn-Latn"
        ]
      },
      {
        "precision": 0.007906,
        "recall": 0.011858,
        "f1": 0.008731,
        "accuracy": 0.011858,
        "main_score": 0.008731,
        "hf_subset": "ary_Arab-kat_Geor",
        "languages": [
          "ary-Arab",
          "kat-Geor"
        ]
      },
      {
        "precision": 0.009771,
        "recall": 0.012846,
        "f1": 0.010149,
        "accuracy": 0.012846,
        "main_score": 0.010149,
        "hf_subset": "ary_Arab-lua_Latn",
        "languages": [
          "ary-Arab",
          "lua-Latn"
        ]
      },
      {
        "precision": 0.013074,
        "recall": 0.019763,
        "f1": 0.013894,
        "accuracy": 0.019763,
        "main_score": 0.013894,
        "hf_subset": "ary_Arab-nya_Latn",
        "languages": [
          "ary-Arab",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.00683,
        "recall": 0.01087,
        "f1": 0.00723,
        "accuracy": 0.01087,
        "main_score": 0.00723,
        "hf_subset": "ary_Arab-slv_Latn",
        "languages": [
          "ary-Arab",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.025153,
        "recall": 0.031621,
        "f1": 0.025808,
        "accuracy": 0.031621,
        "main_score": 0.025808,
        "hf_subset": "ary_Arab-tpi_Latn",
        "languages": [
          "ary-Arab",
          "tpi-Latn"
        ]
      },
      {
        "precision": 0.018396,
        "recall": 0.024704,
        "f1": 0.019071,
        "accuracy": 0.024704,
        "main_score": 0.019071,
        "hf_subset": "ary_Arab-zsm_Latn",
        "languages": [
          "ary-Arab",
          "zsm-Latn"
        ]
      },
      {
        "precision": 0.009805,
        "recall": 0.013834,
        "f1": 0.010211,
        "accuracy": 0.013834,
        "main_score": 0.010211,
        "hf_subset": "ary_Arab-ayr_Latn",
        "languages": [
          "ary-Arab",
          "ayr-Latn"
        ]
      },
      {
        "precision": 0.019655,
        "recall": 0.028656,
        "f1": 0.020576,
        "accuracy": 0.028656,
        "main_score": 0.020576,
        "hf_subset": "ary_Arab-dan_Latn",
        "languages": [
          "ary-Arab",
          "dan-Latn"
        ]
      },
      {
        "precision": 9e-06,
        "recall": 0.000988,
        "f1": 1.8e-05,
        "accuracy": 0.000988,
        "main_score": 1.8e-05,
        "hf_subset": "ary_Arab-guj_Gujr",
        "languages": [
          "ary-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.008893,
        "recall": 0.009881,
        "f1": 0.009223,
        "accuracy": 0.009881,
        "main_score": 0.009223,
        "hf_subset": "ary_Arab-kaz_Cyrl",
        "languages": [
          "ary-Arab",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.011251,
        "recall": 0.018775,
        "f1": 0.012095,
        "accuracy": 0.018775,
        "main_score": 0.012095,
        "hf_subset": "ary_Arab-lug_Latn",
        "languages": [
          "ary-Arab",
          "lug-Latn"
        ]
      },
      {
        "precision": 0.015016,
        "recall": 0.027668,
        "f1": 0.016765,
        "accuracy": 0.027668,
        "main_score": 0.016765,
        "hf_subset": "ary_Arab-oci_Latn",
        "languages": [
          "ary-Arab",
          "oci-Latn"
        ]
      },
      {
        "precision": 0.011199,
        "recall": 0.011858,
        "f1": 0.011364,
        "accuracy": 0.011858,
        "main_score": 0.011364,
        "hf_subset": "ary_Arab-smo_Latn",
        "languages": [
          "ary-Arab",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.010123,
        "recall": 0.013834,
        "f1": 0.010684,
        "accuracy": 0.013834,
        "main_score": 0.010684,
        "hf_subset": "ary_Arab-tsn_Latn",
        "languages": [
          "ary-Arab",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.007131,
        "recall": 0.012846,
        "f1": 0.007783,
        "accuracy": 0.012846,
        "main_score": 0.007783,
        "hf_subset": "ary_Arab-zul_Latn",
        "languages": [
          "ary-Arab",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.007002,
        "recall": 0.012846,
        "f1": 0.00762,
        "accuracy": 0.012846,
        "main_score": 0.00762,
        "hf_subset": "ary_Arab-azb_Arab",
        "languages": [
          "ary-Arab",
          "azb-Arab"
        ]
      },
      {
        "precision": 0.0109,
        "recall": 0.020751,
        "f1": 0.011816,
        "accuracy": 0.020751,
        "main_score": 0.011816,
        "hf_subset": "ary_Arab-deu_Latn",
        "languages": [
          "ary-Arab",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.015316,
        "recall": 0.01581,
        "f1": 0.015481,
        "accuracy": 0.01581,
        "main_score": 0.015481,
        "hf_subset": "ary_Arab-hat_Latn",
        "languages": [
          "ary-Arab",
          "hat-Latn"
        ]
      },
      {
        "precision": 0.00198,
        "recall": 0.003953,
        "f1": 0.001984,
        "accuracy": 0.003953,
        "main_score": 0.001984,
        "hf_subset": "ary_Arab-kbp_Latn",
        "languages": [
          "ary-Arab",
          "kbp-Latn"
        ]
      },
      {
        "precision": 0.014679,
        "recall": 0.019763,
        "f1": 0.01549,
        "accuracy": 0.019763,
        "main_score": 0.01549,
        "hf_subset": "ary_Arab-luo_Latn",
        "languages": [
          "ary-Arab",
          "luo-Latn"
        ]
      },
      {
        "precision": 0.001162,
        "recall": 0.004941,
        "f1": 0.001305,
        "accuracy": 0.004941,
        "main_score": 0.001305,
        "hf_subset": "ary_Arab-ory_Orya",
        "languages": [
          "ary-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.010233,
        "recall": 0.016798,
        "f1": 0.010953,
        "accuracy": 0.016798,
        "main_score": 0.010953,
        "hf_subset": "ary_Arab-sna_Latn",
        "languages": [
          "ary-Arab",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.010603,
        "recall": 0.018775,
        "f1": 0.011727,
        "accuracy": 0.018775,
        "main_score": 0.011727,
        "hf_subset": "ary_Arab-tso_Latn",
        "languages": [
          "ary-Arab",
          "tso-Latn"
        ]
      },
      {
        "precision": 0.003865,
        "recall": 0.008893,
        "f1": 0.004265,
        "accuracy": 0.008893,
        "main_score": 0.004265,
        "hf_subset": "ary_Arab-azj_Latn",
        "languages": [
          "ary-Arab",
          "azj-Latn"
        ]
      },
      {
        "precision": 0.010312,
        "recall": 0.016798,
        "f1": 0.011434,
        "accuracy": 0.016798,
        "main_score": 0.011434,
        "hf_subset": "ary_Arab-dik_Latn",
        "languages": [
          "ary-Arab",
          "dik-Latn"
        ]
      },
      {
        "precision": 0.018809,
        "recall": 0.022727,
        "f1": 0.019171,
        "accuracy": 0.022727,
        "main_score": 0.019171,
        "hf_subset": "ary_Arab-hau_Latn",
        "languages": [
          "ary-Arab",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.008449,
        "recall": 0.014822,
        "f1": 0.00955,
        "accuracy": 0.014822,
        "main_score": 0.00955,
        "hf_subset": "ary_Arab-kea_Latn",
        "languages": [
          "ary-Arab",
          "kea-Latn"
        ]
      },
      {
        "precision": 0.034296,
        "recall": 0.049407,
        "f1": 0.036191,
        "accuracy": 0.049407,
        "main_score": 0.036191,
        "hf_subset": "ary_Arab-lus_Latn",
        "languages": [
          "ary-Arab",
          "lus-Latn"
        ]
      },
      {
        "precision": 0.047084,
        "recall": 0.060277,
        "f1": 0.049107,
        "accuracy": 0.060277,
        "main_score": 0.049107,
        "hf_subset": "ary_Arab-pag_Latn",
        "languages": [
          "ary-Arab",
          "pag-Latn"
        ]
      },
      {
        "precision": 0.01046,
        "recall": 0.012846,
        "f1": 0.010775,
        "accuracy": 0.012846,
        "main_score": 0.010775,
        "hf_subset": "ary_Arab-snd_Arab",
        "languages": [
          "ary-Arab",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.006889,
        "recall": 0.012846,
        "f1": 0.007986,
        "accuracy": 0.012846,
        "main_score": 0.007986,
        "hf_subset": "ary_Arab-tuk_Latn",
        "languages": [
          "ary-Arab",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.005629,
        "recall": 0.01087,
        "f1": 0.0064,
        "accuracy": 0.01087,
        "main_score": 0.0064,
        "hf_subset": "ary_Arab-bak_Cyrl",
        "languages": [
          "ary-Arab",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.00524,
        "recall": 0.006917,
        "f1": 0.005435,
        "accuracy": 0.006917,
        "main_score": 0.005435,
        "hf_subset": "ary_Arab-dyu_Latn",
        "languages": [
          "ary-Arab",
          "dyu-Latn"
        ]
      },
      {
        "precision": 0.00317,
        "recall": 0.006917,
        "f1": 0.003341,
        "accuracy": 0.006917,
        "main_score": 0.003341,
        "hf_subset": "ary_Arab-heb_Hebr",
        "languages": [
          "ary-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.003987,
        "recall": 0.006917,
        "f1": 0.004348,
        "accuracy": 0.006917,
        "main_score": 0.004348,
        "hf_subset": "ary_Arab-khk_Cyrl",
        "languages": [
          "ary-Arab",
          "khk-Cyrl"
        ]
      },
      {
        "precision": 0.005064,
        "recall": 0.009881,
        "f1": 0.005505,
        "accuracy": 0.009881,
        "main_score": 0.005505,
        "hf_subset": "ary_Arab-lvs_Latn",
        "languages": [
          "ary-Arab",
          "lvs-Latn"
        ]
      },
      {
        "precision": 7e-06,
        "recall": 0.001976,
        "f1": 1.4e-05,
        "accuracy": 0.001976,
        "main_score": 1.4e-05,
        "hf_subset": "ary_Arab-pan_Guru",
        "languages": [
          "ary-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.010643,
        "recall": 0.01581,
        "f1": 0.011517,
        "accuracy": 0.01581,
        "main_score": 0.011517,
        "hf_subset": "ary_Arab-som_Latn",
        "languages": [
          "ary-Arab",
          "som-Latn"
        ]
      },
      {
        "precision": 0.008745,
        "recall": 0.012846,
        "f1": 0.009091,
        "accuracy": 0.012846,
        "main_score": 0.009091,
        "hf_subset": "ary_Arab-tum_Latn",
        "languages": [
          "ary-Arab",
          "tum-Latn"
        ]
      },
      {
        "precision": 0.027838,
        "recall": 0.048419,
        "f1": 0.032256,
        "accuracy": 0.048419,
        "main_score": 0.032256,
        "hf_subset": "ces_Latn-ary_Arab",
        "languages": [
          "ces-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.013195,
        "recall": 0.024704,
        "f1": 0.014831,
        "accuracy": 0.024704,
        "main_score": 0.014831,
        "hf_subset": "gaz_Latn-ary_Arab",
        "languages": [
          "gaz-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.030059,
        "recall": 0.048419,
        "f1": 0.032402,
        "accuracy": 0.048419,
        "main_score": 0.032402,
        "hf_subset": "kam_Latn-ary_Arab",
        "languages": [
          "kam-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.031482,
        "recall": 0.044466,
        "f1": 0.034295,
        "accuracy": 0.044466,
        "main_score": 0.034295,
        "hf_subset": "lit_Latn-ary_Arab",
        "languages": [
          "lit-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.059684,
        "recall": 0.094862,
        "f1": 0.067714,
        "accuracy": 0.094862,
        "main_score": 0.067714,
        "hf_subset": "nob_Latn-ary_Arab",
        "languages": [
          "nob-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.043053,
        "recall": 0.06917,
        "f1": 0.04915,
        "accuracy": 0.06917,
        "main_score": 0.04915,
        "hf_subset": "scn_Latn-ary_Arab",
        "languages": [
          "scn-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.018211,
        "recall": 0.031621,
        "f1": 0.02028,
        "accuracy": 0.031621,
        "main_score": 0.02028,
        "hf_subset": "tgk_Cyrl-ary_Arab",
        "languages": [
          "tgk-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.015464,
        "recall": 0.024704,
        "f1": 0.017009,
        "accuracy": 0.024704,
        "main_score": 0.017009,
        "hf_subset": "yor_Latn-ary_Arab",
        "languages": [
          "yor-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.700138,
        "recall": 0.751976,
        "f1": 0.714257,
        "accuracy": 0.751976,
        "main_score": 0.714257,
        "hf_subset": "arz_Arab-ary_Arab",
        "languages": [
          "arz-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.024797,
        "recall": 0.037549,
        "f1": 0.026941,
        "accuracy": 0.037549,
        "main_score": 0.026941,
        "hf_subset": "cjk_Latn-ary_Arab",
        "languages": [
          "cjk-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.030112,
        "recall": 0.043478,
        "f1": 0.033051,
        "accuracy": 0.043478,
        "main_score": 0.033051,
        "hf_subset": "gla_Latn-ary_Arab",
        "languages": [
          "gla-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 2e-06,
        "accuracy": 0.000988,
        "main_score": 2e-06,
        "hf_subset": "kan_Knda-ary_Arab",
        "languages": [
          "kan-Knda",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.050925,
        "recall": 0.079051,
        "f1": 0.056089,
        "accuracy": 0.079051,
        "main_score": 0.056089,
        "hf_subset": "lmo_Latn-ary_Arab",
        "languages": [
          "lmo-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.000994,
        "recall": 0.002964,
        "f1": 0.001001,
        "accuracy": 0.002964,
        "main_score": 0.001001,
        "hf_subset": "npi_Deva-ary_Arab",
        "languages": [
          "npi-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.003226,
        "recall": 0.005929,
        "f1": 0.003388,
        "accuracy": 0.005929,
        "main_score": 0.003388,
        "hf_subset": "shn_Mymr-ary_Arab",
        "languages": [
          "shn-Mymr",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.042605,
        "recall": 0.063241,
        "f1": 0.04593,
        "accuracy": 0.063241,
        "main_score": 0.04593,
        "hf_subset": "tgl_Latn-ary_Arab",
        "languages": [
          "tgl-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.071149,
        "recall": 0.110672,
        "f1": 0.080624,
        "accuracy": 0.110672,
        "main_score": 0.080624,
        "hf_subset": "yue_Hant-ary_Arab",
        "languages": [
          "yue-Hant",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.000989,
        "recall": 0.001976,
        "f1": 0.000991,
        "accuracy": 0.001976,
        "main_score": 0.000991,
        "hf_subset": "asm_Beng-ary_Arab",
        "languages": [
          "asm-Beng",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.009224,
        "recall": 0.01087,
        "f1": 0.00939,
        "accuracy": 0.01087,
        "main_score": 0.00939,
        "hf_subset": "ckb_Arab-ary_Arab",
        "languages": [
          "ckb-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.029314,
        "recall": 0.044466,
        "f1": 0.03153,
        "accuracy": 0.044466,
        "main_score": 0.03153,
        "hf_subset": "gle_Latn-ary_Arab",
        "languages": [
          "gle-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.00314,
        "recall": 0.006917,
        "f1": 0.003598,
        "accuracy": 0.006917,
        "main_score": 0.003598,
        "hf_subset": "kas_Arab-ary_Arab",
        "languages": [
          "kas-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.023012,
        "recall": 0.035573,
        "f1": 0.025716,
        "accuracy": 0.035573,
        "main_score": 0.025716,
        "hf_subset": "ltg_Latn-ary_Arab",
        "languages": [
          "ltg-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.041804,
        "recall": 0.071146,
        "f1": 0.047841,
        "accuracy": 0.071146,
        "main_score": 0.047841,
        "hf_subset": "nso_Latn-ary_Arab",
        "languages": [
          "nso-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 2e-06,
        "accuracy": 0.000988,
        "main_score": 2e-06,
        "hf_subset": "sin_Sinh-ary_Arab",
        "languages": [
          "sin-Sinh",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.017069,
        "recall": 0.030632,
        "f1": 0.019312,
        "accuracy": 0.030632,
        "main_score": 0.019312,
        "hf_subset": "tha_Thai-ary_Arab",
        "languages": [
          "tha-Thai",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.094307,
        "recall": 0.148221,
        "f1": 0.107458,
        "accuracy": 0.148221,
        "main_score": 0.107458,
        "hf_subset": "zho_Hans-ary_Arab",
        "languages": [
          "zho-Hans",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.061472,
        "recall": 0.097826,
        "f1": 0.069658,
        "accuracy": 0.097826,
        "main_score": 0.069658,
        "hf_subset": "ast_Latn-ary_Arab",
        "languages": [
          "ast-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.028852,
        "recall": 0.049407,
        "f1": 0.032315,
        "accuracy": 0.049407,
        "main_score": 0.032315,
        "hf_subset": "crh_Latn-ary_Arab",
        "languages": [
          "crh-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.060307,
        "recall": 0.100791,
        "f1": 0.069594,
        "accuracy": 0.100791,
        "main_score": 0.069594,
        "hf_subset": "glg_Latn-ary_Arab",
        "languages": [
          "glg-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 6e-06,
        "recall": 0.001976,
        "f1": 1.3e-05,
        "accuracy": 0.001976,
        "main_score": 1.3e-05,
        "hf_subset": "kas_Deva-ary_Arab",
        "languages": [
          "kas-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.03327,
        "recall": 0.061265,
        "f1": 0.03852,
        "accuracy": 0.061265,
        "main_score": 0.03852,
        "hf_subset": "ltz_Latn-ary_Arab",
        "languages": [
          "ltz-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.00353,
        "recall": 0.005929,
        "f1": 0.003757,
        "accuracy": 0.005929,
        "main_score": 0.003757,
        "hf_subset": "nus_Latn-ary_Arab",
        "languages": [
          "nus-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.024694,
        "recall": 0.049407,
        "f1": 0.029368,
        "accuracy": 0.049407,
        "main_score": 0.029368,
        "hf_subset": "slk_Latn-ary_Arab",
        "languages": [
          "slk-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 3e-06,
        "recall": 0.000988,
        "f1": 5e-06,
        "accuracy": 0.000988,
        "main_score": 5e-06,
        "hf_subset": "tir_Ethi-ary_Arab",
        "languages": [
          "tir-Ethi",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.053729,
        "recall": 0.09585,
        "f1": 0.0632,
        "accuracy": 0.09585,
        "main_score": 0.0632,
        "hf_subset": "zho_Hant-ary_Arab",
        "languages": [
          "zho-Hant",
          "ary-Arab"
        ]
      },
      {
        "precision": 2e-06,
        "recall": 0.000988,
        "f1": 3e-06,
        "accuracy": 0.000988,
        "main_score": 3e-06,
        "hf_subset": "awa_Deva-ary_Arab",
        "languages": [
          "awa-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.03192,
        "recall": 0.047431,
        "f1": 0.035066,
        "accuracy": 0.047431,
        "main_score": 0.035066,
        "hf_subset": "cym_Latn-ary_Arab",
        "languages": [
          "cym-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.037607,
        "recall": 0.059289,
        "f1": 0.041067,
        "accuracy": 0.059289,
        "main_score": 0.041067,
        "hf_subset": "grn_Latn-ary_Arab",
        "languages": [
          "grn-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.003066,
        "recall": 0.006917,
        "f1": 0.003159,
        "accuracy": 0.006917,
        "main_score": 0.003159,
        "hf_subset": "kat_Geor-ary_Arab",
        "languages": [
          "kat-Geor",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.031751,
        "recall": 0.049407,
        "f1": 0.034522,
        "accuracy": 0.049407,
        "main_score": 0.034522,
        "hf_subset": "lua_Latn-ary_Arab",
        "languages": [
          "lua-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.043348,
        "recall": 0.064229,
        "f1": 0.046298,
        "accuracy": 0.064229,
        "main_score": 0.046298,
        "hf_subset": "nya_Latn-ary_Arab",
        "languages": [
          "nya-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.0274,
        "recall": 0.048419,
        "f1": 0.031907,
        "accuracy": 0.048419,
        "main_score": 0.031907,
        "hf_subset": "slv_Latn-ary_Arab",
        "languages": [
          "slv-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.067749,
        "recall": 0.09585,
        "f1": 0.073052,
        "accuracy": 0.09585,
        "main_score": 0.073052,
        "hf_subset": "tpi_Latn-ary_Arab",
        "languages": [
          "tpi-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.049692,
        "recall": 0.078063,
        "f1": 0.056007,
        "accuracy": 0.078063,
        "main_score": 0.056007,
        "hf_subset": "zsm_Latn-ary_Arab",
        "languages": [
          "zsm-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.020584,
        "recall": 0.034585,
        "f1": 0.022807,
        "accuracy": 0.034585,
        "main_score": 0.022807,
        "hf_subset": "ayr_Latn-ary_Arab",
        "languages": [
          "ayr-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.06684,
        "recall": 0.097826,
        "f1": 0.073754,
        "accuracy": 0.097826,
        "main_score": 0.073754,
        "hf_subset": "dan_Latn-ary_Arab",
        "languages": [
          "dan-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 2e-06,
        "accuracy": 0.000988,
        "main_score": 2e-06,
        "hf_subset": "guj_Gujr-ary_Arab",
        "languages": [
          "guj-Gujr",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.018469,
        "recall": 0.022727,
        "f1": 0.019237,
        "accuracy": 0.022727,
        "main_score": 0.019237,
        "hf_subset": "kaz_Cyrl-ary_Arab",
        "languages": [
          "kaz-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.028264,
        "recall": 0.050395,
        "f1": 0.03189,
        "accuracy": 0.050395,
        "main_score": 0.03189,
        "hf_subset": "lug_Latn-ary_Arab",
        "languages": [
          "lug-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.058214,
        "recall": 0.096838,
        "f1": 0.067057,
        "accuracy": 0.096838,
        "main_score": 0.067057,
        "hf_subset": "oci_Latn-ary_Arab",
        "languages": [
          "oci-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.027444,
        "recall": 0.043478,
        "f1": 0.029824,
        "accuracy": 0.043478,
        "main_score": 0.029824,
        "hf_subset": "smo_Latn-ary_Arab",
        "languages": [
          "smo-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.02671,
        "recall": 0.048419,
        "f1": 0.030084,
        "accuracy": 0.048419,
        "main_score": 0.030084,
        "hf_subset": "tsn_Latn-ary_Arab",
        "languages": [
          "tsn-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.014971,
        "recall": 0.025692,
        "f1": 0.016607,
        "accuracy": 0.025692,
        "main_score": 0.016607,
        "hf_subset": "zul_Latn-ary_Arab",
        "languages": [
          "zul-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.016215,
        "recall": 0.025692,
        "f1": 0.017375,
        "accuracy": 0.025692,
        "main_score": 0.017375,
        "hf_subset": "azb_Arab-ary_Arab",
        "languages": [
          "azb-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.053911,
        "recall": 0.087945,
        "f1": 0.06137,
        "accuracy": 0.087945,
        "main_score": 0.06137,
        "hf_subset": "deu_Latn-ary_Arab",
        "languages": [
          "deu-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.03651,
        "recall": 0.061265,
        "f1": 0.040781,
        "accuracy": 0.061265,
        "main_score": 0.040781,
        "hf_subset": "hat_Latn-ary_Arab",
        "languages": [
          "hat-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.002142,
        "recall": 0.004941,
        "f1": 0.002637,
        "accuracy": 0.004941,
        "main_score": 0.002637,
        "hf_subset": "kbp_Latn-ary_Arab",
        "languages": [
          "kbp-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.04553,
        "recall": 0.072134,
        "f1": 0.050383,
        "accuracy": 0.072134,
        "main_score": 0.050383,
        "hf_subset": "luo_Latn-ary_Arab",
        "languages": [
          "luo-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 2e-06,
        "accuracy": 0.000988,
        "main_score": 2e-06,
        "hf_subset": "ory_Orya-ary_Arab",
        "languages": [
          "ory-Orya",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.023808,
        "recall": 0.041502,
        "f1": 0.02634,
        "accuracy": 0.041502,
        "main_score": 0.02634,
        "hf_subset": "sna_Latn-ary_Arab",
        "languages": [
          "sna-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.027467,
        "recall": 0.047431,
        "f1": 0.030613,
        "accuracy": 0.047431,
        "main_score": 0.030613,
        "hf_subset": "tso_Latn-ary_Arab",
        "languages": [
          "tso-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.017516,
        "recall": 0.029644,
        "f1": 0.019699,
        "accuracy": 0.029644,
        "main_score": 0.019699,
        "hf_subset": "azj_Latn-ary_Arab",
        "languages": [
          "azj-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.029402,
        "recall": 0.041502,
        "f1": 0.031303,
        "accuracy": 0.041502,
        "main_score": 0.031303,
        "hf_subset": "dik_Latn-ary_Arab",
        "languages": [
          "dik-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.039153,
        "recall": 0.067194,
        "f1": 0.044351,
        "accuracy": 0.067194,
        "main_score": 0.044351,
        "hf_subset": "hau_Latn-ary_Arab",
        "languages": [
          "hau-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.046225,
        "recall": 0.06917,
        "f1": 0.050963,
        "accuracy": 0.06917,
        "main_score": 0.050963,
        "hf_subset": "kea_Latn-ary_Arab",
        "languages": [
          "kea-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.088158,
        "recall": 0.119565,
        "f1": 0.095414,
        "accuracy": 0.119565,
        "main_score": 0.095414,
        "hf_subset": "lus_Latn-ary_Arab",
        "languages": [
          "lus-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.120797,
        "recall": 0.160079,
        "f1": 0.127938,
        "accuracy": 0.160079,
        "main_score": 0.127938,
        "hf_subset": "pag_Latn-ary_Arab",
        "languages": [
          "pag-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.019826,
        "recall": 0.032609,
        "f1": 0.022087,
        "accuracy": 0.032609,
        "main_score": 0.022087,
        "hf_subset": "snd_Arab-ary_Arab",
        "languages": [
          "snd-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.026709,
        "recall": 0.044466,
        "f1": 0.030088,
        "accuracy": 0.044466,
        "main_score": 0.030088,
        "hf_subset": "tuk_Latn-ary_Arab",
        "languages": [
          "tuk-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.011516,
        "recall": 0.01581,
        "f1": 0.012242,
        "accuracy": 0.01581,
        "main_score": 0.012242,
        "hf_subset": "bak_Cyrl-ary_Arab",
        "languages": [
          "bak-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.024615,
        "recall": 0.040514,
        "f1": 0.027101,
        "accuracy": 0.040514,
        "main_score": 0.027101,
        "hf_subset": "dyu_Latn-ary_Arab",
        "languages": [
          "dyu-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.031125,
        "recall": 0.049407,
        "f1": 0.034213,
        "accuracy": 0.049407,
        "main_score": 0.034213,
        "hf_subset": "heb_Hebr-ary_Arab",
        "languages": [
          "heb-Hebr",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.005118,
        "recall": 0.009881,
        "f1": 0.005594,
        "accuracy": 0.009881,
        "main_score": 0.005594,
        "hf_subset": "khk_Cyrl-ary_Arab",
        "languages": [
          "khk-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.0138,
        "recall": 0.021739,
        "f1": 0.015279,
        "accuracy": 0.021739,
        "main_score": 0.015279,
        "hf_subset": "lvs_Latn-ary_Arab",
        "languages": [
          "lvs-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 1e-06,
        "recall": 0.000988,
        "f1": 3e-06,
        "accuracy": 0.000988,
        "main_score": 3e-06,
        "hf_subset": "pan_Guru-ary_Arab",
        "languages": [
          "pan-Guru",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.020133,
        "recall": 0.033597,
        "f1": 0.021928,
        "accuracy": 0.033597,
        "main_score": 0.021928,
        "hf_subset": "som_Latn-ary_Arab",
        "languages": [
          "som-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.021473,
        "recall": 0.039526,
        "f1": 0.024108,
        "accuracy": 0.039526,
        "main_score": 0.024108,
        "hf_subset": "tum_Latn-ary_Arab",
        "languages": [
          "tum-Latn",
          "ary-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 58.71566343307495,
  "kg_co2_emissions": null
}