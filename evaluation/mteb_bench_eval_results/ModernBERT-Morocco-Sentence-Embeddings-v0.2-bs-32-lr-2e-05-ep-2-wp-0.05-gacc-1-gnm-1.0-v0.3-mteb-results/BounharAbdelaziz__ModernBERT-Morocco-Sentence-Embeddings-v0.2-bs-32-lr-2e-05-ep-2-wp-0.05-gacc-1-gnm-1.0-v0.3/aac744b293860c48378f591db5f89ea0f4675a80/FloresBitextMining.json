{
  "dataset_revision": "e6b647fcb6299a2f686f742f4d4c023e553ea67e",
  "task_name": "FloresBitextMining",
  "mteb_version": "1.34.22",
  "scores": {
    "devtest": [
      {
        "precision": 0.006914,
        "recall": 0.014822,
        "f1": 0.007769,
        "accuracy": 0.014822,
        "main_score": 0.007769,
        "hf_subset": "ace_Arab-ary_Arab",
        "languages": [
          "ace-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.02701,
        "recall": 0.04249,
        "f1": 0.029438,
        "accuracy": 0.04249,
        "main_score": 0.029438,
        "hf_subset": "bam_Latn-ary_Arab",
        "languages": [
          "bam-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.000132,
        "recall": 0.002964,
        "f1": 0.000237,
        "accuracy": 0.002964,
        "main_score": 0.000237,
        "hf_subset": "dzo_Tibt-ary_Arab",
        "languages": [
          "dzo-Tibt",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.003987,
        "recall": 0.005929,
        "f1": 0.004018,
        "accuracy": 0.005929,
        "main_score": 0.004018,
        "hf_subset": "hin_Deva-ary_Arab",
        "languages": [
          "hin-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.000494,
        "recall": 0.000988,
        "f1": 0.000659,
        "accuracy": 0.000988,
        "main_score": 0.000659,
        "hf_subset": "khm_Khmr-ary_Arab",
        "languages": [
          "khm-Khmr",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.002175,
        "recall": 0.003953,
        "f1": 0.002308,
        "accuracy": 0.003953,
        "main_score": 0.002308,
        "hf_subset": "mag_Deva-ary_Arab",
        "languages": [
          "mag-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.035481,
        "recall": 0.059289,
        "f1": 0.039497,
        "accuracy": 0.059289,
        "main_score": 0.039497,
        "hf_subset": "pap_Latn-ary_Arab",
        "languages": [
          "pap-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.020214,
        "recall": 0.036561,
        "f1": 0.023058,
        "accuracy": 0.036561,
        "main_score": 0.023058,
        "hf_subset": "sot_Latn-ary_Arab",
        "languages": [
          "sot-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.02748,
        "recall": 0.052372,
        "f1": 0.030572,
        "accuracy": 0.052372,
        "main_score": 0.030572,
        "hf_subset": "tur_Latn-ary_Arab",
        "languages": [
          "tur-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.034273,
        "recall": 0.057312,
        "f1": 0.038816,
        "accuracy": 0.057312,
        "main_score": 0.038816,
        "hf_subset": "ace_Latn-ary_Arab",
        "languages": [
          "ace-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.043103,
        "recall": 0.063241,
        "f1": 0.047381,
        "accuracy": 0.063241,
        "main_score": 0.047381,
        "hf_subset": "ban_Latn-ary_Arab",
        "languages": [
          "ban-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.001999,
        "recall": 0.007905,
        "f1": 0.002478,
        "accuracy": 0.007905,
        "main_score": 0.002478,
        "hf_subset": "ell_Grek-ary_Arab",
        "languages": [
          "ell-Grek",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.001297,
        "recall": 0.003953,
        "f1": 0.001518,
        "accuracy": 0.003953,
        "main_score": 0.001518,
        "hf_subset": "hne_Deva-ary_Arab",
        "languages": [
          "hne-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.015925,
        "recall": 0.025692,
        "f1": 0.017164,
        "accuracy": 0.025692,
        "main_score": 0.017164,
        "hf_subset": "kik_Latn-ary_Arab",
        "languages": [
          "kik-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.002382,
        "recall": 0.005929,
        "f1": 0.002679,
        "accuracy": 0.005929,
        "main_score": 0.002679,
        "hf_subset": "mai_Deva-ary_Arab",
        "languages": [
          "mai-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.007241,
        "recall": 0.019763,
        "f1": 0.008426,
        "accuracy": 0.019763,
        "main_score": 0.008426,
        "hf_subset": "pbt_Arab-ary_Arab",
        "languages": [
          "pbt-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.036615,
        "recall": 0.056324,
        "f1": 0.040535,
        "accuracy": 0.056324,
        "main_score": 0.040535,
        "hf_subset": "spa_Latn-ary_Arab",
        "languages": [
          "spa-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.031753,
        "recall": 0.047431,
        "f1": 0.034931,
        "accuracy": 0.047431,
        "main_score": 0.034931,
        "hf_subset": "twi_Latn-ary_Arab",
        "languages": [
          "twi-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.472277,
        "recall": 0.58004,
        "f1": 0.503454,
        "accuracy": 0.58004,
        "main_score": 0.503454,
        "hf_subset": "acm_Arab-ary_Arab",
        "languages": [
          "acm-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.002625,
        "recall": 0.005929,
        "f1": 0.003,
        "accuracy": 0.005929,
        "main_score": 0.003,
        "hf_subset": "bel_Cyrl-ary_Arab",
        "languages": [
          "bel-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.127711,
        "recall": 0.173913,
        "f1": 0.138992,
        "accuracy": 0.173913,
        "main_score": 0.138992,
        "hf_subset": "eng_Latn-ary_Arab",
        "languages": [
          "eng-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.028706,
        "recall": 0.048419,
        "f1": 0.032489,
        "accuracy": 0.048419,
        "main_score": 0.032489,
        "hf_subset": "hrv_Latn-ary_Arab",
        "languages": [
          "hrv-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.025425,
        "recall": 0.040514,
        "f1": 0.028467,
        "accuracy": 0.040514,
        "main_score": 0.028467,
        "hf_subset": "kin_Latn-ary_Arab",
        "languages": [
          "kin-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.001049,
        "recall": 0.003953,
        "f1": 0.001107,
        "accuracy": 0.003953,
        "main_score": 0.001107,
        "hf_subset": "mal_Mlym-ary_Arab",
        "languages": [
          "mal-Mlym",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.012656,
        "recall": 0.018775,
        "f1": 0.013403,
        "accuracy": 0.018775,
        "main_score": 0.013403,
        "hf_subset": "pes_Arab-ary_Arab",
        "languages": [
          "pes-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.046088,
        "recall": 0.071146,
        "f1": 0.051834,
        "accuracy": 0.071146,
        "main_score": 0.051834,
        "hf_subset": "srd_Latn-ary_Arab",
        "languages": [
          "srd-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.004128,
        "recall": 0.007905,
        "f1": 0.004596,
        "accuracy": 0.007905,
        "main_score": 0.004596,
        "hf_subset": "tzm_Tfng-ary_Arab",
        "languages": [
          "tzm-Tfng",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.483623,
        "recall": 0.586957,
        "f1": 0.51318,
        "accuracy": 0.586957,
        "main_score": 0.51318,
        "hf_subset": "acq_Arab-ary_Arab",
        "languages": [
          "acq-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.017594,
        "recall": 0.033597,
        "f1": 0.020357,
        "accuracy": 0.033597,
        "main_score": 0.020357,
        "hf_subset": "bem_Latn-ary_Arab",
        "languages": [
          "bem-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.040928,
        "recall": 0.063241,
        "f1": 0.045079,
        "accuracy": 0.063241,
        "main_score": 0.045079,
        "hf_subset": "epo_Latn-ary_Arab",
        "languages": [
          "epo-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.019592,
        "recall": 0.035573,
        "f1": 0.022415,
        "accuracy": 0.035573,
        "main_score": 0.022415,
        "hf_subset": "hun_Latn-ary_Arab",
        "languages": [
          "hun-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.000796,
        "recall": 0.004941,
        "f1": 0.001159,
        "accuracy": 0.004941,
        "main_score": 0.001159,
        "hf_subset": "kir_Cyrl-ary_Arab",
        "languages": [
          "kir-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.002066,
        "recall": 0.005929,
        "f1": 0.00255,
        "accuracy": 0.005929,
        "main_score": 0.00255,
        "hf_subset": "mar_Deva-ary_Arab",
        "languages": [
          "mar-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.020346,
        "recall": 0.037549,
        "f1": 0.022895,
        "accuracy": 0.037549,
        "main_score": 0.022895,
        "hf_subset": "plt_Latn-ary_Arab",
        "languages": [
          "plt-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.004951,
        "recall": 0.006917,
        "f1": 0.004961,
        "accuracy": 0.006917,
        "main_score": 0.004961,
        "hf_subset": "srp_Cyrl-ary_Arab",
        "languages": [
          "srp-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.007416,
        "recall": 0.008893,
        "f1": 0.007585,
        "accuracy": 0.008893,
        "main_score": 0.007585,
        "hf_subset": "uig_Arab-ary_Arab",
        "languages": [
          "uig-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.478755,
        "recall": 0.572134,
        "f1": 0.506363,
        "accuracy": 0.572134,
        "main_score": 0.506363,
        "hf_subset": "aeb_Arab-ary_Arab",
        "languages": [
          "aeb-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.001088,
        "recall": 0.003953,
        "f1": 0.001173,
        "accuracy": 0.003953,
        "main_score": 0.001173,
        "hf_subset": "ben_Beng-ary_Arab",
        "languages": [
          "ben-Beng",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.022539,
        "recall": 0.041502,
        "f1": 0.0255,
        "accuracy": 0.041502,
        "main_score": 0.0255,
        "hf_subset": "est_Latn-ary_Arab",
        "languages": [
          "est-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.000122,
        "recall": 0.002964,
        "f1": 0.00023,
        "accuracy": 0.002964,
        "main_score": 0.00023,
        "hf_subset": "hye_Armn-ary_Arab",
        "languages": [
          "hye-Armn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.014351,
        "recall": 0.031621,
        "f1": 0.016519,
        "accuracy": 0.031621,
        "main_score": 0.016519,
        "hf_subset": "kmb_Latn-ary_Arab",
        "languages": [
          "kmb-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.001392,
        "recall": 0.008893,
        "f1": 0.002093,
        "accuracy": 0.008893,
        "main_score": 0.002093,
        "hf_subset": "min_Arab-ary_Arab",
        "languages": [
          "min-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.017735,
        "recall": 0.035573,
        "f1": 0.020592,
        "accuracy": 0.035573,
        "main_score": 0.020592,
        "hf_subset": "pol_Latn-ary_Arab",
        "languages": [
          "pol-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.018434,
        "recall": 0.034585,
        "f1": 0.020644,
        "accuracy": 0.034585,
        "main_score": 0.020644,
        "hf_subset": "ssw_Latn-ary_Arab",
        "languages": [
          "ssw-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.001593,
        "recall": 0.003953,
        "f1": 0.001847,
        "accuracy": 0.003953,
        "main_score": 0.001847,
        "hf_subset": "ukr_Cyrl-ary_Arab",
        "languages": [
          "ukr-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.051786,
        "recall": 0.074111,
        "f1": 0.056551,
        "accuracy": 0.074111,
        "main_score": 0.056551,
        "hf_subset": "afr_Latn-ary_Arab",
        "languages": [
          "afr-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.002674,
        "recall": 0.006917,
        "f1": 0.003092,
        "accuracy": 0.006917,
        "main_score": 0.003092,
        "hf_subset": "bho_Deva-ary_Arab",
        "languages": [
          "bho-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.019498,
        "recall": 0.038538,
        "f1": 0.022596,
        "accuracy": 0.038538,
        "main_score": 0.022596,
        "hf_subset": "eus_Latn-ary_Arab",
        "languages": [
          "eus-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.026519,
        "recall": 0.040514,
        "f1": 0.028774,
        "accuracy": 0.040514,
        "main_score": 0.028774,
        "hf_subset": "ibo_Latn-ary_Arab",
        "languages": [
          "ibo-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.028837,
        "recall": 0.05336,
        "f1": 0.032956,
        "accuracy": 0.05336,
        "main_score": 0.032956,
        "hf_subset": "kmr_Latn-ary_Arab",
        "languages": [
          "kmr-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.030059,
        "recall": 0.05336,
        "f1": 0.034717,
        "accuracy": 0.05336,
        "main_score": 0.034717,
        "hf_subset": "min_Latn-ary_Arab",
        "languages": [
          "min-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.053459,
        "recall": 0.081028,
        "f1": 0.059452,
        "accuracy": 0.081028,
        "main_score": 0.059452,
        "hf_subset": "por_Latn-ary_Arab",
        "languages": [
          "por-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.047485,
        "recall": 0.074111,
        "f1": 0.051996,
        "accuracy": 0.074111,
        "main_score": 0.051996,
        "hf_subset": "sun_Latn-ary_Arab",
        "languages": [
          "sun-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.024318,
        "recall": 0.040514,
        "f1": 0.027412,
        "accuracy": 0.040514,
        "main_score": 0.027412,
        "hf_subset": "umb_Latn-ary_Arab",
        "languages": [
          "umb-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.49226,
        "recall": 0.592885,
        "f1": 0.521453,
        "accuracy": 0.592885,
        "main_score": 0.521453,
        "hf_subset": "ajp_Arab-ary_Arab",
        "languages": [
          "ajp-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.007157,
        "recall": 0.012846,
        "f1": 0.007874,
        "accuracy": 0.012846,
        "main_score": 0.007874,
        "hf_subset": "bjn_Arab-ary_Arab",
        "languages": [
          "bjn-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.025364,
        "recall": 0.04249,
        "f1": 0.028683,
        "accuracy": 0.04249,
        "main_score": 0.028683,
        "hf_subset": "ewe_Latn-ary_Arab",
        "languages": [
          "ewe-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.031865,
        "recall": 0.051383,
        "f1": 0.035966,
        "accuracy": 0.051383,
        "main_score": 0.035966,
        "hf_subset": "ilo_Latn-ary_Arab",
        "languages": [
          "ilo-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.008475,
        "recall": 0.013834,
        "f1": 0.009216,
        "accuracy": 0.013834,
        "main_score": 0.009216,
        "hf_subset": "knc_Arab-ary_Arab",
        "languages": [
          "knc-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.002335,
        "recall": 0.006917,
        "f1": 0.00258,
        "accuracy": 0.006917,
        "main_score": 0.00258,
        "hf_subset": "mkd_Cyrl-ary_Arab",
        "languages": [
          "mkd-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.020422,
        "recall": 0.031621,
        "f1": 0.021969,
        "accuracy": 0.031621,
        "main_score": 0.021969,
        "hf_subset": "prs_Arab-ary_Arab",
        "languages": [
          "prs-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.046721,
        "recall": 0.075099,
        "f1": 0.052212,
        "accuracy": 0.075099,
        "main_score": 0.052212,
        "hf_subset": "swe_Latn-ary_Arab",
        "languages": [
          "swe-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.004069,
        "recall": 0.01087,
        "f1": 0.004671,
        "accuracy": 0.01087,
        "main_score": 0.004671,
        "hf_subset": "urd_Arab-ary_Arab",
        "languages": [
          "urd-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.033438,
        "recall": 0.054348,
        "f1": 0.037147,
        "accuracy": 0.054348,
        "main_score": 0.037147,
        "hf_subset": "aka_Latn-ary_Arab",
        "languages": [
          "aka-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.036442,
        "recall": 0.064229,
        "f1": 0.041457,
        "accuracy": 0.064229,
        "main_score": 0.041457,
        "hf_subset": "bjn_Latn-ary_Arab",
        "languages": [
          "bjn-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.029922,
        "recall": 0.051383,
        "f1": 0.033886,
        "accuracy": 0.051383,
        "main_score": 0.033886,
        "hf_subset": "fao_Latn-ary_Arab",
        "languages": [
          "fao-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.03744,
        "recall": 0.064229,
        "f1": 0.042138,
        "accuracy": 0.064229,
        "main_score": 0.042138,
        "hf_subset": "ind_Latn-ary_Arab",
        "languages": [
          "ind-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.030647,
        "recall": 0.049407,
        "f1": 0.033734,
        "accuracy": 0.049407,
        "main_score": 0.033734,
        "hf_subset": "knc_Latn-ary_Arab",
        "languages": [
          "knc-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.02815,
        "recall": 0.048419,
        "f1": 0.032275,
        "accuracy": 0.048419,
        "main_score": 0.032275,
        "hf_subset": "mlt_Latn-ary_Arab",
        "languages": [
          "mlt-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.016869,
        "recall": 0.033597,
        "f1": 0.01957,
        "accuracy": 0.033597,
        "main_score": 0.01957,
        "hf_subset": "quy_Latn-ary_Arab",
        "languages": [
          "quy-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.019137,
        "recall": 0.035573,
        "f1": 0.022034,
        "accuracy": 0.035573,
        "main_score": 0.022034,
        "hf_subset": "swh_Latn-ary_Arab",
        "languages": [
          "swh-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.019667,
        "recall": 0.035573,
        "f1": 0.022495,
        "accuracy": 0.035573,
        "main_score": 0.022495,
        "hf_subset": "uzn_Latn-ary_Arab",
        "languages": [
          "uzn-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.031699,
        "recall": 0.049407,
        "f1": 0.034733,
        "accuracy": 0.049407,
        "main_score": 0.034733,
        "hf_subset": "als_Latn-ary_Arab",
        "languages": [
          "als-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.000991,
        "recall": 0.001976,
        "f1": 0.000994,
        "accuracy": 0.001976,
        "main_score": 0.000994,
        "hf_subset": "bod_Tibt-ary_Arab",
        "languages": [
          "bod-Tibt",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.019285,
        "recall": 0.038538,
        "f1": 0.021876,
        "accuracy": 0.038538,
        "main_score": 0.021876,
        "hf_subset": "fij_Latn-ary_Arab",
        "languages": [
          "fij-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.03536,
        "recall": 0.060277,
        "f1": 0.040343,
        "accuracy": 0.060277,
        "main_score": 0.040343,
        "hf_subset": "isl_Latn-ary_Arab",
        "languages": [
          "isl-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.021746,
        "recall": 0.032609,
        "f1": 0.023549,
        "accuracy": 0.032609,
        "main_score": 0.023549,
        "hf_subset": "kon_Latn-ary_Arab",
        "languages": [
          "kon-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.001661,
        "recall": 0.005929,
        "f1": 0.002004,
        "accuracy": 0.005929,
        "main_score": 0.002004,
        "hf_subset": "mni_Beng-ary_Arab",
        "languages": [
          "mni-Beng",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.039446,
        "recall": 0.063241,
        "f1": 0.044186,
        "accuracy": 0.063241,
        "main_score": 0.044186,
        "hf_subset": "ron_Latn-ary_Arab",
        "languages": [
          "ron-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.022737,
        "recall": 0.034585,
        "f1": 0.024959,
        "accuracy": 0.034585,
        "main_score": 0.024959,
        "hf_subset": "szl_Latn-ary_Arab",
        "languages": [
          "szl-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.055858,
        "recall": 0.079051,
        "f1": 0.061192,
        "accuracy": 0.079051,
        "main_score": 0.061192,
        "hf_subset": "vec_Latn-ary_Arab",
        "languages": [
          "vec-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.00589,
        "recall": 0.012846,
        "f1": 0.006845,
        "accuracy": 0.012846,
        "main_score": 0.006845,
        "hf_subset": "amh_Ethi-ary_Arab",
        "languages": [
          "amh-Ethi",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.025014,
        "recall": 0.044466,
        "f1": 0.027945,
        "accuracy": 0.044466,
        "main_score": 0.027945,
        "hf_subset": "bos_Latn-ary_Arab",
        "languages": [
          "bos-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.022084,
        "recall": 0.039526,
        "f1": 0.025394,
        "accuracy": 0.039526,
        "main_score": 0.025394,
        "hf_subset": "fin_Latn-ary_Arab",
        "languages": [
          "fin-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.042567,
        "recall": 0.067194,
        "f1": 0.047746,
        "accuracy": 0.067194,
        "main_score": 0.047746,
        "hf_subset": "ita_Latn-ary_Arab",
        "languages": [
          "ita-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.009468,
        "recall": 0.024704,
        "f1": 0.011575,
        "accuracy": 0.024704,
        "main_score": 0.011575,
        "hf_subset": "kor_Hang-ary_Arab",
        "languages": [
          "kor-Hang",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.020083,
        "recall": 0.035573,
        "f1": 0.022234,
        "accuracy": 0.035573,
        "main_score": 0.022234,
        "hf_subset": "mos_Latn-ary_Arab",
        "languages": [
          "mos-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.024587,
        "recall": 0.041502,
        "f1": 0.027189,
        "accuracy": 0.041502,
        "main_score": 0.027189,
        "hf_subset": "run_Latn-ary_Arab",
        "languages": [
          "run-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.000221,
        "recall": 0.003953,
        "f1": 0.000406,
        "accuracy": 0.003953,
        "main_score": 0.000406,
        "hf_subset": "tam_Taml-ary_Arab",
        "languages": [
          "tam-Taml",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.026438,
        "recall": 0.04249,
        "f1": 0.029069,
        "accuracy": 0.04249,
        "main_score": 0.029069,
        "hf_subset": "vie_Latn-ary_Arab",
        "languages": [
          "vie-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.487773,
        "recall": 0.579051,
        "f1": 0.514514,
        "accuracy": 0.579051,
        "main_score": 0.514514,
        "hf_subset": "apc_Arab-ary_Arab",
        "languages": [
          "apc-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.031527,
        "recall": 0.051383,
        "f1": 0.034323,
        "accuracy": 0.051383,
        "main_score": 0.034323,
        "hf_subset": "bug_Latn-ary_Arab",
        "languages": [
          "bug-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.016027,
        "recall": 0.02668,
        "f1": 0.018047,
        "accuracy": 0.02668,
        "main_score": 0.018047,
        "hf_subset": "fon_Latn-ary_Arab",
        "languages": [
          "fon-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.036157,
        "recall": 0.059289,
        "f1": 0.040134,
        "accuracy": 0.059289,
        "main_score": 0.040134,
        "hf_subset": "jav_Latn-ary_Arab",
        "languages": [
          "jav-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.000678,
        "recall": 0.003953,
        "f1": 0.000978,
        "accuracy": 0.003953,
        "main_score": 0.000978,
        "hf_subset": "lao_Laoo-ary_Arab",
        "languages": [
          "lao-Laoo",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.025906,
        "recall": 0.043478,
        "f1": 0.028883,
        "accuracy": 0.043478,
        "main_score": 0.028883,
        "hf_subset": "mri_Latn-ary_Arab",
        "languages": [
          "mri-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.00411,
        "recall": 0.007905,
        "f1": 0.004561,
        "accuracy": 0.007905,
        "main_score": 0.004561,
        "hf_subset": "rus_Cyrl-ary_Arab",
        "languages": [
          "rus-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.040774,
        "recall": 0.061265,
        "f1": 0.045082,
        "accuracy": 0.061265,
        "main_score": 0.045082,
        "hf_subset": "taq_Latn-ary_Arab",
        "languages": [
          "taq-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.037586,
        "recall": 0.055336,
        "f1": 0.040562,
        "accuracy": 0.055336,
        "main_score": 0.040562,
        "hf_subset": "war_Latn-ary_Arab",
        "languages": [
          "war-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.466797,
        "recall": 0.574111,
        "f1": 0.496793,
        "accuracy": 0.574111,
        "main_score": 0.496793,
        "hf_subset": "arb_Arab-ary_Arab",
        "languages": [
          "arb-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.004064,
        "recall": 0.005929,
        "f1": 0.004153,
        "accuracy": 0.005929,
        "main_score": 0.004153,
        "hf_subset": "bul_Cyrl-ary_Arab",
        "languages": [
          "bul-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.045453,
        "recall": 0.068182,
        "f1": 0.050209,
        "accuracy": 0.068182,
        "main_score": 0.050209,
        "hf_subset": "fra_Latn-ary_Arab",
        "languages": [
          "fra-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.004396,
        "recall": 0.009881,
        "f1": 0.005191,
        "accuracy": 0.009881,
        "main_score": 0.005191,
        "hf_subset": "jpn_Jpan-ary_Arab",
        "languages": [
          "jpn-Jpan",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.038015,
        "recall": 0.0583,
        "f1": 0.042409,
        "accuracy": 0.0583,
        "main_score": 0.042409,
        "hf_subset": "lij_Latn-ary_Arab",
        "languages": [
          "lij-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.001064,
        "recall": 0.003953,
        "f1": 0.001134,
        "accuracy": 0.003953,
        "main_score": 0.001134,
        "hf_subset": "mya_Mymr-ary_Arab",
        "languages": [
          "mya-Mymr",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.019665,
        "recall": 0.034585,
        "f1": 0.021413,
        "accuracy": 0.034585,
        "main_score": 0.021413,
        "hf_subset": "sag_Latn-ary_Arab",
        "languages": [
          "sag-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.003867,
        "recall": 0.008893,
        "f1": 0.004271,
        "accuracy": 0.008893,
        "main_score": 0.004271,
        "hf_subset": "taq_Tfng-ary_Arab",
        "languages": [
          "taq-Tfng",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.02771,
        "recall": 0.048419,
        "f1": 0.031601,
        "accuracy": 0.048419,
        "main_score": 0.031601,
        "hf_subset": "wol_Latn-ary_Arab",
        "languages": [
          "wol-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.00437,
        "recall": 0.012846,
        "f1": 0.005523,
        "accuracy": 0.012846,
        "main_score": 0.005523,
        "hf_subset": "arb_Latn-ary_Arab",
        "languages": [
          "arb-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.046873,
        "recall": 0.072134,
        "f1": 0.052563,
        "accuracy": 0.072134,
        "main_score": 0.052563,
        "hf_subset": "cat_Latn-ary_Arab",
        "languages": [
          "cat-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.053715,
        "recall": 0.076087,
        "f1": 0.057861,
        "accuracy": 0.076087,
        "main_score": 0.057861,
        "hf_subset": "fur_Latn-ary_Arab",
        "languages": [
          "fur-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.028414,
        "recall": 0.046443,
        "f1": 0.032168,
        "accuracy": 0.046443,
        "main_score": 0.032168,
        "hf_subset": "kab_Latn-ary_Arab",
        "languages": [
          "kab-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.042265,
        "recall": 0.062253,
        "f1": 0.045989,
        "accuracy": 0.062253,
        "main_score": 0.045989,
        "hf_subset": "lim_Latn-ary_Arab",
        "languages": [
          "lim-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.045141,
        "recall": 0.065217,
        "f1": 0.049125,
        "accuracy": 0.065217,
        "main_score": 0.049125,
        "hf_subset": "nld_Latn-ary_Arab",
        "languages": [
          "nld-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.001487,
        "recall": 0.003953,
        "f1": 0.001657,
        "accuracy": 0.003953,
        "main_score": 0.001657,
        "hf_subset": "san_Deva-ary_Arab",
        "languages": [
          "san-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.005524,
        "recall": 0.008893,
        "f1": 0.005766,
        "accuracy": 0.008893,
        "main_score": 0.005766,
        "hf_subset": "tat_Cyrl-ary_Arab",
        "languages": [
          "tat-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.022474,
        "recall": 0.039526,
        "f1": 0.025219,
        "accuracy": 0.039526,
        "main_score": 0.025219,
        "hf_subset": "xho_Latn-ary_Arab",
        "languages": [
          "xho-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.450805,
        "recall": 0.560277,
        "f1": 0.480993,
        "accuracy": 0.560277,
        "main_score": 0.480993,
        "hf_subset": "ars_Arab-ary_Arab",
        "languages": [
          "ars-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.042766,
        "recall": 0.064229,
        "f1": 0.046846,
        "accuracy": 0.064229,
        "main_score": 0.046846,
        "hf_subset": "ceb_Latn-ary_Arab",
        "languages": [
          "ceb-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.022619,
        "recall": 0.039526,
        "f1": 0.025819,
        "accuracy": 0.039526,
        "main_score": 0.025819,
        "hf_subset": "fuv_Latn-ary_Arab",
        "languages": [
          "fuv-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.018134,
        "recall": 0.031621,
        "f1": 0.020222,
        "accuracy": 0.031621,
        "main_score": 0.020222,
        "hf_subset": "kac_Latn-ary_Arab",
        "languages": [
          "kac-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.030841,
        "recall": 0.047431,
        "f1": 0.034803,
        "accuracy": 0.047431,
        "main_score": 0.034803,
        "hf_subset": "lin_Latn-ary_Arab",
        "languages": [
          "lin-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.040987,
        "recall": 0.065217,
        "f1": 0.045807,
        "accuracy": 0.065217,
        "main_score": 0.045807,
        "hf_subset": "nno_Latn-ary_Arab",
        "languages": [
          "nno-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.001018,
        "recall": 0.001976,
        "f1": 0.001046,
        "accuracy": 0.001976,
        "main_score": 0.001046,
        "hf_subset": "sat_Olck-ary_Arab",
        "languages": [
          "sat-Olck",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.00346,
        "recall": 0.005929,
        "f1": 0.003955,
        "accuracy": 0.005929,
        "main_score": 0.003955,
        "hf_subset": "tel_Telu-ary_Arab",
        "languages": [
          "tel-Telu",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.008929,
        "recall": 0.016798,
        "f1": 0.009445,
        "accuracy": 0.016798,
        "main_score": 0.009445,
        "hf_subset": "ydd_Hebr-ary_Arab",
        "languages": [
          "ydd-Hebr",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.01026,
        "recall": 0.019763,
        "f1": 0.011627,
        "accuracy": 0.019763,
        "main_score": 0.011627,
        "hf_subset": "ary_Arab-ace_Arab",
        "languages": [
          "ary-Arab",
          "ace-Arab"
        ]
      },
      {
        "precision": 0.036908,
        "recall": 0.0583,
        "f1": 0.041962,
        "accuracy": 0.0583,
        "main_score": 0.041962,
        "hf_subset": "ary_Arab-bam_Latn",
        "languages": [
          "ary-Arab",
          "bam-Latn"
        ]
      },
      {
        "precision": 1.5e-05,
        "recall": 0.001976,
        "f1": 3e-05,
        "accuracy": 0.001976,
        "main_score": 3e-05,
        "hf_subset": "ary_Arab-dzo_Tibt",
        "languages": [
          "ary-Arab",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.003738,
        "recall": 0.009881,
        "f1": 0.004608,
        "accuracy": 0.009881,
        "main_score": 0.004608,
        "hf_subset": "ary_Arab-hin_Deva",
        "languages": [
          "ary-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.002694,
        "recall": 0.009881,
        "f1": 0.003188,
        "accuracy": 0.009881,
        "main_score": 0.003188,
        "hf_subset": "ary_Arab-khm_Khmr",
        "languages": [
          "ary-Arab",
          "khm-Khmr"
        ]
      },
      {
        "precision": 0.004471,
        "recall": 0.012846,
        "f1": 0.004912,
        "accuracy": 0.012846,
        "main_score": 0.004912,
        "hf_subset": "ary_Arab-mag_Deva",
        "languages": [
          "ary-Arab",
          "mag-Deva"
        ]
      },
      {
        "precision": 0.046645,
        "recall": 0.070158,
        "f1": 0.05154,
        "accuracy": 0.070158,
        "main_score": 0.05154,
        "hf_subset": "ary_Arab-pap_Latn",
        "languages": [
          "ary-Arab",
          "pap-Latn"
        ]
      },
      {
        "precision": 0.029513,
        "recall": 0.052372,
        "f1": 0.033785,
        "accuracy": 0.052372,
        "main_score": 0.033785,
        "hf_subset": "ary_Arab-sot_Latn",
        "languages": [
          "ary-Arab",
          "sot-Latn"
        ]
      },
      {
        "precision": 0.027174,
        "recall": 0.046443,
        "f1": 0.030169,
        "accuracy": 0.046443,
        "main_score": 0.030169,
        "hf_subset": "ary_Arab-tur_Latn",
        "languages": [
          "ary-Arab",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.041662,
        "recall": 0.066206,
        "f1": 0.047099,
        "accuracy": 0.066206,
        "main_score": 0.047099,
        "hf_subset": "ary_Arab-ace_Latn",
        "languages": [
          "ary-Arab",
          "ace-Latn"
        ]
      },
      {
        "precision": 0.047564,
        "recall": 0.075099,
        "f1": 0.053041,
        "accuracy": 0.075099,
        "main_score": 0.053041,
        "hf_subset": "ary_Arab-ban_Latn",
        "languages": [
          "ary-Arab",
          "ban-Latn"
        ]
      },
      {
        "precision": 0.004414,
        "recall": 0.012846,
        "f1": 0.005608,
        "accuracy": 0.012846,
        "main_score": 0.005608,
        "hf_subset": "ary_Arab-ell_Grek",
        "languages": [
          "ary-Arab",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.002926,
        "recall": 0.011858,
        "f1": 0.003601,
        "accuracy": 0.011858,
        "main_score": 0.003601,
        "hf_subset": "ary_Arab-hne_Deva",
        "languages": [
          "ary-Arab",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.016388,
        "recall": 0.030632,
        "f1": 0.018841,
        "accuracy": 0.030632,
        "main_score": 0.018841,
        "hf_subset": "ary_Arab-kik_Latn",
        "languages": [
          "ary-Arab",
          "kik-Latn"
        ]
      },
      {
        "precision": 0.003359,
        "recall": 0.008893,
        "f1": 0.00407,
        "accuracy": 0.008893,
        "main_score": 0.00407,
        "hf_subset": "ary_Arab-mai_Deva",
        "languages": [
          "ary-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.015247,
        "recall": 0.031621,
        "f1": 0.017718,
        "accuracy": 0.031621,
        "main_score": 0.017718,
        "hf_subset": "ary_Arab-pbt_Arab",
        "languages": [
          "ary-Arab",
          "pbt-Arab"
        ]
      },
      {
        "precision": 0.044778,
        "recall": 0.074111,
        "f1": 0.050781,
        "accuracy": 0.074111,
        "main_score": 0.050781,
        "hf_subset": "ary_Arab-spa_Latn",
        "languages": [
          "ary-Arab",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.029144,
        "recall": 0.049407,
        "f1": 0.033261,
        "accuracy": 0.049407,
        "main_score": 0.033261,
        "hf_subset": "ary_Arab-twi_Latn",
        "languages": [
          "ary-Arab",
          "twi-Latn"
        ]
      },
      {
        "precision": 0.483541,
        "recall": 0.571146,
        "f1": 0.508013,
        "accuracy": 0.571146,
        "main_score": 0.508013,
        "hf_subset": "ary_Arab-acm_Arab",
        "languages": [
          "ary-Arab",
          "acm-Arab"
        ]
      },
      {
        "precision": 0.003949,
        "recall": 0.01581,
        "f1": 0.005175,
        "accuracy": 0.01581,
        "main_score": 0.005175,
        "hf_subset": "ary_Arab-bel_Cyrl",
        "languages": [
          "ary-Arab",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.105439,
        "recall": 0.152174,
        "f1": 0.116995,
        "accuracy": 0.152174,
        "main_score": 0.116995,
        "hf_subset": "ary_Arab-eng_Latn",
        "languages": [
          "ary-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.028344,
        "recall": 0.050395,
        "f1": 0.032644,
        "accuracy": 0.050395,
        "main_score": 0.032644,
        "hf_subset": "ary_Arab-hrv_Latn",
        "languages": [
          "ary-Arab",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.034918,
        "recall": 0.054348,
        "f1": 0.038424,
        "accuracy": 0.054348,
        "main_score": 0.038424,
        "hf_subset": "ary_Arab-kin_Latn",
        "languages": [
          "ary-Arab",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.002314,
        "recall": 0.006917,
        "f1": 0.002547,
        "accuracy": 0.006917,
        "main_score": 0.002547,
        "hf_subset": "ary_Arab-mal_Mlym",
        "languages": [
          "ary-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.016438,
        "recall": 0.038538,
        "f1": 0.018972,
        "accuracy": 0.038538,
        "main_score": 0.018972,
        "hf_subset": "ary_Arab-pes_Arab",
        "languages": [
          "ary-Arab",
          "pes-Arab"
        ]
      },
      {
        "precision": 0.063041,
        "recall": 0.092885,
        "f1": 0.069108,
        "accuracy": 0.092885,
        "main_score": 0.069108,
        "hf_subset": "ary_Arab-srd_Latn",
        "languages": [
          "ary-Arab",
          "srd-Latn"
        ]
      },
      {
        "precision": 0.005098,
        "recall": 0.012846,
        "f1": 0.005756,
        "accuracy": 0.012846,
        "main_score": 0.005756,
        "hf_subset": "ary_Arab-tzm_Tfng",
        "languages": [
          "ary-Arab",
          "tzm-Tfng"
        ]
      },
      {
        "precision": 0.488877,
        "recall": 0.582016,
        "f1": 0.514628,
        "accuracy": 0.582016,
        "main_score": 0.514628,
        "hf_subset": "ary_Arab-acq_Arab",
        "languages": [
          "ary-Arab",
          "acq-Arab"
        ]
      },
      {
        "precision": 0.031553,
        "recall": 0.054348,
        "f1": 0.035981,
        "accuracy": 0.054348,
        "main_score": 0.035981,
        "hf_subset": "ary_Arab-bem_Latn",
        "languages": [
          "ary-Arab",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.04578,
        "recall": 0.074111,
        "f1": 0.051515,
        "accuracy": 0.074111,
        "main_score": 0.051515,
        "hf_subset": "ary_Arab-epo_Latn",
        "languages": [
          "ary-Arab",
          "epo-Latn"
        ]
      },
      {
        "precision": 0.023465,
        "recall": 0.047431,
        "f1": 0.027794,
        "accuracy": 0.047431,
        "main_score": 0.027794,
        "hf_subset": "ary_Arab-hun_Latn",
        "languages": [
          "ary-Arab",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.006196,
        "recall": 0.020751,
        "f1": 0.007886,
        "accuracy": 0.020751,
        "main_score": 0.007886,
        "hf_subset": "ary_Arab-kir_Cyrl",
        "languages": [
          "ary-Arab",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.003559,
        "recall": 0.011858,
        "f1": 0.004031,
        "accuracy": 0.011858,
        "main_score": 0.004031,
        "hf_subset": "ary_Arab-mar_Deva",
        "languages": [
          "ary-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.024373,
        "recall": 0.043478,
        "f1": 0.027949,
        "accuracy": 0.043478,
        "main_score": 0.027949,
        "hf_subset": "ary_Arab-plt_Latn",
        "languages": [
          "ary-Arab",
          "plt-Latn"
        ]
      },
      {
        "precision": 0.003358,
        "recall": 0.008893,
        "f1": 0.003999,
        "accuracy": 0.008893,
        "main_score": 0.003999,
        "hf_subset": "ary_Arab-srp_Cyrl",
        "languages": [
          "ary-Arab",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.008646,
        "recall": 0.019763,
        "f1": 0.010142,
        "accuracy": 0.019763,
        "main_score": 0.010142,
        "hf_subset": "ary_Arab-uig_Arab",
        "languages": [
          "ary-Arab",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.476186,
        "recall": 0.560277,
        "f1": 0.499888,
        "accuracy": 0.560277,
        "main_score": 0.499888,
        "hf_subset": "ary_Arab-aeb_Arab",
        "languages": [
          "ary-Arab",
          "aeb-Arab"
        ]
      },
      {
        "precision": 0.005651,
        "recall": 0.017787,
        "f1": 0.007149,
        "accuracy": 0.017787,
        "main_score": 0.007149,
        "hf_subset": "ary_Arab-ben_Beng",
        "languages": [
          "ary-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.032975,
        "recall": 0.049407,
        "f1": 0.036313,
        "accuracy": 0.049407,
        "main_score": 0.036313,
        "hf_subset": "ary_Arab-est_Latn",
        "languages": [
          "ary-Arab",
          "est-Latn"
        ]
      },
      {
        "precision": 0.000141,
        "recall": 0.002964,
        "f1": 0.000255,
        "accuracy": 0.002964,
        "main_score": 0.000255,
        "hf_subset": "ary_Arab-hye_Armn",
        "languages": [
          "ary-Arab",
          "hye-Armn"
        ]
      },
      {
        "precision": 0.027216,
        "recall": 0.044466,
        "f1": 0.029891,
        "accuracy": 0.044466,
        "main_score": 0.029891,
        "hf_subset": "ary_Arab-kmb_Latn",
        "languages": [
          "ary-Arab",
          "kmb-Latn"
        ]
      },
      {
        "precision": 0.005446,
        "recall": 0.008893,
        "f1": 0.005782,
        "accuracy": 0.008893,
        "main_score": 0.005782,
        "hf_subset": "ary_Arab-min_Arab",
        "languages": [
          "ary-Arab",
          "min-Arab"
        ]
      },
      {
        "precision": 0.025845,
        "recall": 0.045455,
        "f1": 0.029876,
        "accuracy": 0.045455,
        "main_score": 0.029876,
        "hf_subset": "ary_Arab-pol_Latn",
        "languages": [
          "ary-Arab",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.02655,
        "recall": 0.049407,
        "f1": 0.031241,
        "accuracy": 0.049407,
        "main_score": 0.031241,
        "hf_subset": "ary_Arab-ssw_Latn",
        "languages": [
          "ary-Arab",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.008233,
        "recall": 0.019763,
        "f1": 0.00919,
        "accuracy": 0.019763,
        "main_score": 0.00919,
        "hf_subset": "ary_Arab-ukr_Cyrl",
        "languages": [
          "ary-Arab",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.04779,
        "recall": 0.073123,
        "f1": 0.052794,
        "accuracy": 0.073123,
        "main_score": 0.052794,
        "hf_subset": "ary_Arab-afr_Latn",
        "languages": [
          "ary-Arab",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.004208,
        "recall": 0.017787,
        "f1": 0.005775,
        "accuracy": 0.017787,
        "main_score": 0.005775,
        "hf_subset": "ary_Arab-bho_Deva",
        "languages": [
          "ary-Arab",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.028396,
        "recall": 0.049407,
        "f1": 0.032246,
        "accuracy": 0.049407,
        "main_score": 0.032246,
        "hf_subset": "ary_Arab-eus_Latn",
        "languages": [
          "ary-Arab",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.0304,
        "recall": 0.055336,
        "f1": 0.034874,
        "accuracy": 0.055336,
        "main_score": 0.034874,
        "hf_subset": "ary_Arab-ibo_Latn",
        "languages": [
          "ary-Arab",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.034499,
        "recall": 0.057312,
        "f1": 0.039076,
        "accuracy": 0.057312,
        "main_score": 0.039076,
        "hf_subset": "ary_Arab-kmr_Latn",
        "languages": [
          "ary-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.039469,
        "recall": 0.067194,
        "f1": 0.045529,
        "accuracy": 0.067194,
        "main_score": 0.045529,
        "hf_subset": "ary_Arab-min_Latn",
        "languages": [
          "ary-Arab",
          "min-Latn"
        ]
      },
      {
        "precision": 0.063311,
        "recall": 0.097826,
        "f1": 0.071047,
        "accuracy": 0.097826,
        "main_score": 0.071047,
        "hf_subset": "ary_Arab-por_Latn",
        "languages": [
          "ary-Arab",
          "por-Latn"
        ]
      },
      {
        "precision": 0.052647,
        "recall": 0.083992,
        "f1": 0.059161,
        "accuracy": 0.083992,
        "main_score": 0.059161,
        "hf_subset": "ary_Arab-sun_Latn",
        "languages": [
          "ary-Arab",
          "sun-Latn"
        ]
      },
      {
        "precision": 0.02824,
        "recall": 0.046443,
        "f1": 0.032318,
        "accuracy": 0.046443,
        "main_score": 0.032318,
        "hf_subset": "ary_Arab-umb_Latn",
        "languages": [
          "ary-Arab",
          "umb-Latn"
        ]
      },
      {
        "precision": 0.453137,
        "recall": 0.541502,
        "f1": 0.477208,
        "accuracy": 0.541502,
        "main_score": 0.477208,
        "hf_subset": "ary_Arab-ajp_Arab",
        "languages": [
          "ary-Arab",
          "ajp-Arab"
        ]
      },
      {
        "precision": 0.008551,
        "recall": 0.014822,
        "f1": 0.009363,
        "accuracy": 0.014822,
        "main_score": 0.009363,
        "hf_subset": "ary_Arab-bjn_Arab",
        "languages": [
          "ary-Arab",
          "bjn-Arab"
        ]
      },
      {
        "precision": 0.027832,
        "recall": 0.049407,
        "f1": 0.031934,
        "accuracy": 0.049407,
        "main_score": 0.031934,
        "hf_subset": "ary_Arab-ewe_Latn",
        "languages": [
          "ary-Arab",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.038573,
        "recall": 0.06917,
        "f1": 0.044208,
        "accuracy": 0.06917,
        "main_score": 0.044208,
        "hf_subset": "ary_Arab-ilo_Latn",
        "languages": [
          "ary-Arab",
          "ilo-Latn"
        ]
      },
      {
        "precision": 0.008952,
        "recall": 0.012846,
        "f1": 0.009666,
        "accuracy": 0.012846,
        "main_score": 0.009666,
        "hf_subset": "ary_Arab-knc_Arab",
        "languages": [
          "ary-Arab",
          "knc-Arab"
        ]
      },
      {
        "precision": 0.003894,
        "recall": 0.016798,
        "f1": 0.00527,
        "accuracy": 0.016798,
        "main_score": 0.00527,
        "hf_subset": "ary_Arab-mkd_Cyrl",
        "languages": [
          "ary-Arab",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.027011,
        "recall": 0.046443,
        "f1": 0.029733,
        "accuracy": 0.046443,
        "main_score": 0.029733,
        "hf_subset": "ary_Arab-prs_Arab",
        "languages": [
          "ary-Arab",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.047991,
        "recall": 0.08004,
        "f1": 0.054294,
        "accuracy": 0.08004,
        "main_score": 0.054294,
        "hf_subset": "ary_Arab-swe_Latn",
        "languages": [
          "ary-Arab",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.00919,
        "recall": 0.020751,
        "f1": 0.010043,
        "accuracy": 0.020751,
        "main_score": 0.010043,
        "hf_subset": "ary_Arab-urd_Arab",
        "languages": [
          "ary-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.041861,
        "recall": 0.060277,
        "f1": 0.045868,
        "accuracy": 0.060277,
        "main_score": 0.045868,
        "hf_subset": "ary_Arab-aka_Latn",
        "languages": [
          "ary-Arab",
          "aka-Latn"
        ]
      },
      {
        "precision": 0.047577,
        "recall": 0.077075,
        "f1": 0.053676,
        "accuracy": 0.077075,
        "main_score": 0.053676,
        "hf_subset": "ary_Arab-bjn_Latn",
        "languages": [
          "ary-Arab",
          "bjn-Latn"
        ]
      },
      {
        "precision": 0.028087,
        "recall": 0.054348,
        "f1": 0.033143,
        "accuracy": 0.054348,
        "main_score": 0.033143,
        "hf_subset": "ary_Arab-fao_Latn",
        "languages": [
          "ary-Arab",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.038478,
        "recall": 0.061265,
        "f1": 0.04351,
        "accuracy": 0.061265,
        "main_score": 0.04351,
        "hf_subset": "ary_Arab-ind_Latn",
        "languages": [
          "ary-Arab",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.033327,
        "recall": 0.0583,
        "f1": 0.03829,
        "accuracy": 0.0583,
        "main_score": 0.03829,
        "hf_subset": "ary_Arab-knc_Latn",
        "languages": [
          "ary-Arab",
          "knc-Latn"
        ]
      },
      {
        "precision": 0.026924,
        "recall": 0.048419,
        "f1": 0.031388,
        "accuracy": 0.048419,
        "main_score": 0.031388,
        "hf_subset": "ary_Arab-mlt_Latn",
        "languages": [
          "ary-Arab",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.031358,
        "recall": 0.049407,
        "f1": 0.035302,
        "accuracy": 0.049407,
        "main_score": 0.035302,
        "hf_subset": "ary_Arab-quy_Latn",
        "languages": [
          "ary-Arab",
          "quy-Latn"
        ]
      },
      {
        "precision": 0.024598,
        "recall": 0.043478,
        "f1": 0.028092,
        "accuracy": 0.043478,
        "main_score": 0.028092,
        "hf_subset": "ary_Arab-swh_Latn",
        "languages": [
          "ary-Arab",
          "swh-Latn"
        ]
      },
      {
        "precision": 0.03304,
        "recall": 0.05336,
        "f1": 0.036883,
        "accuracy": 0.05336,
        "main_score": 0.036883,
        "hf_subset": "ary_Arab-uzn_Latn",
        "languages": [
          "ary-Arab",
          "uzn-Latn"
        ]
      },
      {
        "precision": 0.040802,
        "recall": 0.061265,
        "f1": 0.044573,
        "accuracy": 0.061265,
        "main_score": 0.044573,
        "hf_subset": "ary_Arab-als_Latn",
        "languages": [
          "ary-Arab",
          "als-Latn"
        ]
      },
      {
        "precision": 0.001257,
        "recall": 0.005929,
        "f1": 0.00192,
        "accuracy": 0.005929,
        "main_score": 0.00192,
        "hf_subset": "ary_Arab-bod_Tibt",
        "languages": [
          "ary-Arab",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.030248,
        "recall": 0.05336,
        "f1": 0.034533,
        "accuracy": 0.05336,
        "main_score": 0.034533,
        "hf_subset": "ary_Arab-fij_Latn",
        "languages": [
          "ary-Arab",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.037921,
        "recall": 0.067194,
        "f1": 0.04395,
        "accuracy": 0.067194,
        "main_score": 0.04395,
        "hf_subset": "ary_Arab-isl_Latn",
        "languages": [
          "ary-Arab",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.027581,
        "recall": 0.05336,
        "f1": 0.032197,
        "accuracy": 0.05336,
        "main_score": 0.032197,
        "hf_subset": "ary_Arab-kon_Latn",
        "languages": [
          "ary-Arab",
          "kon-Latn"
        ]
      },
      {
        "precision": 0.001704,
        "recall": 0.008893,
        "f1": 0.002174,
        "accuracy": 0.008893,
        "main_score": 0.002174,
        "hf_subset": "ary_Arab-mni_Beng",
        "languages": [
          "ary-Arab",
          "mni-Beng"
        ]
      },
      {
        "precision": 0.047998,
        "recall": 0.06917,
        "f1": 0.053102,
        "accuracy": 0.06917,
        "main_score": 0.053102,
        "hf_subset": "ary_Arab-ron_Latn",
        "languages": [
          "ary-Arab",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.021881,
        "recall": 0.039526,
        "f1": 0.024953,
        "accuracy": 0.039526,
        "main_score": 0.024953,
        "hf_subset": "ary_Arab-szl_Latn",
        "languages": [
          "ary-Arab",
          "szl-Latn"
        ]
      },
      {
        "precision": 0.056086,
        "recall": 0.085968,
        "f1": 0.062249,
        "accuracy": 0.085968,
        "main_score": 0.062249,
        "hf_subset": "ary_Arab-vec_Latn",
        "languages": [
          "ary-Arab",
          "vec-Latn"
        ]
      },
      {
        "precision": 0.007665,
        "recall": 0.021739,
        "f1": 0.009125,
        "accuracy": 0.021739,
        "main_score": 0.009125,
        "hf_subset": "ary_Arab-amh_Ethi",
        "languages": [
          "ary-Arab",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.02655,
        "recall": 0.044466,
        "f1": 0.029684,
        "accuracy": 0.044466,
        "main_score": 0.029684,
        "hf_subset": "ary_Arab-bos_Latn",
        "languages": [
          "ary-Arab",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.024417,
        "recall": 0.037549,
        "f1": 0.027408,
        "accuracy": 0.037549,
        "main_score": 0.027408,
        "hf_subset": "ary_Arab-fin_Latn",
        "languages": [
          "ary-Arab",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.045984,
        "recall": 0.068182,
        "f1": 0.050585,
        "accuracy": 0.068182,
        "main_score": 0.050585,
        "hf_subset": "ary_Arab-ita_Latn",
        "languages": [
          "ary-Arab",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.003646,
        "recall": 0.014822,
        "f1": 0.004988,
        "accuracy": 0.014822,
        "main_score": 0.004988,
        "hf_subset": "ary_Arab-kor_Hang",
        "languages": [
          "ary-Arab",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.028885,
        "recall": 0.052372,
        "f1": 0.032078,
        "accuracy": 0.052372,
        "main_score": 0.032078,
        "hf_subset": "ary_Arab-mos_Latn",
        "languages": [
          "ary-Arab",
          "mos-Latn"
        ]
      },
      {
        "precision": 0.036226,
        "recall": 0.062253,
        "f1": 0.042006,
        "accuracy": 0.062253,
        "main_score": 0.042006,
        "hf_subset": "ary_Arab-run_Latn",
        "languages": [
          "ary-Arab",
          "run-Latn"
        ]
      },
      {
        "precision": 0.002577,
        "recall": 0.008893,
        "f1": 0.003328,
        "accuracy": 0.008893,
        "main_score": 0.003328,
        "hf_subset": "ary_Arab-tam_Taml",
        "languages": [
          "ary-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.026707,
        "recall": 0.045455,
        "f1": 0.030271,
        "accuracy": 0.045455,
        "main_score": 0.030271,
        "hf_subset": "ary_Arab-vie_Latn",
        "languages": [
          "ary-Arab",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.46527,
        "recall": 0.537549,
        "f1": 0.486124,
        "accuracy": 0.537549,
        "main_score": 0.486124,
        "hf_subset": "ary_Arab-apc_Arab",
        "languages": [
          "ary-Arab",
          "apc-Arab"
        ]
      },
      {
        "precision": 0.035542,
        "recall": 0.056324,
        "f1": 0.039887,
        "accuracy": 0.056324,
        "main_score": 0.039887,
        "hf_subset": "ary_Arab-bug_Latn",
        "languages": [
          "ary-Arab",
          "bug-Latn"
        ]
      },
      {
        "precision": 0.019605,
        "recall": 0.034585,
        "f1": 0.022222,
        "accuracy": 0.034585,
        "main_score": 0.022222,
        "hf_subset": "ary_Arab-fon_Latn",
        "languages": [
          "ary-Arab",
          "fon-Latn"
        ]
      },
      {
        "precision": 0.045995,
        "recall": 0.077075,
        "f1": 0.052599,
        "accuracy": 0.077075,
        "main_score": 0.052599,
        "hf_subset": "ary_Arab-jav_Latn",
        "languages": [
          "ary-Arab",
          "jav-Latn"
        ]
      },
      {
        "precision": 0.002988,
        "recall": 0.01087,
        "f1": 0.003549,
        "accuracy": 0.01087,
        "main_score": 0.003549,
        "hf_subset": "ary_Arab-lao_Laoo",
        "languages": [
          "ary-Arab",
          "lao-Laoo"
        ]
      },
      {
        "precision": 0.027131,
        "recall": 0.049407,
        "f1": 0.031743,
        "accuracy": 0.049407,
        "main_score": 0.031743,
        "hf_subset": "ary_Arab-mri_Latn",
        "languages": [
          "ary-Arab",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.006252,
        "recall": 0.020751,
        "f1": 0.008057,
        "accuracy": 0.020751,
        "main_score": 0.008057,
        "hf_subset": "ary_Arab-rus_Cyrl",
        "languages": [
          "ary-Arab",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.03981,
        "recall": 0.064229,
        "f1": 0.044823,
        "accuracy": 0.064229,
        "main_score": 0.044823,
        "hf_subset": "ary_Arab-taq_Latn",
        "languages": [
          "ary-Arab",
          "taq-Latn"
        ]
      },
      {
        "precision": 0.040196,
        "recall": 0.075099,
        "f1": 0.046897,
        "accuracy": 0.075099,
        "main_score": 0.046897,
        "hf_subset": "ary_Arab-war_Latn",
        "languages": [
          "ary-Arab",
          "war-Latn"
        ]
      },
      {
        "precision": 0.493017,
        "recall": 0.581028,
        "f1": 0.516954,
        "accuracy": 0.581028,
        "main_score": 0.516954,
        "hf_subset": "ary_Arab-arb_Arab",
        "languages": [
          "ary-Arab",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.002571,
        "recall": 0.01087,
        "f1": 0.003361,
        "accuracy": 0.01087,
        "main_score": 0.003361,
        "hf_subset": "ary_Arab-bul_Cyrl",
        "languages": [
          "ary-Arab",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.050597,
        "recall": 0.083992,
        "f1": 0.057777,
        "accuracy": 0.083992,
        "main_score": 0.057777,
        "hf_subset": "ary_Arab-fra_Latn",
        "languages": [
          "ary-Arab",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.003123,
        "recall": 0.012846,
        "f1": 0.004073,
        "accuracy": 0.012846,
        "main_score": 0.004073,
        "hf_subset": "ary_Arab-jpn_Jpan",
        "languages": [
          "ary-Arab",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.046425,
        "recall": 0.072134,
        "f1": 0.052065,
        "accuracy": 0.072134,
        "main_score": 0.052065,
        "hf_subset": "ary_Arab-lij_Latn",
        "languages": [
          "ary-Arab",
          "lij-Latn"
        ]
      },
      {
        "precision": 1.1e-05,
        "recall": 0.001976,
        "f1": 2.2e-05,
        "accuracy": 0.001976,
        "main_score": 2.2e-05,
        "hf_subset": "ary_Arab-mya_Mymr",
        "languages": [
          "ary-Arab",
          "mya-Mymr"
        ]
      },
      {
        "precision": 0.02812,
        "recall": 0.048419,
        "f1": 0.030952,
        "accuracy": 0.048419,
        "main_score": 0.030952,
        "hf_subset": "ary_Arab-sag_Latn",
        "languages": [
          "ary-Arab",
          "sag-Latn"
        ]
      },
      {
        "precision": 0.003238,
        "recall": 0.009881,
        "f1": 0.003786,
        "accuracy": 0.009881,
        "main_score": 0.003786,
        "hf_subset": "ary_Arab-taq_Tfng",
        "languages": [
          "ary-Arab",
          "taq-Tfng"
        ]
      },
      {
        "precision": 0.045297,
        "recall": 0.06917,
        "f1": 0.050585,
        "accuracy": 0.06917,
        "main_score": 0.050585,
        "hf_subset": "ary_Arab-wol_Latn",
        "languages": [
          "ary-Arab",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.012687,
        "recall": 0.020751,
        "f1": 0.01369,
        "accuracy": 0.020751,
        "main_score": 0.01369,
        "hf_subset": "ary_Arab-arb_Latn",
        "languages": [
          "ary-Arab",
          "arb-Latn"
        ]
      },
      {
        "precision": 0.058231,
        "recall": 0.083992,
        "f1": 0.064163,
        "accuracy": 0.083992,
        "main_score": 0.064163,
        "hf_subset": "ary_Arab-cat_Latn",
        "languages": [
          "ary-Arab",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.060213,
        "recall": 0.090909,
        "f1": 0.067621,
        "accuracy": 0.090909,
        "main_score": 0.067621,
        "hf_subset": "ary_Arab-fur_Latn",
        "languages": [
          "ary-Arab",
          "fur-Latn"
        ]
      },
      {
        "precision": 0.040977,
        "recall": 0.063241,
        "f1": 0.045755,
        "accuracy": 0.063241,
        "main_score": 0.045755,
        "hf_subset": "ary_Arab-kab_Latn",
        "languages": [
          "ary-Arab",
          "kab-Latn"
        ]
      },
      {
        "precision": 0.051483,
        "recall": 0.082016,
        "f1": 0.05789,
        "accuracy": 0.082016,
        "main_score": 0.05789,
        "hf_subset": "ary_Arab-lim_Latn",
        "languages": [
          "ary-Arab",
          "lim-Latn"
        ]
      },
      {
        "precision": 0.04628,
        "recall": 0.074111,
        "f1": 0.052137,
        "accuracy": 0.074111,
        "main_score": 0.052137,
        "hf_subset": "ary_Arab-nld_Latn",
        "languages": [
          "ary-Arab",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.004551,
        "recall": 0.012846,
        "f1": 0.005301,
        "accuracy": 0.012846,
        "main_score": 0.005301,
        "hf_subset": "ary_Arab-san_Deva",
        "languages": [
          "ary-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.005276,
        "recall": 0.012846,
        "f1": 0.006131,
        "accuracy": 0.012846,
        "main_score": 0.006131,
        "hf_subset": "ary_Arab-tat_Cyrl",
        "languages": [
          "ary-Arab",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.032646,
        "recall": 0.055336,
        "f1": 0.036822,
        "accuracy": 0.055336,
        "main_score": 0.036822,
        "hf_subset": "ary_Arab-xho_Latn",
        "languages": [
          "ary-Arab",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.467844,
        "recall": 0.5583,
        "f1": 0.492446,
        "accuracy": 0.5583,
        "main_score": 0.492446,
        "hf_subset": "ary_Arab-ars_Arab",
        "languages": [
          "ary-Arab",
          "ars-Arab"
        ]
      },
      {
        "precision": 0.047085,
        "recall": 0.071146,
        "f1": 0.051834,
        "accuracy": 0.071146,
        "main_score": 0.051834,
        "hf_subset": "ary_Arab-ceb_Latn",
        "languages": [
          "ary-Arab",
          "ceb-Latn"
        ]
      },
      {
        "precision": 0.032834,
        "recall": 0.055336,
        "f1": 0.036871,
        "accuracy": 0.055336,
        "main_score": 0.036871,
        "hf_subset": "ary_Arab-fuv_Latn",
        "languages": [
          "ary-Arab",
          "fuv-Latn"
        ]
      },
      {
        "precision": 0.026115,
        "recall": 0.043478,
        "f1": 0.029204,
        "accuracy": 0.043478,
        "main_score": 0.029204,
        "hf_subset": "ary_Arab-kac_Latn",
        "languages": [
          "ary-Arab",
          "kac-Latn"
        ]
      },
      {
        "precision": 0.043391,
        "recall": 0.068182,
        "f1": 0.048047,
        "accuracy": 0.068182,
        "main_score": 0.048047,
        "hf_subset": "ary_Arab-lin_Latn",
        "languages": [
          "ary-Arab",
          "lin-Latn"
        ]
      },
      {
        "precision": 0.042542,
        "recall": 0.065217,
        "f1": 0.047633,
        "accuracy": 0.065217,
        "main_score": 0.047633,
        "hf_subset": "ary_Arab-nno_Latn",
        "languages": [
          "ary-Arab",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.002653,
        "recall": 0.009881,
        "f1": 0.003172,
        "accuracy": 0.009881,
        "main_score": 0.003172,
        "hf_subset": "ary_Arab-sat_Olck",
        "languages": [
          "ary-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.003532,
        "recall": 0.007905,
        "f1": 0.003764,
        "accuracy": 0.007905,
        "main_score": 0.003764,
        "hf_subset": "ary_Arab-tel_Telu",
        "languages": [
          "ary-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.006395,
        "recall": 0.013834,
        "f1": 0.007099,
        "accuracy": 0.013834,
        "main_score": 0.007099,
        "hf_subset": "ary_Arab-ydd_Hebr",
        "languages": [
          "ary-Arab",
          "ydd-Hebr"
        ]
      },
      {
        "precision": 0.024764,
        "recall": 0.04249,
        "f1": 0.028283,
        "accuracy": 0.04249,
        "main_score": 0.028283,
        "hf_subset": "ary_Arab-ces_Latn",
        "languages": [
          "ary-Arab",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.020026,
        "recall": 0.036561,
        "f1": 0.023087,
        "accuracy": 0.036561,
        "main_score": 0.023087,
        "hf_subset": "ary_Arab-gaz_Latn",
        "languages": [
          "ary-Arab",
          "gaz-Latn"
        ]
      },
      {
        "precision": 0.026425,
        "recall": 0.050395,
        "f1": 0.030138,
        "accuracy": 0.050395,
        "main_score": 0.030138,
        "hf_subset": "ary_Arab-kam_Latn",
        "languages": [
          "ary-Arab",
          "kam-Latn"
        ]
      },
      {
        "precision": 0.025526,
        "recall": 0.044466,
        "f1": 0.028674,
        "accuracy": 0.044466,
        "main_score": 0.028674,
        "hf_subset": "ary_Arab-lit_Latn",
        "languages": [
          "ary-Arab",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.038897,
        "recall": 0.064229,
        "f1": 0.044138,
        "accuracy": 0.064229,
        "main_score": 0.044138,
        "hf_subset": "ary_Arab-nob_Latn",
        "languages": [
          "ary-Arab",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.038045,
        "recall": 0.061265,
        "f1": 0.042225,
        "accuracy": 0.061265,
        "main_score": 0.042225,
        "hf_subset": "ary_Arab-scn_Latn",
        "languages": [
          "ary-Arab",
          "scn-Latn"
        ]
      },
      {
        "precision": 0.007785,
        "recall": 0.018775,
        "f1": 0.009056,
        "accuracy": 0.018775,
        "main_score": 0.009056,
        "hf_subset": "ary_Arab-tgk_Cyrl",
        "languages": [
          "ary-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.019353,
        "recall": 0.038538,
        "f1": 0.022674,
        "accuracy": 0.038538,
        "main_score": 0.022674,
        "hf_subset": "ary_Arab-yor_Latn",
        "languages": [
          "ary-Arab",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.430125,
        "recall": 0.520751,
        "f1": 0.455244,
        "accuracy": 0.520751,
        "main_score": 0.455244,
        "hf_subset": "ary_Arab-arz_Arab",
        "languages": [
          "ary-Arab",
          "arz-Arab"
        ]
      },
      {
        "precision": 0.015761,
        "recall": 0.030632,
        "f1": 0.018815,
        "accuracy": 0.030632,
        "main_score": 0.018815,
        "hf_subset": "ary_Arab-cjk_Latn",
        "languages": [
          "ary-Arab",
          "cjk-Latn"
        ]
      },
      {
        "precision": 0.035786,
        "recall": 0.0583,
        "f1": 0.040487,
        "accuracy": 0.0583,
        "main_score": 0.040487,
        "hf_subset": "ary_Arab-gla_Latn",
        "languages": [
          "ary-Arab",
          "gla-Latn"
        ]
      },
      {
        "precision": 0.000799,
        "recall": 0.005929,
        "f1": 0.001298,
        "accuracy": 0.005929,
        "main_score": 0.001298,
        "hf_subset": "ary_Arab-kan_Knda",
        "languages": [
          "ary-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.039412,
        "recall": 0.063241,
        "f1": 0.044957,
        "accuracy": 0.063241,
        "main_score": 0.044957,
        "hf_subset": "ary_Arab-lmo_Latn",
        "languages": [
          "ary-Arab",
          "lmo-Latn"
        ]
      },
      {
        "precision": 0.002619,
        "recall": 0.009881,
        "f1": 0.003117,
        "accuracy": 0.009881,
        "main_score": 0.003117,
        "hf_subset": "ary_Arab-npi_Deva",
        "languages": [
          "ary-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.001932,
        "recall": 0.009881,
        "f1": 0.002478,
        "accuracy": 0.009881,
        "main_score": 0.002478,
        "hf_subset": "ary_Arab-shn_Mymr",
        "languages": [
          "ary-Arab",
          "shn-Mymr"
        ]
      },
      {
        "precision": 0.037696,
        "recall": 0.066206,
        "f1": 0.042767,
        "accuracy": 0.066206,
        "main_score": 0.042767,
        "hf_subset": "ary_Arab-tgl_Latn",
        "languages": [
          "ary-Arab",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.010166,
        "recall": 0.023715,
        "f1": 0.012097,
        "accuracy": 0.023715,
        "main_score": 0.012097,
        "hf_subset": "ary_Arab-yue_Hant",
        "languages": [
          "ary-Arab",
          "yue-Hant"
        ]
      },
      {
        "precision": 0.003202,
        "recall": 0.006917,
        "f1": 0.003396,
        "accuracy": 0.006917,
        "main_score": 0.003396,
        "hf_subset": "ary_Arab-asm_Beng",
        "languages": [
          "ary-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.007388,
        "recall": 0.016798,
        "f1": 0.008326,
        "accuracy": 0.016798,
        "main_score": 0.008326,
        "hf_subset": "ary_Arab-ckb_Arab",
        "languages": [
          "ary-Arab",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.047304,
        "recall": 0.076087,
        "f1": 0.053002,
        "accuracy": 0.076087,
        "main_score": 0.053002,
        "hf_subset": "ary_Arab-gle_Latn",
        "languages": [
          "ary-Arab",
          "gle-Latn"
        ]
      },
      {
        "precision": 0.007906,
        "recall": 0.021739,
        "f1": 0.009648,
        "accuracy": 0.021739,
        "main_score": 0.009648,
        "hf_subset": "ary_Arab-kas_Arab",
        "languages": [
          "ary-Arab",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.030776,
        "recall": 0.051383,
        "f1": 0.035151,
        "accuracy": 0.051383,
        "main_score": 0.035151,
        "hf_subset": "ary_Arab-ltg_Latn",
        "languages": [
          "ary-Arab",
          "ltg-Latn"
        ]
      },
      {
        "precision": 0.0437,
        "recall": 0.072134,
        "f1": 0.049014,
        "accuracy": 0.072134,
        "main_score": 0.049014,
        "hf_subset": "ary_Arab-nso_Latn",
        "languages": [
          "ary-Arab",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.001464,
        "recall": 0.005929,
        "f1": 0.001762,
        "accuracy": 0.005929,
        "main_score": 0.001762,
        "hf_subset": "ary_Arab-sin_Sinh",
        "languages": [
          "ary-Arab",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.002172,
        "recall": 0.014822,
        "f1": 0.003457,
        "accuracy": 0.014822,
        "main_score": 0.003457,
        "hf_subset": "ary_Arab-tha_Thai",
        "languages": [
          "ary-Arab",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.007892,
        "recall": 0.022727,
        "f1": 0.009792,
        "accuracy": 0.022727,
        "main_score": 0.009792,
        "hf_subset": "ary_Arab-zho_Hans",
        "languages": [
          "ary-Arab",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.05169,
        "recall": 0.083992,
        "f1": 0.059261,
        "accuracy": 0.083992,
        "main_score": 0.059261,
        "hf_subset": "ary_Arab-ast_Latn",
        "languages": [
          "ary-Arab",
          "ast-Latn"
        ]
      },
      {
        "precision": 0.036093,
        "recall": 0.05336,
        "f1": 0.040147,
        "accuracy": 0.05336,
        "main_score": 0.040147,
        "hf_subset": "ary_Arab-crh_Latn",
        "languages": [
          "ary-Arab",
          "crh-Latn"
        ]
      },
      {
        "precision": 0.065334,
        "recall": 0.092885,
        "f1": 0.071386,
        "accuracy": 0.092885,
        "main_score": 0.071386,
        "hf_subset": "ary_Arab-glg_Latn",
        "languages": [
          "ary-Arab",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.00467,
        "recall": 0.014822,
        "f1": 0.006128,
        "accuracy": 0.014822,
        "main_score": 0.006128,
        "hf_subset": "ary_Arab-kas_Deva",
        "languages": [
          "ary-Arab",
          "kas-Deva"
        ]
      },
      {
        "precision": 0.028685,
        "recall": 0.047431,
        "f1": 0.032556,
        "accuracy": 0.047431,
        "main_score": 0.032556,
        "hf_subset": "ary_Arab-ltz_Latn",
        "languages": [
          "ary-Arab",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.024023,
        "recall": 0.045455,
        "f1": 0.028225,
        "accuracy": 0.045455,
        "main_score": 0.028225,
        "hf_subset": "ary_Arab-nus_Latn",
        "languages": [
          "ary-Arab",
          "nus-Latn"
        ]
      },
      {
        "precision": 0.026166,
        "recall": 0.044466,
        "f1": 0.029518,
        "accuracy": 0.044466,
        "main_score": 0.029518,
        "hf_subset": "ary_Arab-slk_Latn",
        "languages": [
          "ary-Arab",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.005415,
        "recall": 0.022727,
        "f1": 0.007025,
        "accuracy": 0.022727,
        "main_score": 0.007025,
        "hf_subset": "ary_Arab-tir_Ethi",
        "languages": [
          "ary-Arab",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.00981,
        "recall": 0.022727,
        "f1": 0.011834,
        "accuracy": 0.022727,
        "main_score": 0.011834,
        "hf_subset": "ary_Arab-zho_Hant",
        "languages": [
          "ary-Arab",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.003773,
        "recall": 0.012846,
        "f1": 0.004662,
        "accuracy": 0.012846,
        "main_score": 0.004662,
        "hf_subset": "ary_Arab-awa_Deva",
        "languages": [
          "ary-Arab",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.043016,
        "recall": 0.067194,
        "f1": 0.047531,
        "accuracy": 0.067194,
        "main_score": 0.047531,
        "hf_subset": "ary_Arab-cym_Latn",
        "languages": [
          "ary-Arab",
          "cym-Latn"
        ]
      },
      {
        "precision": 0.038682,
        "recall": 0.064229,
        "f1": 0.04408,
        "accuracy": 0.064229,
        "main_score": 0.04408,
        "hf_subset": "ary_Arab-grn_Latn",
        "languages": [
          "ary-Arab",
          "grn-Latn"
        ]
      },
      {
        "precision": 0.003121,
        "recall": 0.006917,
        "f1": 0.003248,
        "accuracy": 0.006917,
        "main_score": 0.003248,
        "hf_subset": "ary_Arab-kat_Geor",
        "languages": [
          "ary-Arab",
          "kat-Geor"
        ]
      },
      {
        "precision": 0.042005,
        "recall": 0.068182,
        "f1": 0.047396,
        "accuracy": 0.068182,
        "main_score": 0.047396,
        "hf_subset": "ary_Arab-lua_Latn",
        "languages": [
          "ary-Arab",
          "lua-Latn"
        ]
      },
      {
        "precision": 0.027234,
        "recall": 0.040514,
        "f1": 0.029615,
        "accuracy": 0.040514,
        "main_score": 0.029615,
        "hf_subset": "ary_Arab-nya_Latn",
        "languages": [
          "ary-Arab",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.034442,
        "recall": 0.063241,
        "f1": 0.03986,
        "accuracy": 0.063241,
        "main_score": 0.03986,
        "hf_subset": "ary_Arab-slv_Latn",
        "languages": [
          "ary-Arab",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.035454,
        "recall": 0.0583,
        "f1": 0.039858,
        "accuracy": 0.0583,
        "main_score": 0.039858,
        "hf_subset": "ary_Arab-tpi_Latn",
        "languages": [
          "ary-Arab",
          "tpi-Latn"
        ]
      },
      {
        "precision": 0.04345,
        "recall": 0.077075,
        "f1": 0.050509,
        "accuracy": 0.077075,
        "main_score": 0.050509,
        "hf_subset": "ary_Arab-zsm_Latn",
        "languages": [
          "ary-Arab",
          "zsm-Latn"
        ]
      },
      {
        "precision": 0.026359,
        "recall": 0.045455,
        "f1": 0.030472,
        "accuracy": 0.045455,
        "main_score": 0.030472,
        "hf_subset": "ary_Arab-ayr_Latn",
        "languages": [
          "ary-Arab",
          "ayr-Latn"
        ]
      },
      {
        "precision": 0.04609,
        "recall": 0.071146,
        "f1": 0.051413,
        "accuracy": 0.071146,
        "main_score": 0.051413,
        "hf_subset": "ary_Arab-dan_Latn",
        "languages": [
          "ary-Arab",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.0044,
        "recall": 0.013834,
        "f1": 0.005151,
        "accuracy": 0.013834,
        "main_score": 0.005151,
        "hf_subset": "ary_Arab-guj_Gujr",
        "languages": [
          "ary-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.00184,
        "recall": 0.005929,
        "f1": 0.002404,
        "accuracy": 0.005929,
        "main_score": 0.002404,
        "hf_subset": "ary_Arab-kaz_Cyrl",
        "languages": [
          "ary-Arab",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.032708,
        "recall": 0.054348,
        "f1": 0.036558,
        "accuracy": 0.054348,
        "main_score": 0.036558,
        "hf_subset": "ary_Arab-lug_Latn",
        "languages": [
          "ary-Arab",
          "lug-Latn"
        ]
      },
      {
        "precision": 0.06201,
        "recall": 0.094862,
        "f1": 0.069917,
        "accuracy": 0.094862,
        "main_score": 0.069917,
        "hf_subset": "ary_Arab-oci_Latn",
        "languages": [
          "ary-Arab",
          "oci-Latn"
        ]
      },
      {
        "precision": 0.037885,
        "recall": 0.066206,
        "f1": 0.043297,
        "accuracy": 0.066206,
        "main_score": 0.043297,
        "hf_subset": "ary_Arab-smo_Latn",
        "languages": [
          "ary-Arab",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.027905,
        "recall": 0.046443,
        "f1": 0.031336,
        "accuracy": 0.046443,
        "main_score": 0.031336,
        "hf_subset": "ary_Arab-tsn_Latn",
        "languages": [
          "ary-Arab",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.022137,
        "recall": 0.036561,
        "f1": 0.024856,
        "accuracy": 0.036561,
        "main_score": 0.024856,
        "hf_subset": "ary_Arab-zul_Latn",
        "languages": [
          "ary-Arab",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.013003,
        "recall": 0.020751,
        "f1": 0.014235,
        "accuracy": 0.020751,
        "main_score": 0.014235,
        "hf_subset": "ary_Arab-azb_Arab",
        "languages": [
          "ary-Arab",
          "azb-Arab"
        ]
      },
      {
        "precision": 0.035218,
        "recall": 0.05336,
        "f1": 0.038664,
        "accuracy": 0.05336,
        "main_score": 0.038664,
        "hf_subset": "ary_Arab-deu_Latn",
        "languages": [
          "ary-Arab",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.050221,
        "recall": 0.077075,
        "f1": 0.056318,
        "accuracy": 0.077075,
        "main_score": 0.056318,
        "hf_subset": "ary_Arab-hat_Latn",
        "languages": [
          "ary-Arab",
          "hat-Latn"
        ]
      },
      {
        "precision": 0.025219,
        "recall": 0.040514,
        "f1": 0.028696,
        "accuracy": 0.040514,
        "main_score": 0.028696,
        "hf_subset": "ary_Arab-kbp_Latn",
        "languages": [
          "ary-Arab",
          "kbp-Latn"
        ]
      },
      {
        "precision": 0.038198,
        "recall": 0.062253,
        "f1": 0.043402,
        "accuracy": 0.062253,
        "main_score": 0.043402,
        "hf_subset": "ary_Arab-luo_Latn",
        "languages": [
          "ary-Arab",
          "luo-Latn"
        ]
      },
      {
        "precision": 0.002345,
        "recall": 0.006917,
        "f1": 0.002603,
        "accuracy": 0.006917,
        "main_score": 0.002603,
        "hf_subset": "ary_Arab-ory_Orya",
        "languages": [
          "ary-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.026523,
        "recall": 0.049407,
        "f1": 0.031259,
        "accuracy": 0.049407,
        "main_score": 0.031259,
        "hf_subset": "ary_Arab-sna_Latn",
        "languages": [
          "ary-Arab",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.025999,
        "recall": 0.048419,
        "f1": 0.030391,
        "accuracy": 0.048419,
        "main_score": 0.030391,
        "hf_subset": "ary_Arab-tso_Latn",
        "languages": [
          "ary-Arab",
          "tso-Latn"
        ]
      },
      {
        "precision": 0.014466,
        "recall": 0.027668,
        "f1": 0.016643,
        "accuracy": 0.027668,
        "main_score": 0.016643,
        "hf_subset": "ary_Arab-azj_Latn",
        "languages": [
          "ary-Arab",
          "azj-Latn"
        ]
      },
      {
        "precision": 0.024194,
        "recall": 0.047431,
        "f1": 0.028393,
        "accuracy": 0.047431,
        "main_score": 0.028393,
        "hf_subset": "ary_Arab-dik_Latn",
        "languages": [
          "ary-Arab",
          "dik-Latn"
        ]
      },
      {
        "precision": 0.032639,
        "recall": 0.05336,
        "f1": 0.035888,
        "accuracy": 0.05336,
        "main_score": 0.035888,
        "hf_subset": "ary_Arab-hau_Latn",
        "languages": [
          "ary-Arab",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.040788,
        "recall": 0.066206,
        "f1": 0.046317,
        "accuracy": 0.066206,
        "main_score": 0.046317,
        "hf_subset": "ary_Arab-kea_Latn",
        "languages": [
          "ary-Arab",
          "kea-Latn"
        ]
      },
      {
        "precision": 0.031423,
        "recall": 0.059289,
        "f1": 0.036764,
        "accuracy": 0.059289,
        "main_score": 0.036764,
        "hf_subset": "ary_Arab-lus_Latn",
        "languages": [
          "ary-Arab",
          "lus-Latn"
        ]
      },
      {
        "precision": 0.040842,
        "recall": 0.073123,
        "f1": 0.047368,
        "accuracy": 0.073123,
        "main_score": 0.047368,
        "hf_subset": "ary_Arab-pag_Latn",
        "languages": [
          "ary-Arab",
          "pag-Latn"
        ]
      },
      {
        "precision": 0.021566,
        "recall": 0.037549,
        "f1": 0.02435,
        "accuracy": 0.037549,
        "main_score": 0.02435,
        "hf_subset": "ary_Arab-snd_Arab",
        "languages": [
          "ary-Arab",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.037652,
        "recall": 0.054348,
        "f1": 0.04138,
        "accuracy": 0.054348,
        "main_score": 0.04138,
        "hf_subset": "ary_Arab-tuk_Latn",
        "languages": [
          "ary-Arab",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.004395,
        "recall": 0.012846,
        "f1": 0.005293,
        "accuracy": 0.012846,
        "main_score": 0.005293,
        "hf_subset": "ary_Arab-bak_Cyrl",
        "languages": [
          "ary-Arab",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.013132,
        "recall": 0.027668,
        "f1": 0.01555,
        "accuracy": 0.027668,
        "main_score": 0.01555,
        "hf_subset": "ary_Arab-dyu_Latn",
        "languages": [
          "ary-Arab",
          "dyu-Latn"
        ]
      },
      {
        "precision": 0.003816,
        "recall": 0.01087,
        "f1": 0.004721,
        "accuracy": 0.01087,
        "main_score": 0.004721,
        "hf_subset": "ary_Arab-heb_Hebr",
        "languages": [
          "ary-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.004364,
        "recall": 0.012846,
        "f1": 0.005138,
        "accuracy": 0.012846,
        "main_score": 0.005138,
        "hf_subset": "ary_Arab-khk_Cyrl",
        "languages": [
          "ary-Arab",
          "khk-Cyrl"
        ]
      },
      {
        "precision": 0.022381,
        "recall": 0.040514,
        "f1": 0.026099,
        "accuracy": 0.040514,
        "main_score": 0.026099,
        "hf_subset": "ary_Arab-lvs_Latn",
        "languages": [
          "ary-Arab",
          "lvs-Latn"
        ]
      },
      {
        "precision": 0.001586,
        "recall": 0.005929,
        "f1": 0.001843,
        "accuracy": 0.005929,
        "main_score": 0.001843,
        "hf_subset": "ary_Arab-pan_Guru",
        "languages": [
          "ary-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.036077,
        "recall": 0.056324,
        "f1": 0.0403,
        "accuracy": 0.056324,
        "main_score": 0.0403,
        "hf_subset": "ary_Arab-som_Latn",
        "languages": [
          "ary-Arab",
          "som-Latn"
        ]
      },
      {
        "precision": 0.025841,
        "recall": 0.045455,
        "f1": 0.02975,
        "accuracy": 0.045455,
        "main_score": 0.02975,
        "hf_subset": "ary_Arab-tum_Latn",
        "languages": [
          "ary-Arab",
          "tum-Latn"
        ]
      },
      {
        "precision": 0.031241,
        "recall": 0.056324,
        "f1": 0.036067,
        "accuracy": 0.056324,
        "main_score": 0.036067,
        "hf_subset": "ces_Latn-ary_Arab",
        "languages": [
          "ces-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.01014,
        "recall": 0.019763,
        "f1": 0.011657,
        "accuracy": 0.019763,
        "main_score": 0.011657,
        "hf_subset": "gaz_Latn-ary_Arab",
        "languages": [
          "gaz-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.018154,
        "recall": 0.031621,
        "f1": 0.020193,
        "accuracy": 0.031621,
        "main_score": 0.020193,
        "hf_subset": "kam_Latn-ary_Arab",
        "languages": [
          "kam-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.021606,
        "recall": 0.038538,
        "f1": 0.024591,
        "accuracy": 0.038538,
        "main_score": 0.024591,
        "hf_subset": "lit_Latn-ary_Arab",
        "languages": [
          "lit-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.038811,
        "recall": 0.068182,
        "f1": 0.044811,
        "accuracy": 0.068182,
        "main_score": 0.044811,
        "hf_subset": "nob_Latn-ary_Arab",
        "languages": [
          "nob-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.033408,
        "recall": 0.049407,
        "f1": 0.036842,
        "accuracy": 0.049407,
        "main_score": 0.036842,
        "hf_subset": "scn_Latn-ary_Arab",
        "languages": [
          "scn-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.003304,
        "recall": 0.005929,
        "f1": 0.003478,
        "accuracy": 0.005929,
        "main_score": 0.003478,
        "hf_subset": "tgk_Cyrl-ary_Arab",
        "languages": [
          "tgk-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.016025,
        "recall": 0.02668,
        "f1": 0.017859,
        "accuracy": 0.02668,
        "main_score": 0.017859,
        "hf_subset": "yor_Latn-ary_Arab",
        "languages": [
          "yor-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.452727,
        "recall": 0.552372,
        "f1": 0.481773,
        "accuracy": 0.552372,
        "main_score": 0.481773,
        "hf_subset": "arz_Arab-ary_Arab",
        "languages": [
          "arz-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.016417,
        "recall": 0.030632,
        "f1": 0.018758,
        "accuracy": 0.030632,
        "main_score": 0.018758,
        "hf_subset": "cjk_Latn-ary_Arab",
        "languages": [
          "cjk-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.027302,
        "recall": 0.047431,
        "f1": 0.030545,
        "accuracy": 0.047431,
        "main_score": 0.030545,
        "hf_subset": "gla_Latn-ary_Arab",
        "languages": [
          "gla-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.002189,
        "recall": 0.007905,
        "f1": 0.002373,
        "accuracy": 0.007905,
        "main_score": 0.002373,
        "hf_subset": "kan_Knda-ary_Arab",
        "languages": [
          "kan-Knda",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.02894,
        "recall": 0.048419,
        "f1": 0.032788,
        "accuracy": 0.048419,
        "main_score": 0.032788,
        "hf_subset": "lmo_Latn-ary_Arab",
        "languages": [
          "lmo-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.001529,
        "recall": 0.003953,
        "f1": 0.001736,
        "accuracy": 0.003953,
        "main_score": 0.001736,
        "hf_subset": "npi_Deva-ary_Arab",
        "languages": [
          "npi-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.001383,
        "recall": 0.004941,
        "f1": 0.001643,
        "accuracy": 0.004941,
        "main_score": 0.001643,
        "hf_subset": "shn_Mymr-ary_Arab",
        "languages": [
          "shn-Mymr",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.029787,
        "recall": 0.054348,
        "f1": 0.033831,
        "accuracy": 0.054348,
        "main_score": 0.033831,
        "hf_subset": "tgl_Latn-ary_Arab",
        "languages": [
          "tgl-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.011966,
        "recall": 0.020751,
        "f1": 0.013592,
        "accuracy": 0.020751,
        "main_score": 0.013592,
        "hf_subset": "yue_Hant-ary_Arab",
        "languages": [
          "yue-Hant",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.000112,
        "recall": 0.003953,
        "f1": 0.000209,
        "accuracy": 0.003953,
        "main_score": 0.000209,
        "hf_subset": "asm_Beng-ary_Arab",
        "languages": [
          "asm-Beng",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.005656,
        "recall": 0.014822,
        "f1": 0.00643,
        "accuracy": 0.014822,
        "main_score": 0.00643,
        "hf_subset": "ckb_Arab-ary_Arab",
        "languages": [
          "ckb-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.034667,
        "recall": 0.057312,
        "f1": 0.038751,
        "accuracy": 0.057312,
        "main_score": 0.038751,
        "hf_subset": "gle_Latn-ary_Arab",
        "languages": [
          "gle-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.005002,
        "recall": 0.009881,
        "f1": 0.005841,
        "accuracy": 0.009881,
        "main_score": 0.005841,
        "hf_subset": "kas_Arab-ary_Arab",
        "languages": [
          "kas-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.022927,
        "recall": 0.048419,
        "f1": 0.027487,
        "accuracy": 0.048419,
        "main_score": 0.027487,
        "hf_subset": "ltg_Latn-ary_Arab",
        "languages": [
          "ltg-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.034265,
        "recall": 0.059289,
        "f1": 0.039193,
        "accuracy": 0.059289,
        "main_score": 0.039193,
        "hf_subset": "nso_Latn-ary_Arab",
        "languages": [
          "nso-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.002562,
        "recall": 0.006917,
        "f1": 0.002811,
        "accuracy": 0.006917,
        "main_score": 0.002811,
        "hf_subset": "sin_Sinh-ary_Arab",
        "languages": [
          "sin-Sinh",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.001715,
        "recall": 0.005929,
        "f1": 0.002155,
        "accuracy": 0.005929,
        "main_score": 0.002155,
        "hf_subset": "tha_Thai-ary_Arab",
        "languages": [
          "tha-Thai",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.011617,
        "recall": 0.017787,
        "f1": 0.012403,
        "accuracy": 0.017787,
        "main_score": 0.012403,
        "hf_subset": "zho_Hans-ary_Arab",
        "languages": [
          "zho-Hans",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.053185,
        "recall": 0.079051,
        "f1": 0.058384,
        "accuracy": 0.079051,
        "main_score": 0.058384,
        "hf_subset": "ast_Latn-ary_Arab",
        "languages": [
          "ast-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.027808,
        "recall": 0.043478,
        "f1": 0.03046,
        "accuracy": 0.043478,
        "main_score": 0.03046,
        "hf_subset": "crh_Latn-ary_Arab",
        "languages": [
          "crh-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.055199,
        "recall": 0.078063,
        "f1": 0.059538,
        "accuracy": 0.078063,
        "main_score": 0.059538,
        "hf_subset": "glg_Latn-ary_Arab",
        "languages": [
          "glg-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.001607,
        "recall": 0.003953,
        "f1": 0.001869,
        "accuracy": 0.003953,
        "main_score": 0.001869,
        "hf_subset": "kas_Deva-ary_Arab",
        "languages": [
          "kas-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.023074,
        "recall": 0.04249,
        "f1": 0.026333,
        "accuracy": 0.04249,
        "main_score": 0.026333,
        "hf_subset": "ltz_Latn-ary_Arab",
        "languages": [
          "ltz-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.029428,
        "recall": 0.044466,
        "f1": 0.031815,
        "accuracy": 0.044466,
        "main_score": 0.031815,
        "hf_subset": "nus_Latn-ary_Arab",
        "languages": [
          "nus-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.023781,
        "recall": 0.041502,
        "f1": 0.026672,
        "accuracy": 0.041502,
        "main_score": 0.026672,
        "hf_subset": "slk_Latn-ary_Arab",
        "languages": [
          "slk-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.006697,
        "recall": 0.012846,
        "f1": 0.007224,
        "accuracy": 0.012846,
        "main_score": 0.007224,
        "hf_subset": "tir_Ethi-ary_Arab",
        "languages": [
          "tir-Ethi",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.01134,
        "recall": 0.020751,
        "f1": 0.012907,
        "accuracy": 0.020751,
        "main_score": 0.012907,
        "hf_subset": "zho_Hant-ary_Arab",
        "languages": [
          "zho-Hant",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.002562,
        "recall": 0.004941,
        "f1": 0.002803,
        "accuracy": 0.004941,
        "main_score": 0.002803,
        "hf_subset": "awa_Deva-ary_Arab",
        "languages": [
          "awa-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.031888,
        "recall": 0.060277,
        "f1": 0.036667,
        "accuracy": 0.060277,
        "main_score": 0.036667,
        "hf_subset": "cym_Latn-ary_Arab",
        "languages": [
          "cym-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.029919,
        "recall": 0.049407,
        "f1": 0.033381,
        "accuracy": 0.049407,
        "main_score": 0.033381,
        "hf_subset": "grn_Latn-ary_Arab",
        "languages": [
          "grn-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.001126,
        "recall": 0.003953,
        "f1": 0.001236,
        "accuracy": 0.003953,
        "main_score": 0.001236,
        "hf_subset": "kat_Geor-ary_Arab",
        "languages": [
          "kat-Geor",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.028911,
        "recall": 0.051383,
        "f1": 0.032869,
        "accuracy": 0.051383,
        "main_score": 0.032869,
        "hf_subset": "lua_Latn-ary_Arab",
        "languages": [
          "lua-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.020113,
        "recall": 0.035573,
        "f1": 0.022788,
        "accuracy": 0.035573,
        "main_score": 0.022788,
        "hf_subset": "nya_Latn-ary_Arab",
        "languages": [
          "nya-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.035844,
        "recall": 0.061265,
        "f1": 0.040478,
        "accuracy": 0.061265,
        "main_score": 0.040478,
        "hf_subset": "slv_Latn-ary_Arab",
        "languages": [
          "slv-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.031943,
        "recall": 0.050395,
        "f1": 0.035057,
        "accuracy": 0.050395,
        "main_score": 0.035057,
        "hf_subset": "tpi_Latn-ary_Arab",
        "languages": [
          "tpi-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.029981,
        "recall": 0.057312,
        "f1": 0.034431,
        "accuracy": 0.057312,
        "main_score": 0.034431,
        "hf_subset": "zsm_Latn-ary_Arab",
        "languages": [
          "zsm-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.014782,
        "recall": 0.028656,
        "f1": 0.016802,
        "accuracy": 0.028656,
        "main_score": 0.016802,
        "hf_subset": "ayr_Latn-ary_Arab",
        "languages": [
          "ayr-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.041889,
        "recall": 0.072134,
        "f1": 0.04881,
        "accuracy": 0.072134,
        "main_score": 0.04881,
        "hf_subset": "dan_Latn-ary_Arab",
        "languages": [
          "dan-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.003135,
        "recall": 0.008893,
        "f1": 0.003762,
        "accuracy": 0.008893,
        "main_score": 0.003762,
        "hf_subset": "guj_Gujr-ary_Arab",
        "languages": [
          "guj-Gujr",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.001086,
        "recall": 0.004941,
        "f1": 0.001171,
        "accuracy": 0.004941,
        "main_score": 0.001171,
        "hf_subset": "kaz_Cyrl-ary_Arab",
        "languages": [
          "kaz-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.02297,
        "recall": 0.038538,
        "f1": 0.026263,
        "accuracy": 0.038538,
        "main_score": 0.026263,
        "hf_subset": "lug_Latn-ary_Arab",
        "languages": [
          "lug-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.053803,
        "recall": 0.081028,
        "f1": 0.059694,
        "accuracy": 0.081028,
        "main_score": 0.059694,
        "hf_subset": "oci_Latn-ary_Arab",
        "languages": [
          "oci-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.027481,
        "recall": 0.045455,
        "f1": 0.030319,
        "accuracy": 0.045455,
        "main_score": 0.030319,
        "hf_subset": "smo_Latn-ary_Arab",
        "languages": [
          "smo-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.021179,
        "recall": 0.035573,
        "f1": 0.023606,
        "accuracy": 0.035573,
        "main_score": 0.023606,
        "hf_subset": "tsn_Latn-ary_Arab",
        "languages": [
          "tsn-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.016089,
        "recall": 0.028656,
        "f1": 0.01809,
        "accuracy": 0.028656,
        "main_score": 0.01809,
        "hf_subset": "zul_Latn-ary_Arab",
        "languages": [
          "zul-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.006652,
        "recall": 0.012846,
        "f1": 0.007124,
        "accuracy": 0.012846,
        "main_score": 0.007124,
        "hf_subset": "azb_Arab-ary_Arab",
        "languages": [
          "azb-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.021327,
        "recall": 0.035573,
        "f1": 0.023645,
        "accuracy": 0.035573,
        "main_score": 0.023645,
        "hf_subset": "deu_Latn-ary_Arab",
        "languages": [
          "deu-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.042764,
        "recall": 0.075099,
        "f1": 0.049195,
        "accuracy": 0.075099,
        "main_score": 0.049195,
        "hf_subset": "hat_Latn-ary_Arab",
        "languages": [
          "hat-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.01346,
        "recall": 0.02668,
        "f1": 0.015561,
        "accuracy": 0.02668,
        "main_score": 0.015561,
        "hf_subset": "kbp_Latn-ary_Arab",
        "languages": [
          "kbp-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.03071,
        "recall": 0.047431,
        "f1": 0.033427,
        "accuracy": 0.047431,
        "main_score": 0.033427,
        "hf_subset": "luo_Latn-ary_Arab",
        "languages": [
          "luo-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.001314,
        "recall": 0.004941,
        "f1": 0.001557,
        "accuracy": 0.004941,
        "main_score": 0.001557,
        "hf_subset": "ory_Orya-ary_Arab",
        "languages": [
          "ory-Orya",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.024615,
        "recall": 0.037549,
        "f1": 0.027229,
        "accuracy": 0.037549,
        "main_score": 0.027229,
        "hf_subset": "sna_Latn-ary_Arab",
        "languages": [
          "sna-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.019539,
        "recall": 0.035573,
        "f1": 0.022491,
        "accuracy": 0.035573,
        "main_score": 0.022491,
        "hf_subset": "tso_Latn-ary_Arab",
        "languages": [
          "tso-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.012622,
        "recall": 0.021739,
        "f1": 0.01396,
        "accuracy": 0.021739,
        "main_score": 0.01396,
        "hf_subset": "azj_Latn-ary_Arab",
        "languages": [
          "azj-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.025966,
        "recall": 0.034585,
        "f1": 0.027251,
        "accuracy": 0.034585,
        "main_score": 0.027251,
        "hf_subset": "dik_Latn-ary_Arab",
        "languages": [
          "dik-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.021345,
        "recall": 0.034585,
        "f1": 0.023746,
        "accuracy": 0.034585,
        "main_score": 0.023746,
        "hf_subset": "hau_Latn-ary_Arab",
        "languages": [
          "hau-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.035072,
        "recall": 0.059289,
        "f1": 0.039499,
        "accuracy": 0.059289,
        "main_score": 0.039499,
        "hf_subset": "kea_Latn-ary_Arab",
        "languages": [
          "kea-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.026916,
        "recall": 0.037549,
        "f1": 0.029308,
        "accuracy": 0.037549,
        "main_score": 0.029308,
        "hf_subset": "lus_Latn-ary_Arab",
        "languages": [
          "lus-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.032983,
        "recall": 0.056324,
        "f1": 0.036767,
        "accuracy": 0.056324,
        "main_score": 0.036767,
        "hf_subset": "pag_Latn-ary_Arab",
        "languages": [
          "pag-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.021088,
        "recall": 0.041502,
        "f1": 0.023802,
        "accuracy": 0.041502,
        "main_score": 0.023802,
        "hf_subset": "snd_Arab-ary_Arab",
        "languages": [
          "snd-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.02773,
        "recall": 0.046443,
        "f1": 0.030791,
        "accuracy": 0.046443,
        "main_score": 0.030791,
        "hf_subset": "tuk_Latn-ary_Arab",
        "languages": [
          "tuk-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.002934,
        "recall": 0.007905,
        "f1": 0.003397,
        "accuracy": 0.007905,
        "main_score": 0.003397,
        "hf_subset": "bak_Cyrl-ary_Arab",
        "languages": [
          "bak-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.009263,
        "recall": 0.019763,
        "f1": 0.010516,
        "accuracy": 0.019763,
        "main_score": 0.010516,
        "hf_subset": "dyu_Latn-ary_Arab",
        "languages": [
          "dyu-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.005342,
        "recall": 0.016798,
        "f1": 0.006177,
        "accuracy": 0.016798,
        "main_score": 0.006177,
        "hf_subset": "heb_Hebr-ary_Arab",
        "languages": [
          "heb-Hebr",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.003548,
        "recall": 0.006917,
        "f1": 0.003794,
        "accuracy": 0.006917,
        "main_score": 0.003794,
        "hf_subset": "khk_Cyrl-ary_Arab",
        "languages": [
          "khk-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.019413,
        "recall": 0.040514,
        "f1": 0.022816,
        "accuracy": 0.040514,
        "main_score": 0.022816,
        "hf_subset": "lvs_Latn-ary_Arab",
        "languages": [
          "lvs-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.003341,
        "recall": 0.009881,
        "f1": 0.003975,
        "accuracy": 0.009881,
        "main_score": 0.003975,
        "hf_subset": "pan_Guru-ary_Arab",
        "languages": [
          "pan-Guru",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.019553,
        "recall": 0.038538,
        "f1": 0.022782,
        "accuracy": 0.038538,
        "main_score": 0.022782,
        "hf_subset": "som_Latn-ary_Arab",
        "languages": [
          "som-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.015296,
        "recall": 0.028656,
        "f1": 0.017571,
        "accuracy": 0.028656,
        "main_score": 0.017571,
        "hf_subset": "tum_Latn-ary_Arab",
        "languages": [
          "tum-Latn",
          "ary-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 411.12904167175293,
  "kg_co2_emissions": null
}