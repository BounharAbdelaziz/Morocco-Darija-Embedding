{
  "dataset_revision": "a74d7350ea12af010cfb1c21e34f1f81fd2e615b",
  "task_name": "SIB200Classification",
  "mteb_version": "1.34.22",
  "scores": {
    "train": [
      {
        "accuracy": 0.660628,
        "f1": 0.648221,
        "f1_weighted": 0.661686,
        "scores_per_experiment": [
          {
            "accuracy": 0.68331,
            "f1": 0.666124,
            "f1_weighted": 0.687907
          },
          {
            "accuracy": 0.619116,
            "f1": 0.610834,
            "f1_weighted": 0.624324
          },
          {
            "accuracy": 0.620542,
            "f1": 0.610982,
            "f1_weighted": 0.611831
          },
          {
            "accuracy": 0.686163,
            "f1": 0.665644,
            "f1_weighted": 0.682868
          },
          {
            "accuracy": 0.680456,
            "f1": 0.671104,
            "f1_weighted": 0.68413
          },
          {
            "accuracy": 0.684736,
            "f1": 0.676125,
            "f1_weighted": 0.690055
          },
          {
            "accuracy": 0.670471,
            "f1": 0.648257,
            "f1_weighted": 0.671331
          },
          {
            "accuracy": 0.627675,
            "f1": 0.623492,
            "f1_weighted": 0.628021
          },
          {
            "accuracy": 0.654779,
            "f1": 0.6388,
            "f1_weighted": 0.655088
          },
          {
            "accuracy": 0.67903,
            "f1": 0.670852,
            "f1_weighted": 0.681304
          }
        ],
        "main_score": 0.660628,
        "hf_subset": "ary_Arab",
        "languages": [
          "ary-Arab"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.581818,
        "f1": 0.564209,
        "f1_weighted": 0.586982,
        "scores_per_experiment": [
          {
            "accuracy": 0.666667,
            "f1": 0.6587,
            "f1_weighted": 0.67606
          },
          {
            "accuracy": 0.505051,
            "f1": 0.507639,
            "f1_weighted": 0.510306
          },
          {
            "accuracy": 0.575758,
            "f1": 0.565965,
            "f1_weighted": 0.565864
          },
          {
            "accuracy": 0.626263,
            "f1": 0.595717,
            "f1_weighted": 0.622045
          },
          {
            "accuracy": 0.555556,
            "f1": 0.528409,
            "f1_weighted": 0.560302
          },
          {
            "accuracy": 0.535354,
            "f1": 0.532325,
            "f1_weighted": 0.545849
          },
          {
            "accuracy": 0.606061,
            "f1": 0.563179,
            "f1_weighted": 0.620057
          },
          {
            "accuracy": 0.575758,
            "f1": 0.551608,
            "f1_weighted": 0.576581
          },
          {
            "accuracy": 0.616162,
            "f1": 0.604414,
            "f1_weighted": 0.62314
          },
          {
            "accuracy": 0.555556,
            "f1": 0.534137,
            "f1_weighted": 0.569617
          }
        ],
        "main_score": 0.581818,
        "hf_subset": "ary_Arab",
        "languages": [
          "ary-Arab"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.690686,
        "f1": 0.670109,
        "f1_weighted": 0.690086,
        "scores_per_experiment": [
          {
            "accuracy": 0.75,
            "f1": 0.735284,
            "f1_weighted": 0.749515
          },
          {
            "accuracy": 0.666667,
            "f1": 0.653803,
            "f1_weighted": 0.671803
          },
          {
            "accuracy": 0.691176,
            "f1": 0.676158,
            "f1_weighted": 0.686733
          },
          {
            "accuracy": 0.686275,
            "f1": 0.662281,
            "f1_weighted": 0.682614
          },
          {
            "accuracy": 0.676471,
            "f1": 0.661966,
            "f1_weighted": 0.681083
          },
          {
            "accuracy": 0.676471,
            "f1": 0.638146,
            "f1_weighted": 0.674186
          },
          {
            "accuracy": 0.686275,
            "f1": 0.652992,
            "f1_weighted": 0.686045
          },
          {
            "accuracy": 0.617647,
            "f1": 0.608918,
            "f1_weighted": 0.619608
          },
          {
            "accuracy": 0.691176,
            "f1": 0.668552,
            "f1_weighted": 0.684701
          },
          {
            "accuracy": 0.764706,
            "f1": 0.74299,
            "f1_weighted": 0.764572
          }
        ],
        "main_score": 0.690686,
        "hf_subset": "ary_Arab",
        "languages": [
          "ary-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 10.850529670715332,
  "kg_co2_emissions": null
}