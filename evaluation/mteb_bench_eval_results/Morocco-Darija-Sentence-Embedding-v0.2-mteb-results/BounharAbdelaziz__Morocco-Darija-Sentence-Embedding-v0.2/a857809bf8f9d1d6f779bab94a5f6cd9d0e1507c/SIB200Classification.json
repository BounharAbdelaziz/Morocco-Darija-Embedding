{
  "dataset_revision": "a74d7350ea12af010cfb1c21e34f1f81fd2e615b",
  "task_name": "SIB200Classification",
  "mteb_version": "1.34.22",
  "scores": {
    "train": [
      {
        "accuracy": 0.720542,
        "f1": 0.713064,
        "f1_weighted": 0.72243,
        "scores_per_experiment": [
          {
            "accuracy": 0.727532,
            "f1": 0.717963,
            "f1_weighted": 0.732074
          },
          {
            "accuracy": 0.723252,
            "f1": 0.704772,
            "f1_weighted": 0.724233
          },
          {
            "accuracy": 0.733238,
            "f1": 0.732537,
            "f1_weighted": 0.731827
          },
          {
            "accuracy": 0.727532,
            "f1": 0.709709,
            "f1_weighted": 0.728038
          },
          {
            "accuracy": 0.738944,
            "f1": 0.739428,
            "f1_weighted": 0.742488
          },
          {
            "accuracy": 0.694722,
            "f1": 0.692219,
            "f1_weighted": 0.694946
          },
          {
            "accuracy": 0.701854,
            "f1": 0.694634,
            "f1_weighted": 0.709103
          },
          {
            "accuracy": 0.713267,
            "f1": 0.710489,
            "f1_weighted": 0.714454
          },
          {
            "accuracy": 0.71184,
            "f1": 0.703569,
            "f1_weighted": 0.713053
          },
          {
            "accuracy": 0.733238,
            "f1": 0.725323,
            "f1_weighted": 0.73409
          }
        ],
        "main_score": 0.720542,
        "hf_subset": "ary_Arab",
        "languages": [
          "ary-Arab"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.627273,
        "f1": 0.618949,
        "f1_weighted": 0.631583,
        "scores_per_experiment": [
          {
            "accuracy": 0.676768,
            "f1": 0.661071,
            "f1_weighted": 0.677315
          },
          {
            "accuracy": 0.616162,
            "f1": 0.594379,
            "f1_weighted": 0.617404
          },
          {
            "accuracy": 0.606061,
            "f1": 0.610458,
            "f1_weighted": 0.609766
          },
          {
            "accuracy": 0.666667,
            "f1": 0.656763,
            "f1_weighted": 0.672468
          },
          {
            "accuracy": 0.707071,
            "f1": 0.685867,
            "f1_weighted": 0.709395
          },
          {
            "accuracy": 0.606061,
            "f1": 0.60461,
            "f1_weighted": 0.610071
          },
          {
            "accuracy": 0.59596,
            "f1": 0.575047,
            "f1_weighted": 0.613396
          },
          {
            "accuracy": 0.646465,
            "f1": 0.642981,
            "f1_weighted": 0.639393
          },
          {
            "accuracy": 0.555556,
            "f1": 0.561123,
            "f1_weighted": 0.548386
          },
          {
            "accuracy": 0.59596,
            "f1": 0.597192,
            "f1_weighted": 0.618235
          }
        ],
        "main_score": 0.627273,
        "hf_subset": "ary_Arab",
        "languages": [
          "ary-Arab"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.72402,
        "f1": 0.717346,
        "f1_weighted": 0.728959,
        "scores_per_experiment": [
          {
            "accuracy": 0.77451,
            "f1": 0.77913,
            "f1_weighted": 0.781984
          },
          {
            "accuracy": 0.686275,
            "f1": 0.66227,
            "f1_weighted": 0.688204
          },
          {
            "accuracy": 0.720588,
            "f1": 0.722912,
            "f1_weighted": 0.718328
          },
          {
            "accuracy": 0.686275,
            "f1": 0.669794,
            "f1_weighted": 0.691809
          },
          {
            "accuracy": 0.789216,
            "f1": 0.78748,
            "f1_weighted": 0.790543
          },
          {
            "accuracy": 0.686275,
            "f1": 0.681442,
            "f1_weighted": 0.68935
          },
          {
            "accuracy": 0.710784,
            "f1": 0.700094,
            "f1_weighted": 0.724859
          },
          {
            "accuracy": 0.705882,
            "f1": 0.702055,
            "f1_weighted": 0.708101
          },
          {
            "accuracy": 0.715686,
            "f1": 0.709298,
            "f1_weighted": 0.722408
          },
          {
            "accuracy": 0.764706,
            "f1": 0.758988,
            "f1_weighted": 0.774008
          }
        ],
        "main_score": 0.72402,
        "hf_subset": "ary_Arab",
        "languages": [
          "ary-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 36.32031178474426,
  "kg_co2_emissions": null
}