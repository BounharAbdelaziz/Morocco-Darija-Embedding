{
  "dataset_revision": "e6b647fcb6299a2f686f742f4d4c023e553ea67e",
  "task_name": "FloresBitextMining",
  "mteb_version": "1.34.22",
  "scores": {
    "devtest": [
      {
        "precision": 0.060274,
        "recall": 0.087945,
        "f1": 0.065602,
        "accuracy": 0.087945,
        "main_score": 0.065602,
        "hf_subset": "ace_Arab-ary_Arab",
        "languages": [
          "ace-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.13307,
        "recall": 0.163043,
        "f1": 0.138811,
        "accuracy": 0.163043,
        "main_score": 0.138811,
        "hf_subset": "bam_Latn-ary_Arab",
        "languages": [
          "bam-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.000989,
        "recall": 0.001976,
        "f1": 0.00099,
        "accuracy": 0.001976,
        "main_score": 0.00099,
        "hf_subset": "dzo_Tibt-ary_Arab",
        "languages": [
          "dzo-Tibt",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.963439,
        "recall": 0.975296,
        "f1": 0.967391,
        "accuracy": 0.975296,
        "main_score": 0.967391,
        "hf_subset": "hin_Deva-ary_Arab",
        "languages": [
          "hin-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.912138,
        "recall": 0.936759,
        "f1": 0.920026,
        "accuracy": 0.936759,
        "main_score": 0.920026,
        "hf_subset": "khm_Khmr-ary_Arab",
        "languages": [
          "khm-Khmr",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.898139,
        "recall": 0.928854,
        "f1": 0.907971,
        "accuracy": 0.928854,
        "main_score": 0.907971,
        "hf_subset": "mag_Deva-ary_Arab",
        "languages": [
          "mag-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.609955,
        "recall": 0.684783,
        "f1": 0.63082,
        "accuracy": 0.684783,
        "main_score": 0.63082,
        "hf_subset": "pap_Latn-ary_Arab",
        "languages": [
          "pap-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.154582,
        "recall": 0.184783,
        "f1": 0.161137,
        "accuracy": 0.184783,
        "main_score": 0.161137,
        "hf_subset": "sot_Latn-ary_Arab",
        "languages": [
          "sot-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.956851,
        "recall": 0.970356,
        "f1": 0.961298,
        "accuracy": 0.970356,
        "main_score": 0.961298,
        "hf_subset": "tur_Latn-ary_Arab",
        "languages": [
          "tur-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.360202,
        "recall": 0.422925,
        "f1": 0.374842,
        "accuracy": 0.422925,
        "main_score": 0.374842,
        "hf_subset": "ace_Latn-ary_Arab",
        "languages": [
          "ace-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.557228,
        "recall": 0.631423,
        "f1": 0.57814,
        "accuracy": 0.631423,
        "main_score": 0.57814,
        "hf_subset": "ban_Latn-ary_Arab",
        "languages": [
          "ban-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.964427,
        "recall": 0.975296,
        "f1": 0.96805,
        "accuracy": 0.975296,
        "main_score": 0.96805,
        "hf_subset": "ell_Grek-ary_Arab",
        "languages": [
          "ell-Grek",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.830863,
        "recall": 0.876482,
        "f1": 0.844848,
        "accuracy": 0.876482,
        "main_score": 0.844848,
        "hf_subset": "hne_Deva-ary_Arab",
        "languages": [
          "hne-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.147475,
        "recall": 0.1917,
        "f1": 0.156361,
        "accuracy": 0.1917,
        "main_score": 0.156361,
        "hf_subset": "kik_Latn-ary_Arab",
        "languages": [
          "kik-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.827157,
        "recall": 0.874506,
        "f1": 0.841535,
        "accuracy": 0.874506,
        "main_score": 0.841535,
        "hf_subset": "mai_Deva-ary_Arab",
        "languages": [
          "mai-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.775305,
        "recall": 0.826087,
        "f1": 0.790719,
        "accuracy": 0.826087,
        "main_score": 0.790719,
        "hf_subset": "pbt_Arab-ary_Arab",
        "languages": [
          "pbt-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.963439,
        "recall": 0.975296,
        "f1": 0.967391,
        "accuracy": 0.975296,
        "main_score": 0.967391,
        "hf_subset": "spa_Latn-ary_Arab",
        "languages": [
          "spa-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.205425,
        "recall": 0.252964,
        "f1": 0.216541,
        "accuracy": 0.252964,
        "main_score": 0.216541,
        "hf_subset": "twi_Latn-ary_Arab",
        "languages": [
          "twi-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.96558,
        "recall": 0.976285,
        "f1": 0.969038,
        "accuracy": 0.976285,
        "main_score": 0.969038,
        "hf_subset": "acm_Arab-ary_Arab",
        "languages": [
          "acm-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.942358,
        "recall": 0.960474,
        "f1": 0.948287,
        "accuracy": 0.960474,
        "main_score": 0.948287,
        "hf_subset": "bel_Cyrl-ary_Arab",
        "languages": [
          "bel-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.97085,
        "recall": 0.980237,
        "f1": 0.973979,
        "accuracy": 0.980237,
        "main_score": 0.973979,
        "hf_subset": "eng_Latn-ary_Arab",
        "languages": [
          "eng-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.963439,
        "recall": 0.975296,
        "f1": 0.967391,
        "accuracy": 0.975296,
        "main_score": 0.967391,
        "hf_subset": "hrv_Latn-ary_Arab",
        "languages": [
          "hrv-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.108778,
        "recall": 0.142292,
        "f1": 0.115261,
        "accuracy": 0.142292,
        "main_score": 0.115261,
        "hf_subset": "kin_Latn-ary_Arab",
        "languages": [
          "kin-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.939065,
        "recall": 0.958498,
        "f1": 0.945487,
        "accuracy": 0.958498,
        "main_score": 0.945487,
        "hf_subset": "mal_Mlym-ary_Arab",
        "languages": [
          "mal-Mlym",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.960474,
        "recall": 0.972332,
        "f1": 0.964427,
        "accuracy": 0.972332,
        "main_score": 0.964427,
        "hf_subset": "pes_Arab-ary_Arab",
        "languages": [
          "pes-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.675098,
        "recall": 0.743083,
        "f1": 0.694159,
        "accuracy": 0.743083,
        "main_score": 0.694159,
        "hf_subset": "srd_Latn-ary_Arab",
        "languages": [
          "srd-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.029349,
        "recall": 0.04249,
        "f1": 0.031799,
        "accuracy": 0.04249,
        "main_score": 0.031799,
        "hf_subset": "tzm_Tfng-ary_Arab",
        "languages": [
          "tzm-Tfng",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.972332,
        "recall": 0.981225,
        "f1": 0.975296,
        "accuracy": 0.981225,
        "main_score": 0.975296,
        "hf_subset": "acq_Arab-ary_Arab",
        "languages": [
          "acq-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.176423,
        "recall": 0.216403,
        "f1": 0.184616,
        "accuracy": 0.216403,
        "main_score": 0.184616,
        "hf_subset": "bem_Latn-ary_Arab",
        "languages": [
          "bem-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.945323,
        "recall": 0.961462,
        "f1": 0.950593,
        "accuracy": 0.961462,
        "main_score": 0.950593,
        "hf_subset": "epo_Latn-ary_Arab",
        "languages": [
          "epo-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.966733,
        "recall": 0.977273,
        "f1": 0.970191,
        "accuracy": 0.977273,
        "main_score": 0.970191,
        "hf_subset": "hun_Latn-ary_Arab",
        "languages": [
          "hun-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.876235,
        "recall": 0.912055,
        "f1": 0.887912,
        "accuracy": 0.912055,
        "main_score": 0.887912,
        "hf_subset": "kir_Cyrl-ary_Arab",
        "languages": [
          "kir-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.924489,
        "recall": 0.948617,
        "f1": 0.932378,
        "accuracy": 0.948617,
        "main_score": 0.932378,
        "hf_subset": "mar_Deva-ary_Arab",
        "languages": [
          "mar-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.510021,
        "recall": 0.577075,
        "f1": 0.527154,
        "accuracy": 0.577075,
        "main_score": 0.527154,
        "hf_subset": "plt_Latn-ary_Arab",
        "languages": [
          "plt-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.961462,
        "recall": 0.97332,
        "f1": 0.965415,
        "accuracy": 0.97332,
        "main_score": 0.965415,
        "hf_subset": "srp_Cyrl-ary_Arab",
        "languages": [
          "srp-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.823123,
        "recall": 0.869565,
        "f1": 0.837352,
        "accuracy": 0.869565,
        "main_score": 0.837352,
        "hf_subset": "uig_Arab-ary_Arab",
        "languages": [
          "uig-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.960474,
        "recall": 0.97332,
        "f1": 0.964756,
        "accuracy": 0.97332,
        "main_score": 0.964756,
        "hf_subset": "aeb_Arab-ary_Arab",
        "languages": [
          "aeb-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.931653,
        "recall": 0.951581,
        "f1": 0.938076,
        "accuracy": 0.951581,
        "main_score": 0.938076,
        "hf_subset": "ben_Beng-ary_Arab",
        "languages": [
          "ben-Beng",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.937253,
        "recall": 0.955534,
        "f1": 0.943182,
        "accuracy": 0.955534,
        "main_score": 0.943182,
        "hf_subset": "est_Latn-ary_Arab",
        "languages": [
          "est-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.933136,
        "recall": 0.954545,
        "f1": 0.940217,
        "accuracy": 0.954545,
        "main_score": 0.940217,
        "hf_subset": "hye_Armn-ary_Arab",
        "languages": [
          "hye-Armn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.12922,
        "recall": 0.164032,
        "f1": 0.135434,
        "accuracy": 0.164032,
        "main_score": 0.135434,
        "hf_subset": "kmb_Latn-ary_Arab",
        "languages": [
          "kmb-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.040266,
        "recall": 0.062253,
        "f1": 0.043741,
        "accuracy": 0.062253,
        "main_score": 0.043741,
        "hf_subset": "min_Arab-ary_Arab",
        "languages": [
          "min-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.951087,
        "recall": 0.966403,
        "f1": 0.956192,
        "accuracy": 0.966403,
        "main_score": 0.956192,
        "hf_subset": "pol_Latn-ary_Arab",
        "languages": [
          "pol-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.148794,
        "recall": 0.187747,
        "f1": 0.156407,
        "accuracy": 0.187747,
        "main_score": 0.156407,
        "hf_subset": "ssw_Latn-ary_Arab",
        "languages": [
          "ssw-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.973814,
        "recall": 0.982213,
        "f1": 0.976614,
        "accuracy": 0.982213,
        "main_score": 0.976614,
        "hf_subset": "ukr_Cyrl-ary_Arab",
        "languages": [
          "ukr-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.953557,
        "recall": 0.968379,
        "f1": 0.958498,
        "accuracy": 0.968379,
        "main_score": 0.958498,
        "hf_subset": "afr_Latn-ary_Arab",
        "languages": [
          "afr-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.817442,
        "recall": 0.865613,
        "f1": 0.832054,
        "accuracy": 0.865613,
        "main_score": 0.832054,
        "hf_subset": "bho_Deva-ary_Arab",
        "languages": [
          "bho-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.877454,
        "recall": 0.912055,
        "f1": 0.888194,
        "accuracy": 0.912055,
        "main_score": 0.888194,
        "hf_subset": "eus_Latn-ary_Arab",
        "languages": [
          "eus-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.124866,
        "recall": 0.161067,
        "f1": 0.131571,
        "accuracy": 0.161067,
        "main_score": 0.131571,
        "hf_subset": "ibo_Latn-ary_Arab",
        "languages": [
          "ibo-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.648794,
        "recall": 0.70751,
        "f1": 0.664386,
        "accuracy": 0.70751,
        "main_score": 0.664386,
        "hf_subset": "kmr_Latn-ary_Arab",
        "languages": [
          "kmr-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.560174,
        "recall": 0.641304,
        "f1": 0.582542,
        "accuracy": 0.641304,
        "main_score": 0.582542,
        "hf_subset": "min_Latn-ary_Arab",
        "languages": [
          "min-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.966403,
        "recall": 0.977273,
        "f1": 0.970026,
        "accuracy": 0.977273,
        "main_score": 0.970026,
        "hf_subset": "por_Latn-ary_Arab",
        "languages": [
          "por-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.814369,
        "recall": 0.860672,
        "f1": 0.827953,
        "accuracy": 0.860672,
        "main_score": 0.827953,
        "hf_subset": "sun_Latn-ary_Arab",
        "languages": [
          "sun-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.127579,
        "recall": 0.166008,
        "f1": 0.134311,
        "accuracy": 0.166008,
        "main_score": 0.134311,
        "hf_subset": "umb_Latn-ary_Arab",
        "languages": [
          "umb-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.974308,
        "recall": 0.982213,
        "f1": 0.976943,
        "accuracy": 0.982213,
        "main_score": 0.976943,
        "hf_subset": "ajp_Arab-ary_Arab",
        "languages": [
          "ajp-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.053531,
        "recall": 0.076087,
        "f1": 0.057831,
        "accuracy": 0.076087,
        "main_score": 0.057831,
        "hf_subset": "bjn_Arab-ary_Arab",
        "languages": [
          "bjn-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.141914,
        "recall": 0.182806,
        "f1": 0.150245,
        "accuracy": 0.182806,
        "main_score": 0.150245,
        "hf_subset": "ewe_Latn-ary_Arab",
        "languages": [
          "ewe-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.330678,
        "recall": 0.414032,
        "f1": 0.350856,
        "accuracy": 0.414032,
        "main_score": 0.350856,
        "hf_subset": "ilo_Latn-ary_Arab",
        "languages": [
          "ilo-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.04527,
        "recall": 0.0583,
        "f1": 0.048012,
        "accuracy": 0.0583,
        "main_score": 0.048012,
        "hf_subset": "knc_Arab-ary_Arab",
        "languages": [
          "knc-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.964427,
        "recall": 0.975296,
        "f1": 0.96805,
        "accuracy": 0.975296,
        "main_score": 0.96805,
        "hf_subset": "mkd_Cyrl-ary_Arab",
        "languages": [
          "mkd-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.945817,
        "recall": 0.962451,
        "f1": 0.951252,
        "accuracy": 0.962451,
        "main_score": 0.951252,
        "hf_subset": "prs_Arab-ary_Arab",
        "languages": [
          "prs-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.971344,
        "recall": 0.980237,
        "f1": 0.974308,
        "accuracy": 0.980237,
        "main_score": 0.974308,
        "hf_subset": "swe_Latn-ary_Arab",
        "languages": [
          "swe-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.934947,
        "recall": 0.955534,
        "f1": 0.9417,
        "accuracy": 0.955534,
        "main_score": 0.9417,
        "hf_subset": "urd_Arab-ary_Arab",
        "languages": [
          "urd-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.200994,
        "recall": 0.251976,
        "f1": 0.211713,
        "accuracy": 0.251976,
        "main_score": 0.211713,
        "hf_subset": "aka_Latn-ary_Arab",
        "languages": [
          "aka-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.669198,
        "recall": 0.730237,
        "f1": 0.686188,
        "accuracy": 0.730237,
        "main_score": 0.686188,
        "hf_subset": "bjn_Latn-ary_Arab",
        "languages": [
          "bjn-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.609017,
        "recall": 0.678854,
        "f1": 0.628251,
        "accuracy": 0.678854,
        "main_score": 0.628251,
        "hf_subset": "fao_Latn-ary_Arab",
        "languages": [
          "fao-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.969368,
        "recall": 0.979249,
        "f1": 0.972661,
        "accuracy": 0.979249,
        "main_score": 0.972661,
        "hf_subset": "ind_Latn-ary_Arab",
        "languages": [
          "ind-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.179625,
        "recall": 0.222332,
        "f1": 0.190146,
        "accuracy": 0.222332,
        "main_score": 0.190146,
        "hf_subset": "knc_Latn-ary_Arab",
        "languages": [
          "knc-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.345763,
        "recall": 0.412055,
        "f1": 0.360684,
        "accuracy": 0.412055,
        "main_score": 0.360684,
        "hf_subset": "mlt_Latn-ary_Arab",
        "languages": [
          "mlt-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.173318,
        "recall": 0.217391,
        "f1": 0.183455,
        "accuracy": 0.217391,
        "main_score": 0.183455,
        "hf_subset": "quy_Latn-ary_Arab",
        "languages": [
          "quy-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.805693,
        "recall": 0.854743,
        "f1": 0.820426,
        "accuracy": 0.854743,
        "main_score": 0.820426,
        "hf_subset": "swh_Latn-ary_Arab",
        "languages": [
          "swh-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.842836,
        "recall": 0.887352,
        "f1": 0.856705,
        "accuracy": 0.887352,
        "main_score": 0.856705,
        "hf_subset": "uzn_Latn-ary_Arab",
        "languages": [
          "uzn-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.959486,
        "recall": 0.972332,
        "f1": 0.963768,
        "accuracy": 0.972332,
        "main_score": 0.963768,
        "hf_subset": "als_Latn-ary_Arab",
        "languages": [
          "als-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.030272,
        "recall": 0.04249,
        "f1": 0.032966,
        "accuracy": 0.04249,
        "main_score": 0.032966,
        "hf_subset": "bod_Tibt-ary_Arab",
        "languages": [
          "bod-Tibt",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.123371,
        "recall": 0.158103,
        "f1": 0.13034,
        "accuracy": 0.158103,
        "main_score": 0.13034,
        "hf_subset": "fij_Latn-ary_Arab",
        "languages": [
          "fij-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.911561,
        "recall": 0.937747,
        "f1": 0.920125,
        "accuracy": 0.937747,
        "main_score": 0.920125,
        "hf_subset": "isl_Latn-ary_Arab",
        "languages": [
          "isl-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.184949,
        "recall": 0.23419,
        "f1": 0.195782,
        "accuracy": 0.23419,
        "main_score": 0.195782,
        "hf_subset": "kon_Latn-ary_Arab",
        "languages": [
          "kon-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.082033,
        "recall": 0.109684,
        "f1": 0.087193,
        "accuracy": 0.109684,
        "main_score": 0.087193,
        "hf_subset": "mni_Beng-ary_Arab",
        "languages": [
          "mni-Beng",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.970109,
        "recall": 0.979249,
        "f1": 0.973057,
        "accuracy": 0.979249,
        "main_score": 0.973057,
        "hf_subset": "ron_Latn-ary_Arab",
        "languages": [
          "ron-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.797299,
        "recall": 0.842885,
        "f1": 0.810755,
        "accuracy": 0.842885,
        "main_score": 0.810755,
        "hf_subset": "szl_Latn-ary_Arab",
        "languages": [
          "szl-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.815176,
        "recall": 0.859684,
        "f1": 0.828561,
        "accuracy": 0.859684,
        "main_score": 0.828561,
        "hf_subset": "vec_Latn-ary_Arab",
        "languages": [
          "vec-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.756076,
        "recall": 0.815217,
        "f1": 0.773206,
        "accuracy": 0.815217,
        "main_score": 0.773206,
        "hf_subset": "amh_Ethi-ary_Arab",
        "languages": [
          "amh-Ethi",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.967885,
        "recall": 0.978261,
        "f1": 0.971344,
        "accuracy": 0.978261,
        "main_score": 0.971344,
        "hf_subset": "bos_Latn-ary_Arab",
        "languages": [
          "bos-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.956028,
        "recall": 0.970356,
        "f1": 0.960804,
        "accuracy": 0.970356,
        "main_score": 0.960804,
        "hf_subset": "fin_Latn-ary_Arab",
        "languages": [
          "fin-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.966403,
        "recall": 0.977273,
        "f1": 0.970026,
        "accuracy": 0.977273,
        "main_score": 0.970026,
        "hf_subset": "ita_Latn-ary_Arab",
        "languages": [
          "ita-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.952404,
        "recall": 0.967391,
        "f1": 0.957345,
        "accuracy": 0.967391,
        "main_score": 0.957345,
        "hf_subset": "kor_Hang-ary_Arab",
        "languages": [
          "kor-Hang",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.140651,
        "recall": 0.171937,
        "f1": 0.147623,
        "accuracy": 0.171937,
        "main_score": 0.147623,
        "hf_subset": "mos_Latn-ary_Arab",
        "languages": [
          "mos-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.11409,
        "recall": 0.148221,
        "f1": 0.120904,
        "accuracy": 0.148221,
        "main_score": 0.120904,
        "hf_subset": "run_Latn-ary_Arab",
        "languages": [
          "run-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.936594,
        "recall": 0.956522,
        "f1": 0.943182,
        "accuracy": 0.956522,
        "main_score": 0.943182,
        "hf_subset": "tam_Taml-ary_Arab",
        "languages": [
          "tam-Taml",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.953063,
        "recall": 0.968379,
        "f1": 0.958169,
        "accuracy": 0.968379,
        "main_score": 0.958169,
        "hf_subset": "vie_Latn-ary_Arab",
        "languages": [
          "vie-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.962945,
        "recall": 0.974308,
        "f1": 0.966733,
        "accuracy": 0.974308,
        "main_score": 0.966733,
        "hf_subset": "apc_Arab-ary_Arab",
        "languages": [
          "apc-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.314799,
        "recall": 0.380435,
        "f1": 0.330999,
        "accuracy": 0.380435,
        "main_score": 0.330999,
        "hf_subset": "bug_Latn-ary_Arab",
        "languages": [
          "bug-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.130039,
        "recall": 0.163043,
        "f1": 0.13726,
        "accuracy": 0.163043,
        "main_score": 0.13726,
        "hf_subset": "fon_Latn-ary_Arab",
        "languages": [
          "fon-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.841693,
        "recall": 0.881423,
        "f1": 0.853541,
        "accuracy": 0.881423,
        "main_score": 0.853541,
        "hf_subset": "jav_Latn-ary_Arab",
        "languages": [
          "jav-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.924736,
        "recall": 0.94664,
        "f1": 0.931818,
        "accuracy": 0.94664,
        "main_score": 0.931818,
        "hf_subset": "lao_Laoo-ary_Arab",
        "languages": [
          "lao-Laoo",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.12657,
        "recall": 0.157115,
        "f1": 0.133056,
        "accuracy": 0.157115,
        "main_score": 0.133056,
        "hf_subset": "mri_Latn-ary_Arab",
        "languages": [
          "mri-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.961957,
        "recall": 0.974308,
        "f1": 0.966074,
        "accuracy": 0.974308,
        "main_score": 0.966074,
        "hf_subset": "rus_Cyrl-ary_Arab",
        "languages": [
          "rus-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.187988,
        "recall": 0.229249,
        "f1": 0.197135,
        "accuracy": 0.229249,
        "main_score": 0.197135,
        "hf_subset": "taq_Latn-ary_Arab",
        "languages": [
          "taq-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.494104,
        "recall": 0.581028,
        "f1": 0.516124,
        "accuracy": 0.581028,
        "main_score": 0.516124,
        "hf_subset": "war_Latn-ary_Arab",
        "languages": [
          "war-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.975296,
        "recall": 0.983202,
        "f1": 0.977931,
        "accuracy": 0.983202,
        "main_score": 0.977931,
        "hf_subset": "arb_Arab-ary_Arab",
        "languages": [
          "arb-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.969697,
        "recall": 0.979249,
        "f1": 0.972826,
        "accuracy": 0.979249,
        "main_score": 0.972826,
        "hf_subset": "bul_Cyrl-ary_Arab",
        "languages": [
          "bul-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.965415,
        "recall": 0.976285,
        "f1": 0.969038,
        "accuracy": 0.976285,
        "main_score": 0.969038,
        "hf_subset": "fra_Latn-ary_Arab",
        "languages": [
          "fra-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.94664,
        "recall": 0.963439,
        "f1": 0.95224,
        "accuracy": 0.963439,
        "main_score": 0.95224,
        "hf_subset": "jpn_Jpan-ary_Arab",
        "languages": [
          "jpn-Jpan",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.672511,
        "recall": 0.73913,
        "f1": 0.69085,
        "accuracy": 0.73913,
        "main_score": 0.69085,
        "hf_subset": "lij_Latn-ary_Arab",
        "languages": [
          "lij-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.837698,
        "recall": 0.884387,
        "f1": 0.85247,
        "accuracy": 0.884387,
        "main_score": 0.85247,
        "hf_subset": "mya_Mymr-ary_Arab",
        "languages": [
          "mya-Mymr",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.164695,
        "recall": 0.203557,
        "f1": 0.173485,
        "accuracy": 0.203557,
        "main_score": 0.173485,
        "hf_subset": "sag_Latn-ary_Arab",
        "languages": [
          "sag-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.043414,
        "recall": 0.056324,
        "f1": 0.046519,
        "accuracy": 0.056324,
        "main_score": 0.046519,
        "hf_subset": "taq_Tfng-ary_Arab",
        "languages": [
          "taq-Tfng",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.19416,
        "recall": 0.23913,
        "f1": 0.204641,
        "accuracy": 0.23913,
        "main_score": 0.204641,
        "hf_subset": "wol_Latn-ary_Arab",
        "languages": [
          "wol-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.135132,
        "recall": 0.159091,
        "f1": 0.139655,
        "accuracy": 0.159091,
        "main_score": 0.139655,
        "hf_subset": "arb_Latn-ary_Arab",
        "languages": [
          "arb-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.963768,
        "recall": 0.975296,
        "f1": 0.967556,
        "accuracy": 0.975296,
        "main_score": 0.967556,
        "hf_subset": "cat_Latn-ary_Arab",
        "languages": [
          "cat-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.623298,
        "recall": 0.6917,
        "f1": 0.642098,
        "accuracy": 0.6917,
        "main_score": 0.642098,
        "hf_subset": "fur_Latn-ary_Arab",
        "languages": [
          "fur-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.062672,
        "recall": 0.085968,
        "f1": 0.067111,
        "accuracy": 0.085968,
        "main_score": 0.067111,
        "hf_subset": "kab_Latn-ary_Arab",
        "languages": [
          "kab-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.636345,
        "recall": 0.70751,
        "f1": 0.656248,
        "accuracy": 0.70751,
        "main_score": 0.656248,
        "hf_subset": "lim_Latn-ary_Arab",
        "languages": [
          "lim-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.95751,
        "recall": 0.971344,
        "f1": 0.962121,
        "accuracy": 0.971344,
        "main_score": 0.962121,
        "hf_subset": "nld_Latn-ary_Arab",
        "languages": [
          "nld-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.768939,
        "recall": 0.828063,
        "f1": 0.786288,
        "accuracy": 0.828063,
        "main_score": 0.786288,
        "hf_subset": "san_Deva-ary_Arab",
        "languages": [
          "san-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.388,
        "recall": 0.45751,
        "f1": 0.404872,
        "accuracy": 0.45751,
        "main_score": 0.404872,
        "hf_subset": "tat_Cyrl-ary_Arab",
        "languages": [
          "tat-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.27212,
        "recall": 0.323123,
        "f1": 0.28264,
        "accuracy": 0.323123,
        "main_score": 0.28264,
        "hf_subset": "xho_Latn-ary_Arab",
        "languages": [
          "xho-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.972332,
        "recall": 0.981225,
        "f1": 0.975296,
        "accuracy": 0.981225,
        "main_score": 0.975296,
        "hf_subset": "ars_Arab-ary_Arab",
        "languages": [
          "ars-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.550821,
        "recall": 0.625494,
        "f1": 0.571294,
        "accuracy": 0.625494,
        "main_score": 0.571294,
        "hf_subset": "ceb_Latn-ary_Arab",
        "languages": [
          "ceb-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.151276,
        "recall": 0.179842,
        "f1": 0.157638,
        "accuracy": 0.179842,
        "main_score": 0.157638,
        "hf_subset": "fuv_Latn-ary_Arab",
        "languages": [
          "fuv-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.141773,
        "recall": 0.16996,
        "f1": 0.148516,
        "accuracy": 0.16996,
        "main_score": 0.148516,
        "hf_subset": "kac_Latn-ary_Arab",
        "languages": [
          "kac-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.183293,
        "recall": 0.236166,
        "f1": 0.193868,
        "accuracy": 0.236166,
        "main_score": 0.193868,
        "hf_subset": "lin_Latn-ary_Arab",
        "languages": [
          "lin-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.960639,
        "recall": 0.972332,
        "f1": 0.964427,
        "accuracy": 0.972332,
        "main_score": 0.964427,
        "hf_subset": "nno_Latn-ary_Arab",
        "languages": [
          "nno-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.005455,
        "recall": 0.008893,
        "f1": 0.005639,
        "accuracy": 0.008893,
        "main_score": 0.005639,
        "hf_subset": "sat_Olck-ary_Arab",
        "languages": [
          "sat-Olck",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.908103,
        "recall": 0.935771,
        "f1": 0.916996,
        "accuracy": 0.935771,
        "main_score": 0.916996,
        "hf_subset": "tel_Telu-ary_Arab",
        "languages": [
          "tel-Telu",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.656824,
        "recall": 0.724308,
        "f1": 0.675681,
        "accuracy": 0.724308,
        "main_score": 0.675681,
        "hf_subset": "ydd_Hebr-ary_Arab",
        "languages": [
          "ydd-Hebr",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.093333,
        "recall": 0.156126,
        "f1": 0.1067,
        "accuracy": 0.156126,
        "main_score": 0.1067,
        "hf_subset": "ary_Arab-ace_Arab",
        "languages": [
          "ary-Arab",
          "ace-Arab"
        ]
      },
      {
        "precision": 0.136112,
        "recall": 0.217391,
        "f1": 0.152771,
        "accuracy": 0.217391,
        "main_score": 0.152771,
        "hf_subset": "ary_Arab-bam_Latn",
        "languages": [
          "ary-Arab",
          "bam-Latn"
        ]
      },
      {
        "precision": 0.00055,
        "recall": 0.005929,
        "f1": 0.00077,
        "accuracy": 0.005929,
        "main_score": 0.00077,
        "hf_subset": "ary_Arab-dzo_Tibt",
        "languages": [
          "ary-Arab",
          "dzo-Tibt"
        ]
      },
      {
        "precision": 0.949934,
        "recall": 0.965415,
        "f1": 0.954875,
        "accuracy": 0.965415,
        "main_score": 0.954875,
        "hf_subset": "ary_Arab-hin_Deva",
        "languages": [
          "ary-Arab",
          "hin-Deva"
        ]
      },
      {
        "precision": 0.925889,
        "recall": 0.948617,
        "f1": 0.9333,
        "accuracy": 0.948617,
        "main_score": 0.9333,
        "hf_subset": "ary_Arab-khm_Khmr",
        "languages": [
          "ary-Arab",
          "khm-Khmr"
        ]
      },
      {
        "precision": 0.884634,
        "recall": 0.918972,
        "f1": 0.895487,
        "accuracy": 0.918972,
        "main_score": 0.895487,
        "hf_subset": "ary_Arab-mag_Deva",
        "languages": [
          "ary-Arab",
          "mag-Deva"
        ]
      },
      {
        "precision": 0.641076,
        "recall": 0.728261,
        "f1": 0.665589,
        "accuracy": 0.728261,
        "main_score": 0.665589,
        "hf_subset": "ary_Arab-pap_Latn",
        "languages": [
          "ary-Arab",
          "pap-Latn"
        ]
      },
      {
        "precision": 0.158146,
        "recall": 0.248024,
        "f1": 0.176718,
        "accuracy": 0.248024,
        "main_score": 0.176718,
        "hf_subset": "ary_Arab-sot_Latn",
        "languages": [
          "ary-Arab",
          "sot-Latn"
        ]
      },
      {
        "precision": 0.952734,
        "recall": 0.967391,
        "f1": 0.95751,
        "accuracy": 0.967391,
        "main_score": 0.95751,
        "hf_subset": "ary_Arab-tur_Latn",
        "languages": [
          "ary-Arab",
          "tur-Latn"
        ]
      },
      {
        "precision": 0.356797,
        "recall": 0.464427,
        "f1": 0.383284,
        "accuracy": 0.464427,
        "main_score": 0.383284,
        "hf_subset": "ary_Arab-ace_Latn",
        "languages": [
          "ary-Arab",
          "ace-Latn"
        ]
      },
      {
        "precision": 0.548341,
        "recall": 0.645257,
        "f1": 0.575398,
        "accuracy": 0.645257,
        "main_score": 0.575398,
        "hf_subset": "ary_Arab-ban_Latn",
        "languages": [
          "ary-Arab",
          "ban-Latn"
        ]
      },
      {
        "precision": 0.955863,
        "recall": 0.969368,
        "f1": 0.96031,
        "accuracy": 0.969368,
        "main_score": 0.96031,
        "hf_subset": "ary_Arab-ell_Grek",
        "languages": [
          "ary-Arab",
          "ell-Grek"
        ]
      },
      {
        "precision": 0.819944,
        "recall": 0.871542,
        "f1": 0.836001,
        "accuracy": 0.871542,
        "main_score": 0.836001,
        "hf_subset": "ary_Arab-hne_Deva",
        "languages": [
          "ary-Arab",
          "hne-Deva"
        ]
      },
      {
        "precision": 0.145713,
        "recall": 0.240119,
        "f1": 0.166271,
        "accuracy": 0.240119,
        "main_score": 0.166271,
        "hf_subset": "ary_Arab-kik_Latn",
        "languages": [
          "ary-Arab",
          "kik-Latn"
        ]
      },
      {
        "precision": 0.799605,
        "recall": 0.856719,
        "f1": 0.817457,
        "accuracy": 0.856719,
        "main_score": 0.817457,
        "hf_subset": "ary_Arab-mai_Deva",
        "languages": [
          "ary-Arab",
          "mai-Deva"
        ]
      },
      {
        "precision": 0.785747,
        "recall": 0.839921,
        "f1": 0.802012,
        "accuracy": 0.839921,
        "main_score": 0.802012,
        "hf_subset": "ary_Arab-pbt_Arab",
        "languages": [
          "ary-Arab",
          "pbt-Arab"
        ]
      },
      {
        "precision": 0.963768,
        "recall": 0.975296,
        "f1": 0.967556,
        "accuracy": 0.975296,
        "main_score": 0.967556,
        "hf_subset": "ary_Arab-spa_Latn",
        "languages": [
          "ary-Arab",
          "spa-Latn"
        ]
      },
      {
        "precision": 0.184739,
        "recall": 0.283597,
        "f1": 0.206423,
        "accuracy": 0.283597,
        "main_score": 0.206423,
        "hf_subset": "ary_Arab-twi_Latn",
        "languages": [
          "ary-Arab",
          "twi-Latn"
        ]
      },
      {
        "precision": 0.967062,
        "recall": 0.977273,
        "f1": 0.970356,
        "accuracy": 0.977273,
        "main_score": 0.970356,
        "hf_subset": "ary_Arab-acm_Arab",
        "languages": [
          "ary-Arab",
          "acm-Arab"
        ]
      },
      {
        "precision": 0.941206,
        "recall": 0.959486,
        "f1": 0.947134,
        "accuracy": 0.959486,
        "main_score": 0.947134,
        "hf_subset": "ary_Arab-bel_Cyrl",
        "languages": [
          "ary-Arab",
          "bel-Cyrl"
        ]
      },
      {
        "precision": 0.97859,
        "recall": 0.985178,
        "f1": 0.980731,
        "accuracy": 0.985178,
        "main_score": 0.980731,
        "hf_subset": "ary_Arab-eng_Latn",
        "languages": [
          "ary-Arab",
          "eng-Latn"
        ]
      },
      {
        "precision": 0.960474,
        "recall": 0.972332,
        "f1": 0.964262,
        "accuracy": 0.972332,
        "main_score": 0.964262,
        "hf_subset": "ary_Arab-hrv_Latn",
        "languages": [
          "ary-Arab",
          "hrv-Latn"
        ]
      },
      {
        "precision": 0.12497,
        "recall": 0.199605,
        "f1": 0.140217,
        "accuracy": 0.199605,
        "main_score": 0.140217,
        "hf_subset": "ary_Arab-kin_Latn",
        "languages": [
          "ary-Arab",
          "kin-Latn"
        ]
      },
      {
        "precision": 0.935277,
        "recall": 0.955534,
        "f1": 0.941864,
        "accuracy": 0.955534,
        "main_score": 0.941864,
        "hf_subset": "ary_Arab-mal_Mlym",
        "languages": [
          "ary-Arab",
          "mal-Mlym"
        ]
      },
      {
        "precision": 0.970026,
        "recall": 0.979249,
        "f1": 0.972991,
        "accuracy": 0.979249,
        "main_score": 0.972991,
        "hf_subset": "ary_Arab-pes_Arab",
        "languages": [
          "ary-Arab",
          "pes-Arab"
        ]
      },
      {
        "precision": 0.669549,
        "recall": 0.751976,
        "f1": 0.694306,
        "accuracy": 0.751976,
        "main_score": 0.694306,
        "hf_subset": "ary_Arab-srd_Latn",
        "languages": [
          "ary-Arab",
          "srd-Latn"
        ]
      },
      {
        "precision": 0.044019,
        "recall": 0.085968,
        "f1": 0.050559,
        "accuracy": 0.085968,
        "main_score": 0.050559,
        "hf_subset": "ary_Arab-tzm_Tfng",
        "languages": [
          "ary-Arab",
          "tzm-Tfng"
        ]
      },
      {
        "precision": 0.97859,
        "recall": 0.985178,
        "f1": 0.980731,
        "accuracy": 0.985178,
        "main_score": 0.980731,
        "hf_subset": "ary_Arab-acq_Arab",
        "languages": [
          "ary-Arab",
          "acq-Arab"
        ]
      },
      {
        "precision": 0.165764,
        "recall": 0.253953,
        "f1": 0.184163,
        "accuracy": 0.253953,
        "main_score": 0.184163,
        "hf_subset": "ary_Arab-bem_Latn",
        "languages": [
          "ary-Arab",
          "bem-Latn"
        ]
      },
      {
        "precision": 0.939723,
        "recall": 0.95751,
        "f1": 0.945487,
        "accuracy": 0.95751,
        "main_score": 0.945487,
        "hf_subset": "ary_Arab-epo_Latn",
        "languages": [
          "ary-Arab",
          "epo-Latn"
        ]
      },
      {
        "precision": 0.963768,
        "recall": 0.975296,
        "f1": 0.967556,
        "accuracy": 0.975296,
        "main_score": 0.967556,
        "hf_subset": "ary_Arab-hun_Latn",
        "languages": [
          "ary-Arab",
          "hun-Latn"
        ]
      },
      {
        "precision": 0.88941,
        "recall": 0.91996,
        "f1": 0.899111,
        "accuracy": 0.91996,
        "main_score": 0.899111,
        "hf_subset": "ary_Arab-kir_Cyrl",
        "languages": [
          "ary-Arab",
          "kir-Cyrl"
        ]
      },
      {
        "precision": 0.913208,
        "recall": 0.940711,
        "f1": 0.922266,
        "accuracy": 0.940711,
        "main_score": 0.922266,
        "hf_subset": "ary_Arab-mar_Deva",
        "languages": [
          "ary-Arab",
          "mar-Deva"
        ]
      },
      {
        "precision": 0.54712,
        "recall": 0.646245,
        "f1": 0.574529,
        "accuracy": 0.646245,
        "main_score": 0.574529,
        "hf_subset": "ary_Arab-plt_Latn",
        "languages": [
          "ary-Arab",
          "plt-Latn"
        ]
      },
      {
        "precision": 0.964427,
        "recall": 0.975296,
        "f1": 0.967885,
        "accuracy": 0.975296,
        "main_score": 0.967885,
        "hf_subset": "ary_Arab-srp_Cyrl",
        "languages": [
          "ary-Arab",
          "srp-Cyrl"
        ]
      },
      {
        "precision": 0.829545,
        "recall": 0.878458,
        "f1": 0.844993,
        "accuracy": 0.878458,
        "main_score": 0.844993,
        "hf_subset": "ary_Arab-uig_Arab",
        "languages": [
          "ary-Arab",
          "uig-Arab"
        ]
      },
      {
        "precision": 0.957839,
        "recall": 0.971344,
        "f1": 0.962286,
        "accuracy": 0.971344,
        "main_score": 0.962286,
        "hf_subset": "ary_Arab-aeb_Arab",
        "languages": [
          "ary-Arab",
          "aeb-Arab"
        ]
      },
      {
        "precision": 0.907032,
        "recall": 0.934783,
        "f1": 0.915909,
        "accuracy": 0.934783,
        "main_score": 0.915909,
        "hf_subset": "ary_Arab-ben_Beng",
        "languages": [
          "ary-Arab",
          "ben-Beng"
        ]
      },
      {
        "precision": 0.928854,
        "recall": 0.950593,
        "f1": 0.935935,
        "accuracy": 0.950593,
        "main_score": 0.935935,
        "hf_subset": "ary_Arab-est_Latn",
        "languages": [
          "ary-Arab",
          "est-Latn"
        ]
      },
      {
        "precision": 0.931489,
        "recall": 0.952569,
        "f1": 0.938241,
        "accuracy": 0.952569,
        "main_score": 0.938241,
        "hf_subset": "ary_Arab-hye_Armn",
        "languages": [
          "ary-Arab",
          "hye-Armn"
        ]
      },
      {
        "precision": 0.128322,
        "recall": 0.209486,
        "f1": 0.143846,
        "accuracy": 0.209486,
        "main_score": 0.143846,
        "hf_subset": "ary_Arab-kmb_Latn",
        "languages": [
          "ary-Arab",
          "kmb-Latn"
        ]
      },
      {
        "precision": 0.050162,
        "recall": 0.101779,
        "f1": 0.060137,
        "accuracy": 0.101779,
        "main_score": 0.060137,
        "hf_subset": "ary_Arab-min_Arab",
        "languages": [
          "ary-Arab",
          "min-Arab"
        ]
      },
      {
        "precision": 0.964756,
        "recall": 0.975296,
        "f1": 0.968215,
        "accuracy": 0.975296,
        "main_score": 0.968215,
        "hf_subset": "ary_Arab-pol_Latn",
        "languages": [
          "ary-Arab",
          "pol-Latn"
        ]
      },
      {
        "precision": 0.136056,
        "recall": 0.221344,
        "f1": 0.153124,
        "accuracy": 0.221344,
        "main_score": 0.153124,
        "hf_subset": "ary_Arab-ssw_Latn",
        "languages": [
          "ary-Arab",
          "ssw-Latn"
        ]
      },
      {
        "precision": 0.968215,
        "recall": 0.978261,
        "f1": 0.971509,
        "accuracy": 0.978261,
        "main_score": 0.971509,
        "hf_subset": "ary_Arab-ukr_Cyrl",
        "languages": [
          "ary-Arab",
          "ukr-Cyrl"
        ]
      },
      {
        "precision": 0.956357,
        "recall": 0.970356,
        "f1": 0.960968,
        "accuracy": 0.970356,
        "main_score": 0.960968,
        "hf_subset": "ary_Arab-afr_Latn",
        "languages": [
          "ary-Arab",
          "afr-Latn"
        ]
      },
      {
        "precision": 0.806555,
        "recall": 0.858696,
        "f1": 0.822925,
        "accuracy": 0.858696,
        "main_score": 0.822925,
        "hf_subset": "ary_Arab-bho_Deva",
        "languages": [
          "ary-Arab",
          "bho-Deva"
        ]
      },
      {
        "precision": 0.874753,
        "recall": 0.912055,
        "f1": 0.886397,
        "accuracy": 0.912055,
        "main_score": 0.886397,
        "hf_subset": "ary_Arab-eus_Latn",
        "languages": [
          "ary-Arab",
          "eus-Latn"
        ]
      },
      {
        "precision": 0.114041,
        "recall": 0.206522,
        "f1": 0.132763,
        "accuracy": 0.206522,
        "main_score": 0.132763,
        "hf_subset": "ary_Arab-ibo_Latn",
        "languages": [
          "ary-Arab",
          "ibo-Latn"
        ]
      },
      {
        "precision": 0.640563,
        "recall": 0.731225,
        "f1": 0.667326,
        "accuracy": 0.731225,
        "main_score": 0.667326,
        "hf_subset": "ary_Arab-kmr_Latn",
        "languages": [
          "ary-Arab",
          "kmr-Latn"
        ]
      },
      {
        "precision": 0.565125,
        "recall": 0.66502,
        "f1": 0.593275,
        "accuracy": 0.66502,
        "main_score": 0.593275,
        "hf_subset": "ary_Arab-min_Latn",
        "languages": [
          "ary-Arab",
          "min-Latn"
        ]
      },
      {
        "precision": 0.970026,
        "recall": 0.979249,
        "f1": 0.972991,
        "accuracy": 0.979249,
        "main_score": 0.972991,
        "hf_subset": "ary_Arab-por_Latn",
        "languages": [
          "ary-Arab",
          "por-Latn"
        ]
      },
      {
        "precision": 0.757773,
        "recall": 0.824111,
        "f1": 0.777866,
        "accuracy": 0.824111,
        "main_score": 0.777866,
        "hf_subset": "ary_Arab-sun_Latn",
        "languages": [
          "ary-Arab",
          "sun-Latn"
        ]
      },
      {
        "precision": 0.132195,
        "recall": 0.208498,
        "f1": 0.147245,
        "accuracy": 0.208498,
        "main_score": 0.147245,
        "hf_subset": "ary_Arab-umb_Latn",
        "languages": [
          "ary-Arab",
          "umb-Latn"
        ]
      },
      {
        "precision": 0.966733,
        "recall": 0.977273,
        "f1": 0.970191,
        "accuracy": 0.977273,
        "main_score": 0.970191,
        "hf_subset": "ary_Arab-ajp_Arab",
        "languages": [
          "ary-Arab",
          "ajp-Arab"
        ]
      },
      {
        "precision": 0.078965,
        "recall": 0.141304,
        "f1": 0.091741,
        "accuracy": 0.141304,
        "main_score": 0.091741,
        "hf_subset": "ary_Arab-bjn_Arab",
        "languages": [
          "ary-Arab",
          "bjn-Arab"
        ]
      },
      {
        "precision": 0.15039,
        "recall": 0.235178,
        "f1": 0.168307,
        "accuracy": 0.235178,
        "main_score": 0.168307,
        "hf_subset": "ary_Arab-ewe_Latn",
        "languages": [
          "ary-Arab",
          "ewe-Latn"
        ]
      },
      {
        "precision": 0.367865,
        "recall": 0.474308,
        "f1": 0.395011,
        "accuracy": 0.474308,
        "main_score": 0.395011,
        "hf_subset": "ary_Arab-ilo_Latn",
        "languages": [
          "ary-Arab",
          "ilo-Latn"
        ]
      },
      {
        "precision": 0.050749,
        "recall": 0.097826,
        "f1": 0.060222,
        "accuracy": 0.097826,
        "main_score": 0.060222,
        "hf_subset": "ary_Arab-knc_Arab",
        "languages": [
          "ary-Arab",
          "knc-Arab"
        ]
      },
      {
        "precision": 0.965909,
        "recall": 0.976285,
        "f1": 0.969368,
        "accuracy": 0.976285,
        "main_score": 0.969368,
        "hf_subset": "ary_Arab-mkd_Cyrl",
        "languages": [
          "ary-Arab",
          "mkd-Cyrl"
        ]
      },
      {
        "precision": 0.953393,
        "recall": 0.968379,
        "f1": 0.958333,
        "accuracy": 0.968379,
        "main_score": 0.958333,
        "hf_subset": "ary_Arab-prs_Arab",
        "languages": [
          "ary-Arab",
          "prs-Arab"
        ]
      },
      {
        "precision": 0.968215,
        "recall": 0.978261,
        "f1": 0.971509,
        "accuracy": 0.978261,
        "main_score": 0.971509,
        "hf_subset": "ary_Arab-swe_Latn",
        "languages": [
          "ary-Arab",
          "swe-Latn"
        ]
      },
      {
        "precision": 0.934865,
        "recall": 0.955534,
        "f1": 0.941601,
        "accuracy": 0.955534,
        "main_score": 0.941601,
        "hf_subset": "ary_Arab-urd_Arab",
        "languages": [
          "ary-Arab",
          "urd-Arab"
        ]
      },
      {
        "precision": 0.156284,
        "recall": 0.256917,
        "f1": 0.177827,
        "accuracy": 0.256917,
        "main_score": 0.177827,
        "hf_subset": "ary_Arab-aka_Latn",
        "languages": [
          "ary-Arab",
          "aka-Latn"
        ]
      },
      {
        "precision": 0.658442,
        "recall": 0.737154,
        "f1": 0.681628,
        "accuracy": 0.737154,
        "main_score": 0.681628,
        "hf_subset": "ary_Arab-bjn_Latn",
        "languages": [
          "ary-Arab",
          "bjn-Latn"
        ]
      },
      {
        "precision": 0.611992,
        "recall": 0.703557,
        "f1": 0.638908,
        "accuracy": 0.703557,
        "main_score": 0.638908,
        "hf_subset": "ary_Arab-fao_Latn",
        "languages": [
          "ary-Arab",
          "fao-Latn"
        ]
      },
      {
        "precision": 0.968215,
        "recall": 0.978261,
        "f1": 0.971509,
        "accuracy": 0.978261,
        "main_score": 0.971509,
        "hf_subset": "ary_Arab-ind_Latn",
        "languages": [
          "ary-Arab",
          "ind-Latn"
        ]
      },
      {
        "precision": 0.173439,
        "recall": 0.268775,
        "f1": 0.194202,
        "accuracy": 0.268775,
        "main_score": 0.194202,
        "hf_subset": "ary_Arab-knc_Latn",
        "languages": [
          "ary-Arab",
          "knc-Latn"
        ]
      },
      {
        "precision": 0.355653,
        "recall": 0.460474,
        "f1": 0.382278,
        "accuracy": 0.460474,
        "main_score": 0.382278,
        "hf_subset": "ary_Arab-mlt_Latn",
        "languages": [
          "ary-Arab",
          "mlt-Latn"
        ]
      },
      {
        "precision": 0.177066,
        "recall": 0.26087,
        "f1": 0.194842,
        "accuracy": 0.26087,
        "main_score": 0.194842,
        "hf_subset": "ary_Arab-quy_Latn",
        "languages": [
          "ary-Arab",
          "quy-Latn"
        ]
      },
      {
        "precision": 0.784667,
        "recall": 0.842885,
        "f1": 0.802108,
        "accuracy": 0.842885,
        "main_score": 0.802108,
        "hf_subset": "ary_Arab-swh_Latn",
        "languages": [
          "ary-Arab",
          "swh-Latn"
        ]
      },
      {
        "precision": 0.858943,
        "recall": 0.899209,
        "f1": 0.87156,
        "accuracy": 0.899209,
        "main_score": 0.87156,
        "hf_subset": "ary_Arab-uzn_Latn",
        "languages": [
          "ary-Arab",
          "uzn-Latn"
        ]
      },
      {
        "precision": 0.955369,
        "recall": 0.969368,
        "f1": 0.95998,
        "accuracy": 0.969368,
        "main_score": 0.95998,
        "hf_subset": "ary_Arab-als_Latn",
        "languages": [
          "ary-Arab",
          "als-Latn"
        ]
      },
      {
        "precision": 0.026168,
        "recall": 0.067194,
        "f1": 0.031173,
        "accuracy": 0.067194,
        "main_score": 0.031173,
        "hf_subset": "ary_Arab-bod_Tibt",
        "languages": [
          "ary-Arab",
          "bod-Tibt"
        ]
      },
      {
        "precision": 0.136628,
        "recall": 0.218379,
        "f1": 0.152643,
        "accuracy": 0.218379,
        "main_score": 0.152643,
        "hf_subset": "ary_Arab-fij_Latn",
        "languages": [
          "ary-Arab",
          "fij-Latn"
        ]
      },
      {
        "precision": 0.901433,
        "recall": 0.929842,
        "f1": 0.910474,
        "accuracy": 0.929842,
        "main_score": 0.910474,
        "hf_subset": "ary_Arab-isl_Latn",
        "languages": [
          "ary-Arab",
          "isl-Latn"
        ]
      },
      {
        "precision": 0.186491,
        "recall": 0.272727,
        "f1": 0.204927,
        "accuracy": 0.272727,
        "main_score": 0.204927,
        "hf_subset": "ary_Arab-kon_Latn",
        "languages": [
          "ary-Arab",
          "kon-Latn"
        ]
      },
      {
        "precision": 0.09857,
        "recall": 0.170949,
        "f1": 0.11259,
        "accuracy": 0.170949,
        "main_score": 0.11259,
        "hf_subset": "ary_Arab-mni_Beng",
        "languages": [
          "ary-Arab",
          "mni-Beng"
        ]
      },
      {
        "precision": 0.970685,
        "recall": 0.980237,
        "f1": 0.973814,
        "accuracy": 0.980237,
        "main_score": 0.973814,
        "hf_subset": "ary_Arab-ron_Latn",
        "languages": [
          "ary-Arab",
          "ron-Latn"
        ]
      },
      {
        "precision": 0.779315,
        "recall": 0.836957,
        "f1": 0.797153,
        "accuracy": 0.836957,
        "main_score": 0.797153,
        "hf_subset": "ary_Arab-szl_Latn",
        "languages": [
          "ary-Arab",
          "szl-Latn"
        ]
      },
      {
        "precision": 0.795603,
        "recall": 0.851779,
        "f1": 0.812945,
        "accuracy": 0.851779,
        "main_score": 0.812945,
        "hf_subset": "ary_Arab-vec_Latn",
        "languages": [
          "ary-Arab",
          "vec-Latn"
        ]
      },
      {
        "precision": 0.790662,
        "recall": 0.846838,
        "f1": 0.807345,
        "accuracy": 0.846838,
        "main_score": 0.807345,
        "hf_subset": "ary_Arab-amh_Ethi",
        "languages": [
          "ary-Arab",
          "amh-Ethi"
        ]
      },
      {
        "precision": 0.968874,
        "recall": 0.978261,
        "f1": 0.971838,
        "accuracy": 0.978261,
        "main_score": 0.971838,
        "hf_subset": "ary_Arab-bos_Latn",
        "languages": [
          "ary-Arab",
          "bos-Latn"
        ]
      },
      {
        "precision": 0.945323,
        "recall": 0.962451,
        "f1": 0.950922,
        "accuracy": 0.962451,
        "main_score": 0.950922,
        "hf_subset": "ary_Arab-fin_Latn",
        "languages": [
          "ary-Arab",
          "fin-Latn"
        ]
      },
      {
        "precision": 0.97612,
        "recall": 0.983202,
        "f1": 0.978426,
        "accuracy": 0.983202,
        "main_score": 0.978426,
        "hf_subset": "ary_Arab-ita_Latn",
        "languages": [
          "ary-Arab",
          "ita-Latn"
        ]
      },
      {
        "precision": 0.940547,
        "recall": 0.958498,
        "f1": 0.946311,
        "accuracy": 0.958498,
        "main_score": 0.946311,
        "hf_subset": "ary_Arab-kor_Hang",
        "languages": [
          "ary-Arab",
          "kor-Hang"
        ]
      },
      {
        "precision": 0.151284,
        "recall": 0.237154,
        "f1": 0.168983,
        "accuracy": 0.237154,
        "main_score": 0.168983,
        "hf_subset": "ary_Arab-mos_Latn",
        "languages": [
          "ary-Arab",
          "mos-Latn"
        ]
      },
      {
        "precision": 0.116412,
        "recall": 0.188735,
        "f1": 0.130522,
        "accuracy": 0.188735,
        "main_score": 0.130522,
        "hf_subset": "ary_Arab-run_Latn",
        "languages": [
          "ary-Arab",
          "run-Latn"
        ]
      },
      {
        "precision": 0.940053,
        "recall": 0.959486,
        "f1": 0.946476,
        "accuracy": 0.959486,
        "main_score": 0.946476,
        "hf_subset": "ary_Arab-tam_Taml",
        "languages": [
          "ary-Arab",
          "tam-Taml"
        ]
      },
      {
        "precision": 0.951746,
        "recall": 0.965415,
        "f1": 0.956192,
        "accuracy": 0.965415,
        "main_score": 0.956192,
        "hf_subset": "ary_Arab-vie_Latn",
        "languages": [
          "ary-Arab",
          "vie-Latn"
        ]
      },
      {
        "precision": 0.96805,
        "recall": 0.977273,
        "f1": 0.971014,
        "accuracy": 0.977273,
        "main_score": 0.971014,
        "hf_subset": "ary_Arab-apc_Arab",
        "languages": [
          "ary-Arab",
          "apc-Arab"
        ]
      },
      {
        "precision": 0.32228,
        "recall": 0.428854,
        "f1": 0.348437,
        "accuracy": 0.428854,
        "main_score": 0.348437,
        "hf_subset": "ary_Arab-bug_Latn",
        "languages": [
          "ary-Arab",
          "bug-Latn"
        ]
      },
      {
        "precision": 0.099857,
        "recall": 0.181818,
        "f1": 0.11446,
        "accuracy": 0.181818,
        "main_score": 0.11446,
        "hf_subset": "ary_Arab-fon_Latn",
        "languages": [
          "ary-Arab",
          "fon-Latn"
        ]
      },
      {
        "precision": 0.812253,
        "recall": 0.866601,
        "f1": 0.82971,
        "accuracy": 0.866601,
        "main_score": 0.82971,
        "hf_subset": "ary_Arab-jav_Latn",
        "languages": [
          "ary-Arab",
          "jav-Latn"
        ]
      },
      {
        "precision": 0.919466,
        "recall": 0.945652,
        "f1": 0.928195,
        "accuracy": 0.945652,
        "main_score": 0.928195,
        "hf_subset": "ary_Arab-lao_Laoo",
        "languages": [
          "ary-Arab",
          "lao-Laoo"
        ]
      },
      {
        "precision": 0.099036,
        "recall": 0.176877,
        "f1": 0.113617,
        "accuracy": 0.176877,
        "main_score": 0.113617,
        "hf_subset": "ary_Arab-mri_Latn",
        "languages": [
          "ary-Arab",
          "mri-Latn"
        ]
      },
      {
        "precision": 0.969532,
        "recall": 0.979249,
        "f1": 0.972661,
        "accuracy": 0.979249,
        "main_score": 0.972661,
        "hf_subset": "ary_Arab-rus_Cyrl",
        "languages": [
          "ary-Arab",
          "rus-Cyrl"
        ]
      },
      {
        "precision": 0.189594,
        "recall": 0.272727,
        "f1": 0.208135,
        "accuracy": 0.272727,
        "main_score": 0.208135,
        "hf_subset": "ary_Arab-taq_Latn",
        "languages": [
          "ary-Arab",
          "taq-Latn"
        ]
      },
      {
        "precision": 0.515383,
        "recall": 0.616601,
        "f1": 0.543343,
        "accuracy": 0.616601,
        "main_score": 0.543343,
        "hf_subset": "ary_Arab-war_Latn",
        "languages": [
          "ary-Arab",
          "war-Latn"
        ]
      },
      {
        "precision": 0.974638,
        "recall": 0.982213,
        "f1": 0.977108,
        "accuracy": 0.982213,
        "main_score": 0.977108,
        "hf_subset": "ary_Arab-arb_Arab",
        "languages": [
          "ary-Arab",
          "arb-Arab"
        ]
      },
      {
        "precision": 0.968215,
        "recall": 0.978261,
        "f1": 0.971509,
        "accuracy": 0.978261,
        "main_score": 0.971509,
        "hf_subset": "ary_Arab-bul_Cyrl",
        "languages": [
          "ary-Arab",
          "bul-Cyrl"
        ]
      },
      {
        "precision": 0.970685,
        "recall": 0.979249,
        "f1": 0.973485,
        "accuracy": 0.979249,
        "main_score": 0.973485,
        "hf_subset": "ary_Arab-fra_Latn",
        "languages": [
          "ary-Arab",
          "fra-Latn"
        ]
      },
      {
        "precision": 0.941206,
        "recall": 0.959486,
        "f1": 0.947134,
        "accuracy": 0.959486,
        "main_score": 0.947134,
        "hf_subset": "ary_Arab-jpn_Jpan",
        "languages": [
          "ary-Arab",
          "jpn-Jpan"
        ]
      },
      {
        "precision": 0.656738,
        "recall": 0.740119,
        "f1": 0.680948,
        "accuracy": 0.740119,
        "main_score": 0.680948,
        "hf_subset": "ary_Arab-lij_Latn",
        "languages": [
          "ary-Arab",
          "lij-Latn"
        ]
      },
      {
        "precision": 0.846789,
        "recall": 0.890316,
        "f1": 0.860178,
        "accuracy": 0.890316,
        "main_score": 0.860178,
        "hf_subset": "ary_Arab-mya_Mymr",
        "languages": [
          "ary-Arab",
          "mya-Mymr"
        ]
      },
      {
        "precision": 0.176209,
        "recall": 0.26581,
        "f1": 0.194138,
        "accuracy": 0.26581,
        "main_score": 0.194138,
        "hf_subset": "ary_Arab-sag_Latn",
        "languages": [
          "ary-Arab",
          "sag-Latn"
        ]
      },
      {
        "precision": 0.042588,
        "recall": 0.081028,
        "f1": 0.046862,
        "accuracy": 0.081028,
        "main_score": 0.046862,
        "hf_subset": "ary_Arab-taq_Tfng",
        "languages": [
          "ary-Arab",
          "taq-Tfng"
        ]
      },
      {
        "precision": 0.187543,
        "recall": 0.285573,
        "f1": 0.208327,
        "accuracy": 0.285573,
        "main_score": 0.208327,
        "hf_subset": "ary_Arab-wol_Latn",
        "languages": [
          "ary-Arab",
          "wol-Latn"
        ]
      },
      {
        "precision": 0.1511,
        "recall": 0.228261,
        "f1": 0.168025,
        "accuracy": 0.228261,
        "main_score": 0.168025,
        "hf_subset": "ary_Arab-arb_Latn",
        "languages": [
          "ary-Arab",
          "arb-Latn"
        ]
      },
      {
        "precision": 0.962615,
        "recall": 0.974308,
        "f1": 0.966403,
        "accuracy": 0.974308,
        "main_score": 0.966403,
        "hf_subset": "ary_Arab-cat_Latn",
        "languages": [
          "ary-Arab",
          "cat-Latn"
        ]
      },
      {
        "precision": 0.626353,
        "recall": 0.716403,
        "f1": 0.65295,
        "accuracy": 0.716403,
        "main_score": 0.65295,
        "hf_subset": "ary_Arab-fur_Latn",
        "languages": [
          "ary-Arab",
          "fur-Latn"
        ]
      },
      {
        "precision": 0.070646,
        "recall": 0.121542,
        "f1": 0.080235,
        "accuracy": 0.121542,
        "main_score": 0.080235,
        "hf_subset": "ary_Arab-kab_Latn",
        "languages": [
          "ary-Arab",
          "kab-Latn"
        ]
      },
      {
        "precision": 0.64972,
        "recall": 0.73419,
        "f1": 0.675499,
        "accuracy": 0.73419,
        "main_score": 0.675499,
        "hf_subset": "ary_Arab-lim_Latn",
        "languages": [
          "ary-Arab",
          "lim-Latn"
        ]
      },
      {
        "precision": 0.959651,
        "recall": 0.972332,
        "f1": 0.963768,
        "accuracy": 0.972332,
        "main_score": 0.963768,
        "hf_subset": "ary_Arab-nld_Latn",
        "languages": [
          "ary-Arab",
          "nld-Latn"
        ]
      },
      {
        "precision": 0.769466,
        "recall": 0.833992,
        "f1": 0.789295,
        "accuracy": 0.833992,
        "main_score": 0.789295,
        "hf_subset": "ary_Arab-san_Deva",
        "languages": [
          "ary-Arab",
          "san-Deva"
        ]
      },
      {
        "precision": 0.400216,
        "recall": 0.512846,
        "f1": 0.429436,
        "accuracy": 0.512846,
        "main_score": 0.429436,
        "hf_subset": "ary_Arab-tat_Cyrl",
        "languages": [
          "ary-Arab",
          "tat-Cyrl"
        ]
      },
      {
        "precision": 0.266094,
        "recall": 0.371542,
        "f1": 0.290941,
        "accuracy": 0.371542,
        "main_score": 0.290941,
        "hf_subset": "ary_Arab-xho_Latn",
        "languages": [
          "ary-Arab",
          "xho-Latn"
        ]
      },
      {
        "precision": 0.96945,
        "recall": 0.978261,
        "f1": 0.972233,
        "accuracy": 0.978261,
        "main_score": 0.972233,
        "hf_subset": "ary_Arab-ars_Arab",
        "languages": [
          "ary-Arab",
          "ars-Arab"
        ]
      },
      {
        "precision": 0.530642,
        "recall": 0.636364,
        "f1": 0.560977,
        "accuracy": 0.636364,
        "main_score": 0.560977,
        "hf_subset": "ary_Arab-ceb_Latn",
        "languages": [
          "ary-Arab",
          "ceb-Latn"
        ]
      },
      {
        "precision": 0.153151,
        "recall": 0.245059,
        "f1": 0.171103,
        "accuracy": 0.245059,
        "main_score": 0.171103,
        "hf_subset": "ary_Arab-fuv_Latn",
        "languages": [
          "ary-Arab",
          "fuv-Latn"
        ]
      },
      {
        "precision": 0.140795,
        "recall": 0.225296,
        "f1": 0.157366,
        "accuracy": 0.225296,
        "main_score": 0.157366,
        "hf_subset": "ary_Arab-kac_Latn",
        "languages": [
          "ary-Arab",
          "kac-Latn"
        ]
      },
      {
        "precision": 0.180172,
        "recall": 0.279644,
        "f1": 0.201221,
        "accuracy": 0.279644,
        "main_score": 0.201221,
        "hf_subset": "ary_Arab-lin_Latn",
        "languages": [
          "ary-Arab",
          "lin-Latn"
        ]
      },
      {
        "precision": 0.952734,
        "recall": 0.967391,
        "f1": 0.95751,
        "accuracy": 0.967391,
        "main_score": 0.95751,
        "hf_subset": "ary_Arab-nno_Latn",
        "languages": [
          "ary-Arab",
          "nno-Latn"
        ]
      },
      {
        "precision": 0.002831,
        "recall": 0.013834,
        "f1": 0.003517,
        "accuracy": 0.013834,
        "main_score": 0.003517,
        "hf_subset": "ary_Arab-sat_Olck",
        "languages": [
          "ary-Arab",
          "sat-Olck"
        ]
      },
      {
        "precision": 0.898715,
        "recall": 0.929842,
        "f1": 0.908762,
        "accuracy": 0.929842,
        "main_score": 0.908762,
        "hf_subset": "ary_Arab-tel_Telu",
        "languages": [
          "ary-Arab",
          "tel-Telu"
        ]
      },
      {
        "precision": 0.701426,
        "recall": 0.775692,
        "f1": 0.72329,
        "accuracy": 0.775692,
        "main_score": 0.72329,
        "hf_subset": "ary_Arab-ydd_Hebr",
        "languages": [
          "ary-Arab",
          "ydd-Hebr"
        ]
      },
      {
        "precision": 0.965662,
        "recall": 0.976285,
        "f1": 0.969104,
        "accuracy": 0.976285,
        "main_score": 0.969104,
        "hf_subset": "ary_Arab-ces_Latn",
        "languages": [
          "ary-Arab",
          "ces-Latn"
        ]
      },
      {
        "precision": 0.193803,
        "recall": 0.288538,
        "f1": 0.215267,
        "accuracy": 0.288538,
        "main_score": 0.215267,
        "hf_subset": "ary_Arab-gaz_Latn",
        "languages": [
          "ary-Arab",
          "gaz-Latn"
        ]
      },
      {
        "precision": 0.167259,
        "recall": 0.251976,
        "f1": 0.184385,
        "accuracy": 0.251976,
        "main_score": 0.184385,
        "hf_subset": "ary_Arab-kam_Latn",
        "languages": [
          "ary-Arab",
          "kam-Latn"
        ]
      },
      {
        "precision": 0.946673,
        "recall": 0.961462,
        "f1": 0.951416,
        "accuracy": 0.961462,
        "main_score": 0.951416,
        "hf_subset": "ary_Arab-lit_Latn",
        "languages": [
          "ary-Arab",
          "lit-Latn"
        ]
      },
      {
        "precision": 0.968215,
        "recall": 0.978261,
        "f1": 0.971509,
        "accuracy": 0.978261,
        "main_score": 0.971509,
        "hf_subset": "ary_Arab-nob_Latn",
        "languages": [
          "ary-Arab",
          "nob-Latn"
        ]
      },
      {
        "precision": 0.560069,
        "recall": 0.660079,
        "f1": 0.588116,
        "accuracy": 0.660079,
        "main_score": 0.588116,
        "hf_subset": "ary_Arab-scn_Latn",
        "languages": [
          "ary-Arab",
          "scn-Latn"
        ]
      },
      {
        "precision": 0.166272,
        "recall": 0.25,
        "f1": 0.184408,
        "accuracy": 0.25,
        "main_score": 0.184408,
        "hf_subset": "ary_Arab-tgk_Cyrl",
        "languages": [
          "ary-Arab",
          "tgk-Cyrl"
        ]
      },
      {
        "precision": 0.104953,
        "recall": 0.188735,
        "f1": 0.122218,
        "accuracy": 0.188735,
        "main_score": 0.122218,
        "hf_subset": "ary_Arab-yor_Latn",
        "languages": [
          "ary-Arab",
          "yor-Latn"
        ]
      },
      {
        "precision": 0.967885,
        "recall": 0.977273,
        "f1": 0.97085,
        "accuracy": 0.977273,
        "main_score": 0.97085,
        "hf_subset": "ary_Arab-arz_Arab",
        "languages": [
          "ary-Arab",
          "arz-Arab"
        ]
      },
      {
        "precision": 0.169856,
        "recall": 0.257905,
        "f1": 0.188113,
        "accuracy": 0.257905,
        "main_score": 0.188113,
        "hf_subset": "ary_Arab-cjk_Latn",
        "languages": [
          "ary-Arab",
          "cjk-Latn"
        ]
      },
      {
        "precision": 0.518793,
        "recall": 0.625494,
        "f1": 0.548954,
        "accuracy": 0.625494,
        "main_score": 0.548954,
        "hf_subset": "ary_Arab-gla_Latn",
        "languages": [
          "ary-Arab",
          "gla-Latn"
        ]
      },
      {
        "precision": 0.915514,
        "recall": 0.939723,
        "f1": 0.923057,
        "accuracy": 0.939723,
        "main_score": 0.923057,
        "hf_subset": "ary_Arab-kan_Knda",
        "languages": [
          "ary-Arab",
          "kan-Knda"
        ]
      },
      {
        "precision": 0.580642,
        "recall": 0.671937,
        "f1": 0.606253,
        "accuracy": 0.671937,
        "main_score": 0.606253,
        "hf_subset": "ary_Arab-lmo_Latn",
        "languages": [
          "ary-Arab",
          "lmo-Latn"
        ]
      },
      {
        "precision": 0.942556,
        "recall": 0.959486,
        "f1": 0.947958,
        "accuracy": 0.959486,
        "main_score": 0.947958,
        "hf_subset": "ary_Arab-npi_Deva",
        "languages": [
          "ary-Arab",
          "npi-Deva"
        ]
      },
      {
        "precision": 0.126235,
        "recall": 0.217391,
        "f1": 0.144453,
        "accuracy": 0.217391,
        "main_score": 0.144453,
        "hf_subset": "ary_Arab-shn_Mymr",
        "languages": [
          "ary-Arab",
          "shn-Mymr"
        ]
      },
      {
        "precision": 0.919302,
        "recall": 0.943676,
        "f1": 0.927207,
        "accuracy": 0.943676,
        "main_score": 0.927207,
        "hf_subset": "ary_Arab-tgl_Latn",
        "languages": [
          "ary-Arab",
          "tgl-Latn"
        ]
      },
      {
        "precision": 0.967227,
        "recall": 0.977273,
        "f1": 0.97052,
        "accuracy": 0.977273,
        "main_score": 0.97052,
        "hf_subset": "ary_Arab-yue_Hant",
        "languages": [
          "ary-Arab",
          "yue-Hant"
        ]
      },
      {
        "precision": 0.710566,
        "recall": 0.785573,
        "f1": 0.732691,
        "accuracy": 0.785573,
        "main_score": 0.732691,
        "hf_subset": "ary_Arab-asm_Beng",
        "languages": [
          "ary-Arab",
          "asm-Beng"
        ]
      },
      {
        "precision": 0.086961,
        "recall": 0.152174,
        "f1": 0.099525,
        "accuracy": 0.152174,
        "main_score": 0.099525,
        "hf_subset": "ary_Arab-ckb_Arab",
        "languages": [
          "ary-Arab",
          "ckb-Arab"
        ]
      },
      {
        "precision": 0.701606,
        "recall": 0.777668,
        "f1": 0.723874,
        "accuracy": 0.777668,
        "main_score": 0.723874,
        "hf_subset": "ary_Arab-gle_Latn",
        "languages": [
          "ary-Arab",
          "gle-Latn"
        ]
      },
      {
        "precision": 0.387327,
        "recall": 0.499012,
        "f1": 0.416098,
        "accuracy": 0.499012,
        "main_score": 0.416098,
        "hf_subset": "ary_Arab-kas_Arab",
        "languages": [
          "ary-Arab",
          "kas-Arab"
        ]
      },
      {
        "precision": 0.441687,
        "recall": 0.545455,
        "f1": 0.469383,
        "accuracy": 0.545455,
        "main_score": 0.469383,
        "hf_subset": "ary_Arab-ltg_Latn",
        "languages": [
          "ary-Arab",
          "ltg-Latn"
        ]
      },
      {
        "precision": 0.142933,
        "recall": 0.240119,
        "f1": 0.163209,
        "accuracy": 0.240119,
        "main_score": 0.163209,
        "hf_subset": "ary_Arab-nso_Latn",
        "languages": [
          "ary-Arab",
          "nso-Latn"
        ]
      },
      {
        "precision": 0.910161,
        "recall": 0.937747,
        "f1": 0.919038,
        "accuracy": 0.937747,
        "main_score": 0.919038,
        "hf_subset": "ary_Arab-sin_Sinh",
        "languages": [
          "ary-Arab",
          "sin-Sinh"
        ]
      },
      {
        "precision": 0.966733,
        "recall": 0.977273,
        "f1": 0.970191,
        "accuracy": 0.977273,
        "main_score": 0.970191,
        "hf_subset": "ary_Arab-tha_Thai",
        "languages": [
          "ary-Arab",
          "tha-Thai"
        ]
      },
      {
        "precision": 0.960804,
        "recall": 0.97332,
        "f1": 0.964921,
        "accuracy": 0.97332,
        "main_score": 0.964921,
        "hf_subset": "ary_Arab-zho_Hans",
        "languages": [
          "ary-Arab",
          "zho-Hans"
        ]
      },
      {
        "precision": 0.897563,
        "recall": 0.929842,
        "f1": 0.907938,
        "accuracy": 0.929842,
        "main_score": 0.907938,
        "hf_subset": "ary_Arab-ast_Latn",
        "languages": [
          "ary-Arab",
          "ast-Latn"
        ]
      },
      {
        "precision": 0.712895,
        "recall": 0.790514,
        "f1": 0.736298,
        "accuracy": 0.790514,
        "main_score": 0.736298,
        "hf_subset": "ary_Arab-crh_Latn",
        "languages": [
          "ary-Arab",
          "crh-Latn"
        ]
      },
      {
        "precision": 0.969697,
        "recall": 0.979249,
        "f1": 0.972826,
        "accuracy": 0.979249,
        "main_score": 0.972826,
        "hf_subset": "ary_Arab-glg_Latn",
        "languages": [
          "ary-Arab",
          "glg-Latn"
        ]
      },
      {
        "precision": 0.318767,
        "recall": 0.427866,
        "f1": 0.345716,
        "accuracy": 0.427866,
        "main_score": 0.345716,
        "hf_subset": "ary_Arab-kas_Deva",
        "languages": [
          "ary-Arab",
          "kas-Deva"
        ]
      },
      {
        "precision": 0.531195,
        "recall": 0.626482,
        "f1": 0.557859,
        "accuracy": 0.626482,
        "main_score": 0.557859,
        "hf_subset": "ary_Arab-ltz_Latn",
        "languages": [
          "ary-Arab",
          "ltz-Latn"
        ]
      },
      {
        "precision": 0.086877,
        "recall": 0.15415,
        "f1": 0.099108,
        "accuracy": 0.15415,
        "main_score": 0.099108,
        "hf_subset": "ary_Arab-nus_Latn",
        "languages": [
          "ary-Arab",
          "nus-Latn"
        ]
      },
      {
        "precision": 0.95224,
        "recall": 0.967391,
        "f1": 0.957181,
        "accuracy": 0.967391,
        "main_score": 0.957181,
        "hf_subset": "ary_Arab-slk_Latn",
        "languages": [
          "ary-Arab",
          "slk-Latn"
        ]
      },
      {
        "precision": 0.217439,
        "recall": 0.313241,
        "f1": 0.240918,
        "accuracy": 0.313241,
        "main_score": 0.240918,
        "hf_subset": "ary_Arab-tir_Ethi",
        "languages": [
          "ary-Arab",
          "tir-Ethi"
        ]
      },
      {
        "precision": 0.96558,
        "recall": 0.976285,
        "f1": 0.969038,
        "accuracy": 0.976285,
        "main_score": 0.969038,
        "hf_subset": "ary_Arab-zho_Hant",
        "languages": [
          "ary-Arab",
          "zho-Hant"
        ]
      },
      {
        "precision": 0.90695,
        "recall": 0.934783,
        "f1": 0.916008,
        "accuracy": 0.934783,
        "main_score": 0.916008,
        "hf_subset": "ary_Arab-awa_Deva",
        "languages": [
          "ary-Arab",
          "awa-Deva"
        ]
      },
      {
        "precision": 0.85107,
        "recall": 0.894269,
        "f1": 0.86469,
        "accuracy": 0.894269,
        "main_score": 0.86469,
        "hf_subset": "ary_Arab-cym_Latn",
        "languages": [
          "ary-Arab",
          "cym-Latn"
        ]
      },
      {
        "precision": 0.271867,
        "recall": 0.382411,
        "f1": 0.297987,
        "accuracy": 0.382411,
        "main_score": 0.297987,
        "hf_subset": "ary_Arab-grn_Latn",
        "languages": [
          "ary-Arab",
          "grn-Latn"
        ]
      },
      {
        "precision": 0.928063,
        "recall": 0.949605,
        "f1": 0.934947,
        "accuracy": 0.949605,
        "main_score": 0.934947,
        "hf_subset": "ary_Arab-kat_Geor",
        "languages": [
          "ary-Arab",
          "kat-Geor"
        ]
      },
      {
        "precision": 0.18721,
        "recall": 0.284585,
        "f1": 0.208194,
        "accuracy": 0.284585,
        "main_score": 0.208194,
        "hf_subset": "ary_Arab-lua_Latn",
        "languages": [
          "ary-Arab",
          "lua-Latn"
        ]
      },
      {
        "precision": 0.180563,
        "recall": 0.266798,
        "f1": 0.198886,
        "accuracy": 0.266798,
        "main_score": 0.198886,
        "hf_subset": "ary_Arab-nya_Latn",
        "languages": [
          "ary-Arab",
          "nya-Latn"
        ]
      },
      {
        "precision": 0.960804,
        "recall": 0.97332,
        "f1": 0.964921,
        "accuracy": 0.97332,
        "main_score": 0.964921,
        "hf_subset": "ary_Arab-slv_Latn",
        "languages": [
          "ary-Arab",
          "slv-Latn"
        ]
      },
      {
        "precision": 0.31542,
        "recall": 0.431818,
        "f1": 0.344478,
        "accuracy": 0.431818,
        "main_score": 0.344478,
        "hf_subset": "ary_Arab-tpi_Latn",
        "languages": [
          "ary-Arab",
          "tpi-Latn"
        ]
      },
      {
        "precision": 0.968544,
        "recall": 0.978261,
        "f1": 0.971673,
        "accuracy": 0.978261,
        "main_score": 0.971673,
        "hf_subset": "ary_Arab-zsm_Latn",
        "languages": [
          "ary-Arab",
          "zsm-Latn"
        ]
      },
      {
        "precision": 0.136776,
        "recall": 0.212451,
        "f1": 0.15181,
        "accuracy": 0.212451,
        "main_score": 0.15181,
        "hf_subset": "ary_Arab-ayr_Latn",
        "languages": [
          "ary-Arab",
          "ayr-Latn"
        ]
      },
      {
        "precision": 0.968215,
        "recall": 0.978261,
        "f1": 0.971509,
        "accuracy": 0.978261,
        "main_score": 0.971509,
        "hf_subset": "ary_Arab-dan_Latn",
        "languages": [
          "ary-Arab",
          "dan-Latn"
        ]
      },
      {
        "precision": 0.907362,
        "recall": 0.934783,
        "f1": 0.916074,
        "accuracy": 0.934783,
        "main_score": 0.916074,
        "hf_subset": "ary_Arab-guj_Gujr",
        "languages": [
          "ary-Arab",
          "guj-Gujr"
        ]
      },
      {
        "precision": 0.920125,
        "recall": 0.943676,
        "f1": 0.927701,
        "accuracy": 0.943676,
        "main_score": 0.927701,
        "hf_subset": "ary_Arab-kaz_Cyrl",
        "languages": [
          "ary-Arab",
          "kaz-Cyrl"
        ]
      },
      {
        "precision": 0.126593,
        "recall": 0.20751,
        "f1": 0.14355,
        "accuracy": 0.20751,
        "main_score": 0.14355,
        "hf_subset": "ary_Arab-lug_Latn",
        "languages": [
          "ary-Arab",
          "lug-Latn"
        ]
      },
      {
        "precision": 0.897645,
        "recall": 0.927866,
        "f1": 0.907345,
        "accuracy": 0.927866,
        "main_score": 0.907345,
        "hf_subset": "ary_Arab-oci_Latn",
        "languages": [
          "ary-Arab",
          "oci-Latn"
        ]
      },
      {
        "precision": 0.125224,
        "recall": 0.212451,
        "f1": 0.143398,
        "accuracy": 0.212451,
        "main_score": 0.143398,
        "hf_subset": "ary_Arab-smo_Latn",
        "languages": [
          "ary-Arab",
          "smo-Latn"
        ]
      },
      {
        "precision": 0.136685,
        "recall": 0.22332,
        "f1": 0.154778,
        "accuracy": 0.22332,
        "main_score": 0.154778,
        "hf_subset": "ary_Arab-tsn_Latn",
        "languages": [
          "ary-Arab",
          "tsn-Latn"
        ]
      },
      {
        "precision": 0.219949,
        "recall": 0.321146,
        "f1": 0.24257,
        "accuracy": 0.321146,
        "main_score": 0.24257,
        "hf_subset": "ary_Arab-zul_Latn",
        "languages": [
          "ary-Arab",
          "zul-Latn"
        ]
      },
      {
        "precision": 0.372348,
        "recall": 0.481225,
        "f1": 0.400125,
        "accuracy": 0.481225,
        "main_score": 0.400125,
        "hf_subset": "ary_Arab-azb_Arab",
        "languages": [
          "ary-Arab",
          "azb-Arab"
        ]
      },
      {
        "precision": 0.971097,
        "recall": 0.980237,
        "f1": 0.974045,
        "accuracy": 0.980237,
        "main_score": 0.974045,
        "hf_subset": "ary_Arab-deu_Latn",
        "languages": [
          "ary-Arab",
          "deu-Latn"
        ]
      },
      {
        "precision": 0.26635,
        "recall": 0.368577,
        "f1": 0.290788,
        "accuracy": 0.368577,
        "main_score": 0.290788,
        "hf_subset": "ary_Arab-hat_Latn",
        "languages": [
          "ary-Arab",
          "hat-Latn"
        ]
      },
      {
        "precision": 0.114512,
        "recall": 0.189723,
        "f1": 0.129384,
        "accuracy": 0.189723,
        "main_score": 0.129384,
        "hf_subset": "ary_Arab-kbp_Latn",
        "languages": [
          "ary-Arab",
          "kbp-Latn"
        ]
      },
      {
        "precision": 0.146608,
        "recall": 0.229249,
        "f1": 0.162813,
        "accuracy": 0.229249,
        "main_score": 0.162813,
        "hf_subset": "ary_Arab-luo_Latn",
        "languages": [
          "ary-Arab",
          "luo-Latn"
        ]
      },
      {
        "precision": 0.879694,
        "recall": 0.916996,
        "f1": 0.8917,
        "accuracy": 0.916996,
        "main_score": 0.8917,
        "hf_subset": "ary_Arab-ory_Orya",
        "languages": [
          "ary-Arab",
          "ory-Orya"
        ]
      },
      {
        "precision": 0.129762,
        "recall": 0.215415,
        "f1": 0.146779,
        "accuracy": 0.215415,
        "main_score": 0.146779,
        "hf_subset": "ary_Arab-sna_Latn",
        "languages": [
          "ary-Arab",
          "sna-Latn"
        ]
      },
      {
        "precision": 0.127062,
        "recall": 0.212451,
        "f1": 0.144445,
        "accuracy": 0.212451,
        "main_score": 0.144445,
        "hf_subset": "ary_Arab-tso_Latn",
        "languages": [
          "ary-Arab",
          "tso-Latn"
        ]
      },
      {
        "precision": 0.931983,
        "recall": 0.953557,
        "f1": 0.939065,
        "accuracy": 0.953557,
        "main_score": 0.939065,
        "hf_subset": "ary_Arab-azj_Latn",
        "languages": [
          "ary-Arab",
          "azj-Latn"
        ]
      },
      {
        "precision": 0.159143,
        "recall": 0.256917,
        "f1": 0.180385,
        "accuracy": 0.256917,
        "main_score": 0.180385,
        "hf_subset": "ary_Arab-dik_Latn",
        "languages": [
          "ary-Arab",
          "dik-Latn"
        ]
      },
      {
        "precision": 0.454037,
        "recall": 0.571146,
        "f1": 0.486491,
        "accuracy": 0.571146,
        "main_score": 0.486491,
        "hf_subset": "ary_Arab-hau_Latn",
        "languages": [
          "ary-Arab",
          "hau-Latn"
        ]
      },
      {
        "precision": 0.642311,
        "recall": 0.724308,
        "f1": 0.665354,
        "accuracy": 0.724308,
        "main_score": 0.665354,
        "hf_subset": "ary_Arab-kea_Latn",
        "languages": [
          "ary-Arab",
          "kea-Latn"
        ]
      },
      {
        "precision": 0.270705,
        "recall": 0.375494,
        "f1": 0.296163,
        "accuracy": 0.375494,
        "main_score": 0.296163,
        "hf_subset": "ary_Arab-lus_Latn",
        "languages": [
          "ary-Arab",
          "lus-Latn"
        ]
      },
      {
        "precision": 0.422415,
        "recall": 0.527668,
        "f1": 0.449927,
        "accuracy": 0.527668,
        "main_score": 0.449927,
        "hf_subset": "ary_Arab-pag_Latn",
        "languages": [
          "ary-Arab",
          "pag-Latn"
        ]
      },
      {
        "precision": 0.851285,
        "recall": 0.895257,
        "f1": 0.86525,
        "accuracy": 0.895257,
        "main_score": 0.86525,
        "hf_subset": "ary_Arab-snd_Arab",
        "languages": [
          "ary-Arab",
          "snd-Arab"
        ]
      },
      {
        "precision": 0.309715,
        "recall": 0.418972,
        "f1": 0.336603,
        "accuracy": 0.418972,
        "main_score": 0.336603,
        "hf_subset": "ary_Arab-tuk_Latn",
        "languages": [
          "ary-Arab",
          "tuk-Latn"
        ]
      },
      {
        "precision": 0.36284,
        "recall": 0.472332,
        "f1": 0.391042,
        "accuracy": 0.472332,
        "main_score": 0.391042,
        "hf_subset": "ary_Arab-bak_Cyrl",
        "languages": [
          "ary-Arab",
          "bak-Cyrl"
        ]
      },
      {
        "precision": 0.117746,
        "recall": 0.198617,
        "f1": 0.133622,
        "accuracy": 0.198617,
        "main_score": 0.133622,
        "hf_subset": "ary_Arab-dyu_Latn",
        "languages": [
          "ary-Arab",
          "dyu-Latn"
        ]
      },
      {
        "precision": 0.961298,
        "recall": 0.97332,
        "f1": 0.96525,
        "accuracy": 0.97332,
        "main_score": 0.96525,
        "hf_subset": "ary_Arab-heb_Hebr",
        "languages": [
          "ary-Arab",
          "heb-Hebr"
        ]
      },
      {
        "precision": 0.88442,
        "recall": 0.918972,
        "f1": 0.895389,
        "accuracy": 0.918972,
        "main_score": 0.895389,
        "hf_subset": "ary_Arab-khk_Cyrl",
        "languages": [
          "ary-Arab",
          "khk-Cyrl"
        ]
      },
      {
        "precision": 0.951581,
        "recall": 0.965415,
        "f1": 0.956028,
        "accuracy": 0.965415,
        "main_score": 0.956028,
        "hf_subset": "ary_Arab-lvs_Latn",
        "languages": [
          "ary-Arab",
          "lvs-Latn"
        ]
      },
      {
        "precision": 0.866848,
        "recall": 0.906126,
        "f1": 0.879183,
        "accuracy": 0.906126,
        "main_score": 0.879183,
        "hf_subset": "ary_Arab-pan_Guru",
        "languages": [
          "ary-Arab",
          "pan-Guru"
        ]
      },
      {
        "precision": 0.503826,
        "recall": 0.603755,
        "f1": 0.531937,
        "accuracy": 0.603755,
        "main_score": 0.531937,
        "hf_subset": "ary_Arab-som_Latn",
        "languages": [
          "ary-Arab",
          "som-Latn"
        ]
      },
      {
        "precision": 0.163477,
        "recall": 0.254941,
        "f1": 0.183973,
        "accuracy": 0.254941,
        "main_score": 0.183973,
        "hf_subset": "ary_Arab-tum_Latn",
        "languages": [
          "ary-Arab",
          "tum-Latn"
        ]
      },
      {
        "precision": 0.964921,
        "recall": 0.976285,
        "f1": 0.968709,
        "accuracy": 0.976285,
        "main_score": 0.968709,
        "hf_subset": "ces_Latn-ary_Arab",
        "languages": [
          "ces-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.144746,
        "recall": 0.177866,
        "f1": 0.151989,
        "accuracy": 0.177866,
        "main_score": 0.151989,
        "hf_subset": "gaz_Latn-ary_Arab",
        "languages": [
          "gaz-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.160542,
        "recall": 0.202569,
        "f1": 0.169806,
        "accuracy": 0.202569,
        "main_score": 0.169806,
        "hf_subset": "kam_Latn-ary_Arab",
        "languages": [
          "kam-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.951252,
        "recall": 0.966403,
        "f1": 0.956192,
        "accuracy": 0.966403,
        "main_score": 0.956192,
        "hf_subset": "lit_Latn-ary_Arab",
        "languages": [
          "lit-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.966403,
        "recall": 0.977273,
        "f1": 0.970026,
        "accuracy": 0.977273,
        "main_score": 0.970026,
        "hf_subset": "nob_Latn-ary_Arab",
        "languages": [
          "nob-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.570476,
        "recall": 0.646245,
        "f1": 0.589902,
        "accuracy": 0.646245,
        "main_score": 0.589902,
        "hf_subset": "scn_Latn-ary_Arab",
        "languages": [
          "scn-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.138572,
        "recall": 0.173913,
        "f1": 0.146497,
        "accuracy": 0.173913,
        "main_score": 0.146497,
        "hf_subset": "tgk_Cyrl-ary_Arab",
        "languages": [
          "tgk-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.126983,
        "recall": 0.160079,
        "f1": 0.1339,
        "accuracy": 0.160079,
        "main_score": 0.1339,
        "hf_subset": "yor_Latn-ary_Arab",
        "languages": [
          "yor-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.967721,
        "recall": 0.977273,
        "f1": 0.97085,
        "accuracy": 0.977273,
        "main_score": 0.97085,
        "hf_subset": "arz_Arab-ary_Arab",
        "languages": [
          "arz-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.15957,
        "recall": 0.197628,
        "f1": 0.167355,
        "accuracy": 0.197628,
        "main_score": 0.167355,
        "hf_subset": "cjk_Latn-ary_Arab",
        "languages": [
          "cjk-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.49632,
        "recall": 0.560277,
        "f1": 0.512419,
        "accuracy": 0.560277,
        "main_score": 0.512419,
        "hf_subset": "gla_Latn-ary_Arab",
        "languages": [
          "gla-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.908185,
        "recall": 0.935771,
        "f1": 0.917062,
        "accuracy": 0.935771,
        "main_score": 0.917062,
        "hf_subset": "kan_Knda-ary_Arab",
        "languages": [
          "kan-Knda",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.581689,
        "recall": 0.658103,
        "f1": 0.602206,
        "accuracy": 0.658103,
        "main_score": 0.602206,
        "hf_subset": "lmo_Latn-ary_Arab",
        "languages": [
          "lmo-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.931159,
        "recall": 0.951581,
        "f1": 0.937747,
        "accuracy": 0.951581,
        "main_score": 0.937747,
        "hf_subset": "npi_Deva-ary_Arab",
        "languages": [
          "npi-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.135348,
        "recall": 0.167984,
        "f1": 0.142616,
        "accuracy": 0.167984,
        "main_score": 0.142616,
        "hf_subset": "shn_Mymr-ary_Arab",
        "languages": [
          "shn-Mymr",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.915711,
        "recall": 0.939723,
        "f1": 0.923254,
        "accuracy": 0.939723,
        "main_score": 0.923254,
        "hf_subset": "tgl_Latn-ary_Arab",
        "languages": [
          "tgl-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.956028,
        "recall": 0.970356,
        "f1": 0.960804,
        "accuracy": 0.970356,
        "main_score": 0.960804,
        "hf_subset": "yue_Hant-ary_Arab",
        "languages": [
          "yue-Hant",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.698849,
        "recall": 0.762846,
        "f1": 0.716595,
        "accuracy": 0.762846,
        "main_score": 0.716595,
        "hf_subset": "asm_Beng-ary_Arab",
        "languages": [
          "asm-Beng",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.062686,
        "recall": 0.08498,
        "f1": 0.067007,
        "accuracy": 0.08498,
        "main_score": 0.067007,
        "hf_subset": "ckb_Arab-ary_Arab",
        "languages": [
          "ckb-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.708905,
        "recall": 0.771739,
        "f1": 0.726855,
        "accuracy": 0.771739,
        "main_score": 0.726855,
        "hf_subset": "gle_Latn-ary_Arab",
        "languages": [
          "gle-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.383746,
        "recall": 0.456522,
        "f1": 0.401959,
        "accuracy": 0.456522,
        "main_score": 0.401959,
        "hf_subset": "kas_Arab-ary_Arab",
        "languages": [
          "kas-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.436332,
        "recall": 0.514822,
        "f1": 0.456034,
        "accuracy": 0.514822,
        "main_score": 0.456034,
        "hf_subset": "ltg_Latn-ary_Arab",
        "languages": [
          "ltg-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.149594,
        "recall": 0.184783,
        "f1": 0.157055,
        "accuracy": 0.184783,
        "main_score": 0.157055,
        "hf_subset": "nso_Latn-ary_Arab",
        "languages": [
          "nso-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.912138,
        "recall": 0.938735,
        "f1": 0.920685,
        "accuracy": 0.938735,
        "main_score": 0.920685,
        "hf_subset": "sin_Sinh-ary_Arab",
        "languages": [
          "sin-Sinh",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.95191,
        "recall": 0.967391,
        "f1": 0.957016,
        "accuracy": 0.967391,
        "main_score": 0.957016,
        "hf_subset": "tha_Thai-ary_Arab",
        "languages": [
          "tha-Thai",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.953393,
        "recall": 0.968379,
        "f1": 0.958333,
        "accuracy": 0.968379,
        "main_score": 0.958333,
        "hf_subset": "zho_Hans-ary_Arab",
        "languages": [
          "zho-Hans",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.91996,
        "recall": 0.943676,
        "f1": 0.927701,
        "accuracy": 0.943676,
        "main_score": 0.927701,
        "hf_subset": "ast_Latn-ary_Arab",
        "languages": [
          "ast-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.679258,
        "recall": 0.746047,
        "f1": 0.698316,
        "accuracy": 0.746047,
        "main_score": 0.698316,
        "hf_subset": "crh_Latn-ary_Arab",
        "languages": [
          "crh-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.95751,
        "recall": 0.971344,
        "f1": 0.962121,
        "accuracy": 0.971344,
        "main_score": 0.962121,
        "hf_subset": "glg_Latn-ary_Arab",
        "languages": [
          "glg-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.327724,
        "recall": 0.387352,
        "f1": 0.341589,
        "accuracy": 0.387352,
        "main_score": 0.341589,
        "hf_subset": "kas_Deva-ary_Arab",
        "languages": [
          "kas-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.539772,
        "recall": 0.606719,
        "f1": 0.557102,
        "accuracy": 0.606719,
        "main_score": 0.557102,
        "hf_subset": "ltz_Latn-ary_Arab",
        "languages": [
          "ltz-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.077199,
        "recall": 0.110672,
        "f1": 0.083501,
        "accuracy": 0.110672,
        "main_score": 0.083501,
        "hf_subset": "nus_Latn-ary_Arab",
        "languages": [
          "nus-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.960474,
        "recall": 0.97332,
        "f1": 0.964756,
        "accuracy": 0.97332,
        "main_score": 0.964756,
        "hf_subset": "slk_Latn-ary_Arab",
        "languages": [
          "slk-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.16804,
        "recall": 0.20751,
        "f1": 0.175668,
        "accuracy": 0.20751,
        "main_score": 0.175668,
        "hf_subset": "tir_Ethi-ary_Arab",
        "languages": [
          "tir-Ethi",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.955204,
        "recall": 0.969368,
        "f1": 0.959816,
        "accuracy": 0.969368,
        "main_score": 0.959816,
        "hf_subset": "zho_Hant-ary_Arab",
        "languages": [
          "zho-Hant",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.905632,
        "recall": 0.932806,
        "f1": 0.914196,
        "accuracy": 0.932806,
        "main_score": 0.914196,
        "hf_subset": "awa_Deva-ary_Arab",
        "languages": [
          "awa-Deva",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.846353,
        "recall": 0.885375,
        "f1": 0.85802,
        "accuracy": 0.885375,
        "main_score": 0.85802,
        "hf_subset": "cym_Latn-ary_Arab",
        "languages": [
          "cym-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.28642,
        "recall": 0.355731,
        "f1": 0.302398,
        "accuracy": 0.355731,
        "main_score": 0.302398,
        "hf_subset": "grn_Latn-ary_Arab",
        "languages": [
          "grn-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.926383,
        "recall": 0.949605,
        "f1": 0.933959,
        "accuracy": 0.949605,
        "main_score": 0.933959,
        "hf_subset": "kat_Geor-ary_Arab",
        "languages": [
          "kat-Geor",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.190531,
        "recall": 0.23913,
        "f1": 0.201017,
        "accuracy": 0.23913,
        "main_score": 0.201017,
        "hf_subset": "lua_Latn-ary_Arab",
        "languages": [
          "lua-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.170561,
        "recall": 0.217391,
        "f1": 0.179448,
        "accuracy": 0.217391,
        "main_score": 0.179448,
        "hf_subset": "nya_Latn-ary_Arab",
        "languages": [
          "nya-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.958004,
        "recall": 0.971344,
        "f1": 0.962451,
        "accuracy": 0.971344,
        "main_score": 0.962451,
        "hf_subset": "slv_Latn-ary_Arab",
        "languages": [
          "slv-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.345668,
        "recall": 0.407115,
        "f1": 0.3616,
        "accuracy": 0.407115,
        "main_score": 0.3616,
        "hf_subset": "tpi_Latn-ary_Arab",
        "languages": [
          "tpi-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.958498,
        "recall": 0.971344,
        "f1": 0.96278,
        "accuracy": 0.971344,
        "main_score": 0.96278,
        "hf_subset": "zsm_Latn-ary_Arab",
        "languages": [
          "zsm-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.146025,
        "recall": 0.176877,
        "f1": 0.152691,
        "accuracy": 0.176877,
        "main_score": 0.152691,
        "hf_subset": "ayr_Latn-ary_Arab",
        "languages": [
          "ayr-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.968379,
        "recall": 0.978261,
        "f1": 0.971673,
        "accuracy": 0.978261,
        "main_score": 0.971673,
        "hf_subset": "dan_Latn-ary_Arab",
        "languages": [
          "dan-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.913208,
        "recall": 0.939723,
        "f1": 0.921772,
        "accuracy": 0.939723,
        "main_score": 0.921772,
        "hf_subset": "guj_Gujr-ary_Arab",
        "languages": [
          "guj-Gujr",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.934618,
        "recall": 0.954545,
        "f1": 0.941041,
        "accuracy": 0.954545,
        "main_score": 0.941041,
        "hf_subset": "kaz_Cyrl-ary_Arab",
        "languages": [
          "kaz-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.130273,
        "recall": 0.16996,
        "f1": 0.137379,
        "accuracy": 0.16996,
        "main_score": 0.137379,
        "hf_subset": "lug_Latn-ary_Arab",
        "languages": [
          "lug-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.903327,
        "recall": 0.931818,
        "f1": 0.912352,
        "accuracy": 0.931818,
        "main_score": 0.912352,
        "hf_subset": "oci_Latn-ary_Arab",
        "languages": [
          "oci-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.129028,
        "recall": 0.16502,
        "f1": 0.136442,
        "accuracy": 0.16502,
        "main_score": 0.136442,
        "hf_subset": "smo_Latn-ary_Arab",
        "languages": [
          "smo-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.135581,
        "recall": 0.172925,
        "f1": 0.143428,
        "accuracy": 0.172925,
        "main_score": 0.143428,
        "hf_subset": "tsn_Latn-ary_Arab",
        "languages": [
          "tsn-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.209689,
        "recall": 0.253953,
        "f1": 0.219421,
        "accuracy": 0.253953,
        "main_score": 0.219421,
        "hf_subset": "zul_Latn-ary_Arab",
        "languages": [
          "zul-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.370927,
        "recall": 0.450593,
        "f1": 0.390795,
        "accuracy": 0.450593,
        "main_score": 0.390795,
        "hf_subset": "azb_Arab-ary_Arab",
        "languages": [
          "azb-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.966403,
        "recall": 0.977273,
        "f1": 0.970026,
        "accuracy": 0.977273,
        "main_score": 0.970026,
        "hf_subset": "deu_Latn-ary_Arab",
        "languages": [
          "deu-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.265642,
        "recall": 0.332016,
        "f1": 0.279446,
        "accuracy": 0.332016,
        "main_score": 0.279446,
        "hf_subset": "hat_Latn-ary_Arab",
        "languages": [
          "hat-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.110761,
        "recall": 0.143281,
        "f1": 0.117771,
        "accuracy": 0.143281,
        "main_score": 0.117771,
        "hf_subset": "kbp_Latn-ary_Arab",
        "languages": [
          "kbp-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.149094,
        "recall": 0.186759,
        "f1": 0.157129,
        "accuracy": 0.186759,
        "main_score": 0.157129,
        "hf_subset": "luo_Latn-ary_Arab",
        "languages": [
          "luo-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.878129,
        "recall": 0.914032,
        "f1": 0.88946,
        "accuracy": 0.914032,
        "main_score": 0.88946,
        "hf_subset": "ory_Orya-ary_Arab",
        "languages": [
          "ory-Orya",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.14528,
        "recall": 0.175889,
        "f1": 0.15136,
        "accuracy": 0.175889,
        "main_score": 0.15136,
        "hf_subset": "sna_Latn-ary_Arab",
        "languages": [
          "sna-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.147791,
        "recall": 0.184783,
        "f1": 0.156457,
        "accuracy": 0.184783,
        "main_score": 0.156457,
        "hf_subset": "tso_Latn-ary_Arab",
        "languages": [
          "tso-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.93083,
        "recall": 0.953557,
        "f1": 0.938406,
        "accuracy": 0.953557,
        "main_score": 0.938406,
        "hf_subset": "azj_Latn-ary_Arab",
        "languages": [
          "azj-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.178819,
        "recall": 0.22332,
        "f1": 0.189522,
        "accuracy": 0.22332,
        "main_score": 0.189522,
        "hf_subset": "dik_Latn-ary_Arab",
        "languages": [
          "dik-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.4726,
        "recall": 0.532609,
        "f1": 0.487306,
        "accuracy": 0.532609,
        "main_score": 0.487306,
        "hf_subset": "hau_Latn-ary_Arab",
        "languages": [
          "hau-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.594319,
        "recall": 0.676877,
        "f1": 0.617972,
        "accuracy": 0.676877,
        "main_score": 0.617972,
        "hf_subset": "kea_Latn-ary_Arab",
        "languages": [
          "kea-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.299177,
        "recall": 0.347826,
        "f1": 0.311933,
        "accuracy": 0.347826,
        "main_score": 0.311933,
        "hf_subset": "lus_Latn-ary_Arab",
        "languages": [
          "lus-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.432439,
        "recall": 0.501976,
        "f1": 0.450815,
        "accuracy": 0.501976,
        "main_score": 0.450815,
        "hf_subset": "pag_Latn-ary_Arab",
        "languages": [
          "pag-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.846014,
        "recall": 0.889328,
        "f1": 0.859684,
        "accuracy": 0.889328,
        "main_score": 0.859684,
        "hf_subset": "snd_Arab-ary_Arab",
        "languages": [
          "snd-Arab",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.267428,
        "recall": 0.324111,
        "f1": 0.280507,
        "accuracy": 0.324111,
        "main_score": 0.280507,
        "hf_subset": "tuk_Latn-ary_Arab",
        "languages": [
          "tuk-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.336125,
        "recall": 0.408103,
        "f1": 0.354791,
        "accuracy": 0.408103,
        "main_score": 0.354791,
        "hf_subset": "bak_Cyrl-ary_Arab",
        "languages": [
          "bak-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.116811,
        "recall": 0.147233,
        "f1": 0.123721,
        "accuracy": 0.147233,
        "main_score": 0.123721,
        "hf_subset": "dyu_Latn-ary_Arab",
        "languages": [
          "dyu-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.959486,
        "recall": 0.972332,
        "f1": 0.963768,
        "accuracy": 0.972332,
        "main_score": 0.963768,
        "hf_subset": "heb_Hebr-ary_Arab",
        "languages": [
          "heb-Hebr",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.908432,
        "recall": 0.934783,
        "f1": 0.916634,
        "accuracy": 0.934783,
        "main_score": 0.916634,
        "hf_subset": "khk_Cyrl-ary_Arab",
        "languages": [
          "khk-Cyrl",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.944499,
        "recall": 0.962451,
        "f1": 0.950428,
        "accuracy": 0.962451,
        "main_score": 0.950428,
        "hf_subset": "lvs_Latn-ary_Arab",
        "languages": [
          "lvs-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.841996,
        "recall": 0.887352,
        "f1": 0.856028,
        "accuracy": 0.887352,
        "main_score": 0.856028,
        "hf_subset": "pan_Guru-ary_Arab",
        "languages": [
          "pan-Guru",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.483261,
        "recall": 0.546443,
        "f1": 0.499021,
        "accuracy": 0.546443,
        "main_score": 0.499021,
        "hf_subset": "som_Latn-ary_Arab",
        "languages": [
          "som-Latn",
          "ary-Arab"
        ]
      },
      {
        "precision": 0.161336,
        "recall": 0.204545,
        "f1": 0.169458,
        "accuracy": 0.204545,
        "main_score": 0.169458,
        "hf_subset": "tum_Latn-ary_Arab",
        "languages": [
          "tum-Latn",
          "ary-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 777.038624048233,
  "kg_co2_emissions": null
}