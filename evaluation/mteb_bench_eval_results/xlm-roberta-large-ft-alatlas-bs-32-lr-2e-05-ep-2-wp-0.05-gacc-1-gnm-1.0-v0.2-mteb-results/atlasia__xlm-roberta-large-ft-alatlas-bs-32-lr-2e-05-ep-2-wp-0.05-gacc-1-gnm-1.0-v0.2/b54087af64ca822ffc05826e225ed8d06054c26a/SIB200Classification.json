{
  "dataset_revision": "a74d7350ea12af010cfb1c21e34f1f81fd2e615b",
  "task_name": "SIB200Classification",
  "mteb_version": "1.34.22",
  "scores": {
    "train": [
      {
        "accuracy": 0.651641,
        "f1": 0.646591,
        "f1_weighted": 0.655262,
        "scores_per_experiment": [
          {
            "accuracy": 0.654779,
            "f1": 0.65435,
            "f1_weighted": 0.660118
          },
          {
            "accuracy": 0.671897,
            "f1": 0.66234,
            "f1_weighted": 0.675889
          },
          {
            "accuracy": 0.660485,
            "f1": 0.656581,
            "f1_weighted": 0.667318
          },
          {
            "accuracy": 0.676177,
            "f1": 0.666493,
            "f1_weighted": 0.681558
          },
          {
            "accuracy": 0.640514,
            "f1": 0.641266,
            "f1_weighted": 0.64516
          },
          {
            "accuracy": 0.599144,
            "f1": 0.600977,
            "f1_weighted": 0.598212
          },
          {
            "accuracy": 0.659058,
            "f1": 0.653186,
            "f1_weighted": 0.66649
          },
          {
            "accuracy": 0.60913,
            "f1": 0.600218,
            "f1_weighted": 0.60559
          },
          {
            "accuracy": 0.647646,
            "f1": 0.641034,
            "f1_weighted": 0.644721
          },
          {
            "accuracy": 0.697575,
            "f1": 0.689466,
            "f1_weighted": 0.707561
          }
        ],
        "main_score": 0.651641,
        "hf_subset": "ary_Arab",
        "languages": [
          "ary-Arab"
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.565657,
        "f1": 0.557061,
        "f1_weighted": 0.567906,
        "scores_per_experiment": [
          {
            "accuracy": 0.555556,
            "f1": 0.552502,
            "f1_weighted": 0.538253
          },
          {
            "accuracy": 0.565657,
            "f1": 0.55893,
            "f1_weighted": 0.555168
          },
          {
            "accuracy": 0.535354,
            "f1": 0.534211,
            "f1_weighted": 0.537715
          },
          {
            "accuracy": 0.636364,
            "f1": 0.63215,
            "f1_weighted": 0.649839
          },
          {
            "accuracy": 0.555556,
            "f1": 0.536091,
            "f1_weighted": 0.557261
          },
          {
            "accuracy": 0.575758,
            "f1": 0.567216,
            "f1_weighted": 0.578483
          },
          {
            "accuracy": 0.535354,
            "f1": 0.523285,
            "f1_weighted": 0.557574
          },
          {
            "accuracy": 0.555556,
            "f1": 0.544143,
            "f1_weighted": 0.55953
          },
          {
            "accuracy": 0.535354,
            "f1": 0.533053,
            "f1_weighted": 0.524918
          },
          {
            "accuracy": 0.606061,
            "f1": 0.58903,
            "f1_weighted": 0.620323
          }
        ],
        "main_score": 0.565657,
        "hf_subset": "ary_Arab",
        "languages": [
          "ary-Arab"
        ]
      }
    ],
    "test": [
      {
        "accuracy": 0.645098,
        "f1": 0.636462,
        "f1_weighted": 0.648447,
        "scores_per_experiment": [
          {
            "accuracy": 0.656863,
            "f1": 0.662662,
            "f1_weighted": 0.659221
          },
          {
            "accuracy": 0.651961,
            "f1": 0.629575,
            "f1_weighted": 0.652629
          },
          {
            "accuracy": 0.696078,
            "f1": 0.697973,
            "f1_weighted": 0.702042
          },
          {
            "accuracy": 0.651961,
            "f1": 0.644104,
            "f1_weighted": 0.661537
          },
          {
            "accuracy": 0.676471,
            "f1": 0.687115,
            "f1_weighted": 0.678636
          },
          {
            "accuracy": 0.622549,
            "f1": 0.61466,
            "f1_weighted": 0.61999
          },
          {
            "accuracy": 0.656863,
            "f1": 0.639214,
            "f1_weighted": 0.664953
          },
          {
            "accuracy": 0.563725,
            "f1": 0.545468,
            "f1_weighted": 0.563006
          },
          {
            "accuracy": 0.627451,
            "f1": 0.608906,
            "f1_weighted": 0.623077
          },
          {
            "accuracy": 0.647059,
            "f1": 0.634945,
            "f1_weighted": 0.659383
          }
        ],
        "main_score": 0.645098,
        "hf_subset": "ary_Arab",
        "languages": [
          "ary-Arab"
        ]
      }
    ]
  },
  "evaluation_time": 41.505436420440674,
  "kg_co2_emissions": null
}